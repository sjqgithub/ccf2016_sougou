{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 一、数据集切分\n",
    "### 交叉验证\n",
    "10W训练集分成8W和2W,8W用于第一层模型交叉验证，2W用于第二层模型交叉验证\n",
    "\n",
    "## 二、算法流程\n",
    "### 预处理\n",
    "1. 用LR填充空缺目标值，合并train test数据集\n",
    "2. 训练dbow和dm ２种doc2vec特征\n",
    "\n",
    "### 训练第一层模型\n",
    "1. 训练tfidf-lr模型\n",
    "2. 训练dbow-nn模型\n",
    "3. 训练dm-nn模型\n",
    "\n",
    "### 训练第二层模型\n",
    "1. 训练 xgb-ens模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\sun\\AppData\\Local\\Temp\\jieba.cache\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100000, 5)\n",
      "(100000, 2)\n",
      " 4    37107\n",
      " 3    28148\n",
      " 2    18858\n",
      "-1     9280\n",
      " 5     5693\n",
      " 1      560\n",
      " 0      354\n",
      "Name: Education, dtype: int64\n",
      " 0    38996\n",
      " 1    26744\n",
      " 2    18529\n",
      " 3    10654\n",
      " 4     2922\n",
      "-1     1666\n",
      " 5      489\n",
      "Name: age, dtype: int64\n",
      " 0    56976\n",
      " 1    40869\n",
      "-1     2155\n",
      "Name: gender, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading model cost 0.660 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000 20000 30000 频来入梦的频是什么意思\t涨的多音字\t王烁阳\t寒暄的意思\t陈昊\t徐娇\t望而生畏的畏是什么意思\t狂风怒号的号是什么意思\t校草大人求放过\t李爱叶\t千什么万仞\t竣工的近义词\t杨慧\t读后感\t饶组词\t2016qq网名最新版女\t作文那是一次勇敢的尝试开头\t凌潇肃\t女生日记读后感400字\t勉怎么组词\tqq个性说说大全\t昵称女生简短好听2字\t读后感窗边的小豆豆400字\t烟台橡树湾房子敢买吗\t城南旧事读后感400字\t女生日记读后感400字,200字写感受\t啼啭的意思\t勉怎么读\t我悠悠忽忽地漫游了一个下午\t固安自行车主题公园\t我不是潘金莲改档\t世纪星手机和誉品手机哪个更好\t描写昆虫的段落\t清组词\t窗边的小豆豆\ttfboys动漫头像\t频的意思\t陈昊海绵宝宝\t跻身是什么意思\t烟台橡树湾小区\t恶魔少爷别吻我\t涨的多音字组词和拼音\t返璞归真是什么意思\t凌潇肃王志\t变幻莫测的近义词\t韵组词\t透明的近义词\t怅望灰天的怅望是什么意思\t描写萤火虫的段落\t描写昆虫的作文200字\t寒暄的暄是什么意思\t望而生畏是什么意思\t胡先煦\t月球模型被吹走\t奇迹的意思\t书信格式\t雨中的颜色\t衡量是什么意思\tqq女生网名\t描写昆虫的段落100字\t观察蝴蝶的作文(用上拟人的修辞手法)150字\t马宇佟\t关于雨的音乐\t观察蜻蜓的作文(用上拟人的修辞手法)150字\t频的意思是什么\t憧憬是什么意思\t第一次尝试作文400\t读女生日记读后感\t固安第一小学六一图片\t寝不安席的安是什么意思\t余韵的意思\t长方形的面积公式\t草虫的村落中的村落指什么\t王智凌潇潇\t绵亘蜿蜒是什么意思\t耀眼的近义词\t王晶晶\t世纪星手机图片\t2.4米超级月饼\t海绵宝宝的配音是谁\t静谧的近义词\t固安有哪些学校\t2016qq网名\t王智\t尖端是什么意思\t陈浩\t凌潇肃姚晨离婚原因\t固安第一小学现在图片\ttfboys动漫萌头像\t王智性感照\t2016qq网名女生\t勤组词\t固安第一小学图片\t读女生日记有感400字\t读后感窗边的小豆豆\t2016qq女生网名\t阻挠的近义词\t涨的多音字组词大全\t章子怡催汪峰写歌\t昵称女生简短好听\t固安第一小学\t作文那是一次勇敢的尝试\t烟台\t温博研\t赵今麦\t草丛的村落\t草丛的村落中的村落指什么\t王智老公\t织上天的织什么意思\t要挟的近义词\t社会主义核心价值观手抄报\t宋玉枝\t固安公园\t我悠悠忽忽地漫游了一个下午中的悠悠忽忽是\t王智内衣\n",
      "\n",
      "====================\n",
      "['频来', '入梦', '的', '频是', '什么', '意思', '频来_*_入梦', '入梦_*_的', '的_*_频是', '频是_*_什么', '什么_*_意思', '涨', '的', '多音字', '涨_*_的', '的_*_多音字', '王烁阳', '寒暄', '的', '意思', '寒暄_*_的', '的_*_意思', '陈昊', '徐娇', '望而生畏', '的', '畏', '是', '什么', '意思', '望而生畏_*_的', '的_*_畏', '畏_*_是', '是_*_什么', '什么_*_意思', '狂风怒号', '的', '号', '是', '什么', '意思', '狂风怒号_*_的', '的_*_号', '号_*_是', '是_*_什么', '什么_*_意思', '校草', '大人', '求', '放过', '校草_*_大人', '大人_*_求', '求_*_放过', '李爱叶', '千', '什么', '万仞', '千_*_什么', '什么_*_万仞', '竣工', '的', '近义词', '竣工_*_的', '的_*_近义词', '杨慧', '读后感', '饶', '组词', '饶_*_组词', '2016qq', '网名', '最新版', '女', '2016qq_*_网名', '网名_*_最新版', '最新版_*_女', '作文', '那', '是', '一次', '勇敢', '的', '尝试', '开头', '作文_*_那', '那_*_是', '是_*_一次', '一次_*_勇敢', '勇敢_*_的', '的_*_尝试', '尝试_*_开头', '凌潇肃', '女生', '日记', '读后感', '400', '字', '女生_*_日记', '日记_*_读后感', '读后感_*_400', '400_*_字', '勉', '怎么', '组词', '勉_*_怎么', '怎么_*_组词', 'qq', '个性', '说', '说', '大全', 'qq_*_个性', '个性_*_说', '说_*_说', '说_*_大全', '昵称', '女生', '简短', '好听', '2', '字', '昵称_*_女生', '女生_*_简短', '简短_*_好听', '好听_*_2', '2_*_字', '读后感', '窗边', '的', '小豆豆', '400', '字', '读后感_*_窗边', '窗边_*_的', '的_*_小豆豆', '小豆豆_*_400', '400_*_字', '烟台', '橡树', '湾', '房子', '敢', '买', '吗', '烟台_*_橡树', '橡树_*_湾', '湾_*_房子', '房子_*_敢', '敢_*_买', '买_*_吗', '城南', '旧事', '读后感', '400', '字', '城南_*_旧事', '旧事_*_读后感', '读后感_*_400', '400_*_字', '女生', '日记', '读后感', '400', '字', ',', '200', '字', '写', '感受', '女生_*_日记', '日记_*_读后感', '读后感_*_400', '400_*_字', '字_*_,', ',_*_200', '200_*_字', '字_*_写', '写_*_感受', '啼啭', '的', '意思', '啼啭_*_的', '的_*_意思', '勉', '怎么', '读', '勉_*_怎么', '怎么_*_读', '我', '悠悠忽忽', '地', '漫游', '了', '一个', '下午', '我_*_悠悠忽忽', '悠悠忽忽_*_地', '地_*_漫游', '漫游_*_了', '了_*_一个', '一个_*_下午', '固安', '自行车', '主题公园', '固安_*_自行车', '自行车_*_主题公园', '我', '不是', '潘金莲', '改档', '我_*_不是', '不是_*_潘金莲', '潘金莲_*_改档', '世纪', '星', '手机', '和', '誉品', '手机', '哪个', '更好', '世纪_*_星', '星_*_手机', '手机_*_和', '和_*_誉品', '誉品_*_手机', '手机_*_哪个', '哪个_*_更好', '描写', '昆虫', '的', '段落', '描写_*_昆虫', '昆虫_*_的', '的_*_段落', '清', '组词', '清_*_组词', '窗边', '的', '小豆豆', '窗边_*_的', '的_*_小豆豆', 'tfboys', '动漫', '头像', 'tfboys_*_动漫', '动漫_*_头像', '频', '的', '意思', '频_*_的', '的_*_意思', '陈昊', '海绵', '宝宝', '陈昊_*_海绵', '海绵_*_宝宝', '跻身', '是', '什么', '意思', '跻身_*_是', '是_*_什么', '什么_*_意思', '烟台', '橡树', '湾', '小区', '烟台_*_橡树', '橡树_*_湾', '湾_*_小区', '恶魔', '少爷', '别吻', '我', '恶魔_*_少爷', '少爷_*_别吻', '别吻_*_我', '涨', '的', '多音字', '组词', '和', '拼音', '涨_*_的', '的_*_多音字', '多音字_*_组词', '组词_*_和', '和_*_拼音', '返璞归真', '是', '什么', '意思', '返璞归真_*_是', '是_*_什么', '什么_*_意思', '凌潇肃', '王志', '凌潇肃_*_王志', '变幻莫测', '的', '近义词', '变幻莫测_*_的', '的_*_近义词', '韵', '组词', '韵_*_组词', '透明', '的', '近义词', '透明_*_的', '的_*_近义词', '怅望', '灰天', '的', '怅望', '是', '什么', '意思', '怅望_*_灰天', '灰天_*_的', '的_*_怅望', '怅望_*_是', '是_*_什么', '什么_*_意思', '描写', '萤火虫', '的', '段落', '描写_*_萤火虫', '萤火虫_*_的', '的_*_段落', '描写', '昆虫', '的', '作文', '200', '字', '描写_*_昆虫', '昆虫_*_的', '的_*_作文', '作文_*_200', '200_*_字', '寒暄', '的', '暄', '是', '什么', '意思', '寒暄_*_的', '的_*_暄', '暄_*_是', '是_*_什么', '什么_*_意思', '望而生畏', '是', '什么', '意思', '望而生畏_*_是', '是_*_什么', '什么_*_意思', '胡先煦', '月球', '模型', '被', '吹', '走', '月球_*_模型', '模型_*_被', '被_*_吹', '吹_*_走', '奇迹', '的', '意思', '奇迹_*_的', '的_*_意思', '书信', '格式', '书信_*_格式', '雨中', '的', '颜色', '雨中_*_的', '的_*_颜色', '衡量', '是', '什么', '意思', '衡量_*_是', '是_*_什么', '什么_*_意思', 'qq', '女生', '网名', 'qq_*_女生', '女生_*_网名', '描写', '昆虫', '的', '段落', '100', '字', '描写_*_昆虫', '昆虫_*_的', '的_*_段落', '段落_*_100', '100_*_字', '观察', '蝴蝶', '的', '作文', '(', '用', '上', '拟人', '的', '修辞手法', ')', '150', '字', '观察_*_蝴蝶', '蝴蝶_*_的', '的_*_作文', '作文_*_(', '(_*_用', '用_*_上', '上_*_拟人', '拟人_*_的', '的_*_修辞手法', '修辞手法_*_)', ')_*_150', '150_*_字', '马宇', '佟', '马宇_*_佟', '关于', '雨', '的', '音乐', '关于_*_雨', '雨_*_的', '的_*_音乐', '观察', '蜻蜓', '的', '作文', '(', '用', '上', '拟人', '的', '修辞手法', ')', '150', '字', '观察_*_蜻蜓', '蜻蜓_*_的', '的_*_作文', '作文_*_(', '(_*_用', '用_*_上', '上_*_拟人', '拟人_*_的', '的_*_修辞手法', '修辞手法_*_)', ')_*_150', '150_*_字', '频', '的', '意思', '是', '什么', '频_*_的', '的_*_意思', '意思_*_是', '是_*_什么', '憧憬', '是', '什么', '意思', '憧憬_*_是', '是_*_什么', '什么_*_意思', '第一次', '尝试', '作文', '400', '第一次_*_尝试', '尝试_*_作文', '作文_*_400', '读', '女生', '日记', '读后感', '读_*_女生', '女生_*_日记', '日记_*_读后感', '固安', '第一', '小学', '六一', '图片', '固安_*_第一', '第一_*_小学', '小学_*_六一', '六一_*_图片', '寝不安席', '的', '安是', '什么', '意思', '寝不安席_*_的', '的_*_安是', '安是_*_什么', '什么_*_意思', '余韵', '的', '意思', '余韵_*_的', '的_*_意思', '长方形', '的', '面积', '公式', '长方形_*_的', '的_*_面积', '面积_*_公式', '草虫', '的', '村落', '中', '的', '村落', '指', '什么', '草虫_*_的', '的_*_村落', '村落_*_中', '中_*_的', '的_*_村落', '村落_*_指', '指_*_什么', '王智凌', '潇潇', '王智凌_*_潇潇', '绵亘', '蜿蜒', '是', '什么', '意思', '绵亘_*_蜿蜒', '蜿蜒_*_是', '是_*_什么', '什么_*_意思', '耀眼', '的', '近义词', '耀眼_*_的', '的_*_近义词', '王', '晶晶', '王_*_晶晶', '世纪', '星', '手机', '图片', '世纪_*_星', '星_*_手机', '手机_*_图片', '2.4', '米', '超级', '月饼', '2.4_*_米', '米_*_超级', '超级_*_月饼', '海绵', '宝宝', '的', '配音', '是', '谁', '海绵_*_宝宝', '宝宝_*_的', '的_*_配音', '配音_*_是', '是_*_谁', '静谧', '的', '近义词', '静谧_*_的', '的_*_近义词', '固安', '有', '哪些', '学校', '固安_*_有', '有_*_哪些', '哪些_*_学校', '2016qq', '网名', '2016qq_*_网名', '王智', '尖端', '是', '什么', '意思', '尖端_*_是', '是_*_什么', '什么_*_意思', '陈浩', '凌潇肃', '姚晨', '离婚', '原因', '凌潇肃_*_姚晨', '姚晨_*_离婚', '离婚_*_原因', '固安', '第一', '小学', '现在', '图片', '固安_*_第一', '第一_*_小学', '小学_*_现在', '现在_*_图片', 'tfboys', '动漫', '萌', '头像', 'tfboys_*_动漫', '动漫_*_萌', '萌_*_头像', '王智', '性感照', '王智_*_性感照', '2016qq', '网名', '女生', '2016qq_*_网名', '网名_*_女生', '勤', '组词', '勤_*_组词', '固安', '第一', '小学', '图片', '固安_*_第一', '第一_*_小学', '小学_*_图片', '读', '女生', '日记', '有感', '400', '字', '读_*_女生', '女生_*_日记', '日记_*_有感', '有感_*_400', '400_*_字', '读后感', '窗边', '的', '小豆豆', '读后感_*_窗边', '窗边_*_的', '的_*_小豆豆', '2016qq', '女生', '网名', '2016qq_*_女生', '女生_*_网名', '阻挠', '的', '近义词', '阻挠_*_的', '的_*_近义词', '涨', '的', '多音字', '组词', '大全', '涨_*_的', '的_*_多音字', '多音字_*_组词', '组词_*_大全', '章子怡', '催', '汪峰', '写歌', '章子怡_*_催', '催_*_汪峰', '汪峰_*_写歌', '昵称', '女生', '简短', '好听', '昵称_*_女生', '女生_*_简短', '简短_*_好听', '固安', '第一', '小学', '固安_*_第一', '第一_*_小学', '作文', '那', '是', '一次', '勇敢', '的', '尝试', '作文_*_那', '那_*_是', '是_*_一次', '一次_*_勇敢', '勇敢_*_的', '的_*_尝试', '烟台', '温博研', '赵今', '麦', '赵今_*_麦', '草丛', '的', '村落', '草丛_*_的', '的_*_村落', '草丛', '的', '村落', '中', '的', '村落', '指', '什么', '草丛_*_的', '的_*_村落', '村落_*_中', '中_*_的', '的_*_村落', '村落_*_指', '指_*_什么', '王智', '老公', '王智_*_老公', '织', '上天', '的', '织', '什么', '意思', '织_*_上天', '上天_*_的', '的_*_织', '织_*_什么', '什么_*_意思', '要挟', '的', '近义词', '要挟_*_的', '的_*_近义词', '社会主义', '核心', '价值观', '手抄报', '社会主义_*_核心', '核心_*_价值观', '价值观_*_手抄报', '宋玉枝', '固安', '公园', '固安_*_公园', '我', '悠悠忽忽', '地', '漫游', '了', '一个', '下午', '中', '的', '悠悠忽忽', '是', '我_*_悠悠忽忽', '悠悠忽忽_*_地', '地_*_漫游', '漫游_*_了', '了_*_一个', '一个_*_下午', '下午_*_中', '中_*_的', '的_*_悠悠忽忽', '悠悠忽忽_*_是', '王智', '内衣', '\\n', '王智_*_内衣', '内衣_*_\\n']\n",
      "40000 50000 60000 70000 80000 90000 100000 1699133\n"
     ]
    }
   ],
   "source": [
    "'''1.concat train data and test data \n",
    "   2.use lr to fill null label'''\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import jieba\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import StratifiedShuffleSplit,StratifiedKFold,cross_val_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB,BernoulliNB,GaussianNB\n",
    "import pickle\n",
    "import cfg\n",
    "\n",
    "#----------------------load data--------------------------------\n",
    "df_tr = []\n",
    "for i,line in enumerate(open(cfg.data_path + 'user_tag_query.10W.TRAIN',encoding='GB18030')):\n",
    "    segs = line.split('\\t')\n",
    "    row = {}\n",
    "    row['Id'] = segs[0]\n",
    "    row['age'] = int(segs[1])\n",
    "    row['gender'] = int(segs[2])\n",
    "    row['Education'] = int(segs[3])\n",
    "    row['query'] = '\\t'.join(segs[4:])\n",
    "    df_tr.append(row)\n",
    "df_tr = pd.DataFrame(df_tr)\n",
    "\n",
    "df_te=[]\n",
    "for i,line in enumerate(open(cfg.data_path + 'user_tag_query.10W.TEST',encoding='GB18030')):\n",
    "    segs = line.split('\\t')\n",
    "    row = {}\n",
    "    row['Id'] = segs[0]\n",
    "    row['query'] = '\\t'.join(segs[1:])\n",
    "    df_te.append(row)\n",
    "df_te = pd.DataFrame(df_te)\n",
    "\n",
    "print(df_tr.shape)\n",
    "print(df_te.shape)\n",
    "\n",
    "df_all = df_tr\n",
    "# df_all = pd.concat([df_tr,df_te]).fillna(1)\n",
    "# df_all.index = range(len(df_all))\n",
    "\n",
    "for lb in ['Education','age','gender']:\n",
    "    df_all[lb] = df_all[lb] - 1\n",
    "    print(df_all.iloc[:100000][lb].value_counts())\n",
    "    \n",
    "class Tokenizer():\n",
    "    def __init__(self):\n",
    "        self.n = 0\n",
    "    def __call__(self,line):\n",
    "        tokens = []\n",
    "        for query in line.split('\\t'):\n",
    "            words = [word for word in jieba.cut(query)]\n",
    "            for gram in [1,2]:\n",
    "                for i in range(len(words) - gram + 1):\n",
    "                    tokens += [\"_*_\".join(words[i:i+gram])]\n",
    "        if np.random.rand() < 0.00001:\n",
    "            print(line)\n",
    "            print('='*20)\n",
    "            print(tokens)\n",
    "        self.n += 1\n",
    "        if self.n%10000==0:\n",
    "            print(self.n,end=' ')\n",
    "        return tokens    \n",
    "\n",
    "tfv = TfidfVectorizer(tokenizer=Tokenizer(),min_df=3,max_df=0.95,sublinear_tf=True)\n",
    "X_sp = tfv.fit_transform(df_all['query'])\n",
    "# pickle.dump(X_sp,open(root + 'tfidf_10W.pkl','wb'))\n",
    "print(len(tfv.vocabulary_))\n",
    "X_all = X_sp\n",
    "\n",
    "#-----------------------------fill nan-------------------------------------\n",
    "'''填充空值'''\n",
    "for lb,idx in [('Education',0),('age',2),('gender',3)]:\n",
    "    tr = np.where(df_all[lb]!=-1)[0]\n",
    "    va = np.where(df_all[lb]==-1)[0]\n",
    "lb = 'Education'\n",
    "idx = 0\n",
    "tr = np.where(df_all[lb]!=-1)[0]\n",
    "va = np.where(df_all[lb]==-1)[0]\n",
    "df_all.iloc[va,idx] = LogisticRegression(C=1).fit(X_all[tr],df_all.iloc[tr,idx]).predict(X_all[va])\n",
    "\n",
    "lb = 'age'\n",
    "idx = 2\n",
    "tr = np.where(df_all[lb]!=-1)[0]\n",
    "va = np.where(df_all[lb]==-1)[0]\n",
    "df_all.iloc[va,idx] = LogisticRegression(C=2).fit(X_all[tr],df_all.iloc[tr,idx]).predict(X_all[va])\n",
    "\n",
    "lb = 'gender'\n",
    "idx = 3\n",
    "tr = np.where(df_all[lb]!=-1)[0]\n",
    "va = np.where(df_all[lb]==-1)[0]\n",
    "df_all.iloc[va,idx] = LogisticRegression(C=2).fit(X_all[tr],df_all.iloc[tr,idx]).predict(X_all[va])\n",
    "\n",
    "df_all = pd.concat([df_all,df_te]).fillna(0)\n",
    "df_all.to_csv(cfg.data_path + 'all_v2.csv',index=None,encoding='utf8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    58311\n",
       "1    41689\n",
       "Name: gender, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tr['gender'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    158311\n",
       "1.0     41689\n",
       "Name: gender, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all['gender'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Education</th>\n",
       "      <th>Id</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>query</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>22DD920316420BE2DF8D6EE651BA174B</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>柔和双沟\\t女生\\t中财网首页 财经\\thttp://pan.baidu.com/s/1pl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>43CC3AF5A8D6430A3B572337A889AFE4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>广州厨宝烤箱\\t世情薄,人情恶,雨送黄昏花易落,晓风干,泪痕\\t厦门酒店用品批发市场\\t我只...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>E97654BFF5570E2CCD433EA6128EAC19</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>钻石之泪耳机\\t盘锦到沈阳\\t旅顺公交\\t辽宁阜新车牌\\tbaidu\\tk715\\tk716...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>6931EFC26D229CCFCEA125D3F3C21E57</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>最受欢迎狗狗排行榜\\t舶怎么读\\t场景描 写范例\\t三维绘图软件\\t枣和酸奶能一起吃吗\\t好...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>E780470C3BB0D340334BD08CDCC3C71A</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>干槽症能自愈吗\\t太太万岁叶舒心去没去美国\\t干槽症\\t右眼皮下面一直跳是怎么回事\\t麦当劳...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Education                                Id  age  gender  \\\n",
       "0          3  22DD920316420BE2DF8D6EE651BA174B    0       0   \n",
       "1          2  43CC3AF5A8D6430A3B572337A889AFE4    1       0   \n",
       "2          4  E97654BFF5570E2CCD433EA6128EAC19    3       0   \n",
       "3          2  6931EFC26D229CCFCEA125D3F3C21E57    3       1   \n",
       "4          3  E780470C3BB0D340334BD08CDCC3C71A    1       1   \n",
       "\n",
       "                                               query  \n",
       "0  柔和双沟\\t女生\\t中财网首页 财经\\thttp://pan.baidu.com/s/1pl...  \n",
       "1  广州厨宝烤箱\\t世情薄,人情恶,雨送黄昏花易落,晓风干,泪痕\\t厦门酒店用品批发市场\\t我只...  \n",
       "2  钻石之泪耳机\\t盘锦到沈阳\\t旅顺公交\\t辽宁阜新车牌\\tbaidu\\tk715\\tk716...  \n",
       "3  最受欢迎狗狗排行榜\\t舶怎么读\\t场景描 写范例\\t三维绘图软件\\t枣和酸奶能一起吃吗\\t好...  \n",
       "4  干槽症能自愈吗\\t太太万岁叶舒心去没去美国\\t干槽症\\t右眼皮下面一直跳是怎么回事\\t麦当劳...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tr.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>query</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ED89D43B9F602F96D96C25255F7C228C</td>\n",
       "      <td>陈学冬将出的作品\\t刘昊然与谭松韵\\t211学校的分数线\\t谁唱的味道好听\\t吻戏是真吻还是...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>83C3B7B4AAF8074655A8079F561A76D6</td>\n",
       "      <td>e的0.0052次方\\tqq怎么快速提现\\t绝色倾城飞烟\\t马克思主义基本原理概论\\t康世恩...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CA9F675A024FB2353849350A35CF8B0F</td>\n",
       "      <td>黑暗文\\tlpl夏季赛\\t大富豪电玩城\\t英雄联盟之电竞称王\\t手机怎么扫描手机上的二维码\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DE45B5C4E57AAEBCF3FDFA2A774093BF</td>\n",
       "      <td>中秋水库钓鱼\\t鱼竿\\t用蚯蚓钓鱼怎样调漂\\t传统钓\\t3号鱼钩\\t鲫鱼汤的做法大全\\t鱼饵...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>406A681FB3DF81EC0E561796AE50AE50</td>\n",
       "      <td>号码吉凶\\t退休干部死后配偶\\t郫县有哪些大学\\t胜利油田属于中石化还是中石油\\t苏珊米勒狮...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Id  \\\n",
       "0  ED89D43B9F602F96D96C25255F7C228C   \n",
       "1  83C3B7B4AAF8074655A8079F561A76D6   \n",
       "2  CA9F675A024FB2353849350A35CF8B0F   \n",
       "3  DE45B5C4E57AAEBCF3FDFA2A774093BF   \n",
       "4  406A681FB3DF81EC0E561796AE50AE50   \n",
       "\n",
       "                                               query  \n",
       "0  陈学冬将出的作品\\t刘昊然与谭松韵\\t211学校的分数线\\t谁唱的味道好听\\t吻戏是真吻还是...  \n",
       "1  e的0.0052次方\\tqq怎么快速提现\\t绝色倾城飞烟\\t马克思主义基本原理概论\\t康世恩...  \n",
       "2  黑暗文\\tlpl夏季赛\\t大富豪电玩城\\t英雄联盟之电竞称王\\t手机怎么扫描手机上的二维码\\...  \n",
       "3  中秋水库钓鱼\\t鱼竿\\t用蚯蚓钓鱼怎样调漂\\t传统钓\\t3号鱼钩\\t鲫鱼汤的做法大全\\t鱼饵...  \n",
       "4  号码吉凶\\t退休干部死后配偶\\t郫县有哪些大学\\t胜利油田属于中石化还是中石油\\t苏珊米勒狮...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_te.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Education</th>\n",
       "      <th>Id</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>query</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.0</td>\n",
       "      <td>22DD920316420BE2DF8D6EE651BA174B</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>柔和双沟\\t女生\\t中财网首页 财经\\thttp://pan.baidu.com/s/1pl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>43CC3AF5A8D6430A3B572337A889AFE4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>广州厨宝烤箱\\t世情薄,人情恶,雨送黄昏花易落,晓风干,泪痕\\t厦门酒店用品批发市场\\t我只...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.0</td>\n",
       "      <td>E97654BFF5570E2CCD433EA6128EAC19</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>钻石之泪耳机\\t盘锦到沈阳\\t旅顺公交\\t辽宁阜新车牌\\tbaidu\\tk715\\tk716...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>6931EFC26D229CCFCEA125D3F3C21E57</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>最受欢迎狗狗排行榜\\t舶怎么读\\t场景描 写范例\\t三维绘图软件\\t枣和酸奶能一起吃吗\\t好...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.0</td>\n",
       "      <td>E780470C3BB0D340334BD08CDCC3C71A</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>干槽症能自愈吗\\t太太万岁叶舒心去没去美国\\t干槽症\\t右眼皮下面一直跳是怎么回事\\t麦当劳...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Education                                Id  age  gender  \\\n",
       "0        3.0  22DD920316420BE2DF8D6EE651BA174B  0.0     0.0   \n",
       "1        2.0  43CC3AF5A8D6430A3B572337A889AFE4  1.0     0.0   \n",
       "2        4.0  E97654BFF5570E2CCD433EA6128EAC19  3.0     0.0   \n",
       "3        2.0  6931EFC26D229CCFCEA125D3F3C21E57  3.0     1.0   \n",
       "4        3.0  E780470C3BB0D340334BD08CDCC3C71A  1.0     1.0   \n",
       "\n",
       "                                               query  \n",
       "0  柔和双沟\\t女生\\t中财网首页 财经\\thttp://pan.baidu.com/s/1pl...  \n",
       "1  广州厨宝烤箱\\t世情薄,人情恶,雨送黄昏花易落,晓风干,泪痕\\t厦门酒店用品批发市场\\t我只...  \n",
       "2  钻石之泪耳机\\t盘锦到沈阳\\t旅顺公交\\t辽宁阜新车牌\\tbaidu\\tk715\\tk716...  \n",
       "3  最受欢迎狗狗排行榜\\t舶怎么读\\t场景描 写范例\\t三维绘图软件\\t枣和酸奶能一起吃吗\\t好...  \n",
       "4  干槽症能自愈吗\\t太太万岁叶舒心去没去美国\\t干槽症\\t右眼皮下面一直跳是怎么回事\\t麦当劳...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sun\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-09-18 16:58:24.014811 0\n",
      "2018-09-18 16:59:13.445107 10000\n",
      "2018-09-18 17:00:02.583493 20000\n",
      "2018-09-18 17:00:51.289301 30000\n",
      "2018-09-18 17:01:39.779893 40000\n",
      "2018-09-18 17:02:28.438270 50000\n",
      "2018-09-18 17:03:17.842126 60000\n",
      "2018-09-18 17:04:07.605373 70000\n",
      "2018-09-18 17:04:56.875287 80000\n",
      "2018-09-18 17:05:45.370876 90000\n"
     ]
    }
   ],
   "source": [
    "'''train dbow/dm for education/age/gender'''\n",
    "\n",
    "import pandas as pd\n",
    "import jieba\n",
    "from datetime import datetime\n",
    "from collections import namedtuple\n",
    "from gensim.models.doc2vec import Doc2Vec\n",
    "from collections import OrderedDict\n",
    "import subprocess\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import codecs\n",
    "import cfg\n",
    "import numpy as np\n",
    "\n",
    "df_all = pd.read_csv(cfg.data_path + 'all_v2.csv',encoding='utf8')\n",
    "# -------------------add row number to query----------------------\n",
    "doc_f = codecs.open('alldata-id.txt','w',encoding='utf8')\n",
    "for i,queries in enumerate(df_all.iloc[:100000]['query']):\n",
    "    words = []\n",
    "    for query in queries.split('\\t'):\n",
    "        words.extend(list(jieba.cut(query)))\n",
    "    tags = [i]\n",
    "    if i % 10000 == 0:\n",
    "        print(datetime.now(),i)\n",
    "    doc_f.write('_*{} {}'.format(i,' '.join(words)))\n",
    "doc_f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "SentimentDocument = namedtuple('SentimentDocument', 'words tags')\n",
    "class Doc_list(object):\n",
    "    def __init__(self,f):\n",
    "        self.f = f\n",
    "    def __iter__(self):\n",
    "        for i,line in enumerate(codecs.open(self.f,encoding='utf8')):\n",
    "            words = line.split()\n",
    "            tags = [int(words[0][2:])]\n",
    "            words = words[1:]\n",
    "            yield SentimentDocument(words,tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sun\\Anaconda3\\lib\\site-packages\\gensim\\models\\doc2vec.py:366: UserWarning: The parameter `size` is deprecated, will be removed in 4.0.0, use `vector_size` instead.\n",
      "  warnings.warn(\"The parameter `size` is deprecated, will be removed in 4.0.0, use `vector_size` instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-09-18 17:11:12.114198 pass: 1\n",
      "dbow Education [0.42470753 0.48145185 0.52222389 0.56110611 0.56453468] 0.510804812736049\n",
      "dbow age [0.39866013 0.43925607 0.47975    0.52072604 0.52817923] 0.4733142943130019\n",
      "dbow gender [0.58412079 0.66745    0.77885    0.8023     0.7960898 ] 0.7257621196901053\n",
      "2018-09-18 17:23:31.386536 pass: 2\n",
      "dbow Education [0.58264174 0.59279072 0.60306985 0.60966097 0.60229034] 0.5980907225820283\n",
      "dbow age [0.52884712 0.53824618 0.55       0.56537827 0.57088563] 0.5506714384858611\n",
      "dbow gender [0.81210939 0.8144     0.8237     0.82945    0.82219111] 0.8203701008171503\n",
      "2018-09-18 17:41:54.435543 pass: 3\n",
      "dbow Education [0.60978902 0.61478852 0.61516924 0.6229623  0.61709256] 0.6159603287795808\n",
      "dbow age [0.55974403 0.56444356 0.5701     0.57637882 0.57763665] 0.5696606091359295\n",
      "dbow gender [0.82500875 0.82375    0.8309     0.8322     0.82889144] 0.8281500388269502\n",
      "2018-09-18 17:59:43.919977 pass: 4\n",
      "dbow Education [0.62458754 0.62228777 0.62071896 0.62561256 0.62504376] 0.6236501188680321\n",
      "dbow age [0.57234277 0.57134287 0.5776     0.57787889 0.58383758] 0.5766004202035798\n",
      "dbow gender [0.83170841 0.8282     0.8327     0.8363     0.83434172] 0.8326500263330251\n",
      "2018-09-18 18:13:32.681805 pass: 5\n",
      "dbow Education [0.63038696 0.62788721 0.62446878 0.62741274 0.63179477] 0.6283900919266847\n",
      "dbow age [0.58109189 0.57669233 0.58225    0.5819791  0.58578787] 0.5815602377426035\n",
      "dbow gender [0.83325834 0.8321     0.83455    0.83805    0.83329166] 0.834250000333275\n",
      "2018-09-18 18:24:01.945065 pass: 6\n",
      "dbow Education [0.63063694 0.63063694 0.62891855 0.63316332 0.63059459] 0.6307900664410093\n",
      "dbow age [0.58479152 0.58319168 0.58625    0.58482924 0.58723809] 0.5852601057709524\n",
      "dbow gender [0.83530823 0.83285    0.83625    0.83955    0.83509175] 0.8358099978352002\n",
      "2018-09-18 18:31:56.573219 pass: 7\n",
      "dbow Education [0.63078692 0.63268673 0.62856857 0.63256326 0.6346952 ] 0.6318601369624866\n",
      "dbow age [0.58754125 0.58539146 0.5859     0.58747937 0.58958844] 0.587180103792753\n",
      "dbow gender [0.83660817 0.83255    0.8371     0.8391     0.83699185] 0.8364700038367999\n",
      "2018-09-18 18:37:56.510078 pass: 8\n",
      "dbow Education [0.63043696 0.63323668 0.63141843 0.63371337 0.63389508] 0.6325401034630111\n",
      "dbow age [0.58834117 0.58679132 0.587      0.58787939 0.59193879] 0.5883901343079293\n",
      "dbow gender [0.83725814 0.8343     0.83745    0.8415     0.83769188] 0.837640004337475\n",
      "2018-09-18 18:43:35.287315 pass: 9\n",
      "dbow Education [0.63138686 0.63333667 0.63111844 0.63466347 0.63364505] 0.6328300969657359\n",
      "dbow age [0.58909109 0.58669133 0.589      0.58817941 0.59508926] 0.5896102188235561\n",
      "dbow gender [0.83755812 0.8348     0.8364     0.842      0.83704185] 0.8375599948373\n",
      "2018-09-18 18:49:12.077920 pass: 10\n",
      "dbow Education [0.63288671 0.63248675 0.63311834 0.63541354 0.63454518] 0.6336901059735865\n",
      "dbow age [0.59124088 0.58989101 0.5883     0.58757938 0.59238886] 0.5898800248218035\n",
      "dbow gender [0.83785811 0.8332     0.837      0.84185    0.8380919 ] 0.8376000023379749\n",
      "2018-09-18 18:54:32.012428 save done\n"
     ]
    }
   ],
   "source": [
    "df_lb = pd.read_csv(cfg.data_path + 'all_v2.csv',usecols=['Education','age','gender'],nrows=100000)\n",
    "ys = {}\n",
    "for lb in ['Education','age','gender']:\n",
    "    ys[lb] = np.array(df_lb[lb])\n",
    "\n",
    "d2v = Doc2Vec(dm=0, size=300, negative=5, hs=0, min_count=3, window=30,sample=1e-5,\n",
    "              workers=6,alpha=0.025,min_alpha=0.025,epochs=1)\n",
    "doc_list = Doc_list('alldata-id.txt')\n",
    "d2v.build_vocab(doc_list)\n",
    "    \n",
    "# -------------------train dbow doc2vec---------------------------------------------\n",
    "for i in range(10):\n",
    "    print(datetime.now(),'pass:',i + 1)\n",
    "    doc_list = Doc_list('alldata-id.txt')\n",
    "    d2v.train(doc_list,total_examples=d2v.corpus_count, epochs=d2v.epochs)\n",
    "    X_d2v = np.array([d2v.docvecs[i] for i in range(100000)])\n",
    "    for lb in [\"Education\",'age','gender']:\n",
    "        scores = cross_val_score(LogisticRegression(C=3),X_d2v,ys[lb],cv=5)\n",
    "        print('dbow',lb,scores,np.mean(scores))\n",
    "d2v.save(cfg.data_path + 'dbow_d2v.model')\n",
    "print(datetime.now(),'save done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sun\\Anaconda3\\lib\\site-packages\\gensim\\models\\doc2vec.py:366: UserWarning: The parameter `size` is deprecated, will be removed in 4.0.0, use `vector_size` instead.\n",
      "  warnings.warn(\"The parameter `size` is deprecated, will be removed in 4.0.0, use `vector_size` instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-09-18 19:06:51.248945 pass: 0\n",
      "dm Education [0.44670533 0.53619638 0.56162192 0.55960596 0.54518178] 0.5298622733191444\n",
      "dm age [0.42425757 0.49760024 0.51505    0.51512576 0.50022503] 0.4904517208522911\n",
      "dm gender [0.63576821 0.76865    0.78575    0.77905    0.76303815] 0.7464512726994031\n",
      "2018-09-18 19:23:45.742218 pass: 1\n",
      "dm Education [0.57269273 0.58844116 0.58662067 0.58550855 0.57028554] 0.5807097298528802\n",
      "dm age [0.52444756 0.54009599 0.5408     0.53637682 0.52292844] 0.5329297607504534\n",
      "dm gender [0.77651117 0.7974     0.80025    0.796      0.78458923] 0.7909500807805501\n",
      "2018-09-18 19:38:53.010901 pass: 2\n",
      "dm Education [0.58934107 0.59774023 0.59587021 0.59365937 0.58123719] 0.5915696099749838\n",
      "dm age [0.54334567 0.55084492 0.5497     0.54497725 0.53418013] 0.5446095913646803\n",
      "dm gender [0.79506025 0.8057     0.8075     0.8038     0.79073954] 0.8005599567928998\n",
      "2018-09-18 19:48:24.878007 pass: 3\n",
      "dm Education [0.59999    0.60263974 0.60091995 0.59810981 0.58923839] 0.5981795775535119\n",
      "dm age [0.55174483 0.55684432 0.55135    0.54947747 0.5420313 ] 0.5502895839310579\n",
      "dm gender [0.8019099  0.80885    0.80965    0.80955    0.79893995] 0.8057799703004248\n",
      "2018-09-18 19:55:50.288842 pass: 4\n",
      "dm Education [0.60308969 0.60433957 0.60691965 0.6019602  0.59438916] 0.6021396530969899\n",
      "dm age [0.55739426 0.56214379 0.5571     0.55542777 0.5446817 ] 0.5553495039678576\n",
      "dm gender [0.80815959 0.811      0.8115     0.8126     0.80244012] 0.8091399428052999\n",
      "2018-09-18 20:02:03.098854 pass: 5\n",
      "dm Education [0.60733927 0.60828917 0.60776961 0.60636064 0.59828974] 0.6056096856401668\n",
      "dm age [0.56119388 0.56624338 0.56165    0.55947797 0.54778217] 0.5592694794996332\n",
      "dm gender [0.81030948 0.81245    0.8146     0.81485    0.80559028] 0.8115599528079498\n",
      "2018-09-18 20:07:53.000213 pass: 6\n",
      "dm Education [0.60783922 0.61133887 0.60961952 0.61106111 0.60059009] 0.6080897591679435\n",
      "dm age [0.56459354 0.56709329 0.5642     0.55962798 0.55078262] 0.5612594860217095\n",
      "dm gender [0.81270936 0.815      0.8173     0.8171     0.80774039] 0.8139699503102248\n",
      "2018-09-18 20:14:00.361872 pass: 7\n",
      "dm Education [0.60878912 0.61433857 0.61121944 0.6109611  0.60304046] 0.6096697356874693\n",
      "dm age [0.56649335 0.56974303 0.565      0.56257813 0.55538331] 0.5638395625529867\n",
      "dm gender [0.81415929 0.8156     0.8203     0.82005    0.81019051] 0.816059960312175\n",
      "2018-09-18 20:20:08.589867 pass: 8\n",
      "dm Education [0.61253875 0.61578842 0.61316934 0.61361136 0.60639096] 0.6122997657192211\n",
      "dm age [0.56739326 0.57334267 0.56705    0.56512826 0.55683353] 0.5659495415697868\n",
      "dm gender [0.81575921 0.8171     0.8206     0.8206     0.81259063] 0.8173299683141749\n",
      "2018-09-18 20:25:52.783067 pass: 9\n",
      "dm Education [0.61113889 0.61848815 0.61696915 0.61531153 0.60924139] 0.614229821239948\n",
      "dm age [0.56809319 0.57259274 0.57055    0.56862843 0.55973396] 0.5679196645844888\n",
      "dm gender [0.81685916 0.81815    0.8222     0.82265    0.81254063] 0.8184799568147\n",
      "2018-09-18 20:31:47.296391 save done\n"
     ]
    }
   ],
   "source": [
    "d2v = Doc2Vec(dm=1, size=300, negative=5, hs=0, min_count=3, window=10,sample=1e-5,\n",
    "              workers=6,alpha=0.05,min_alpha=0.025,epochs=1)\n",
    "doc_list = Doc_list('alldata-id.txt')\n",
    "d2v.build_vocab(doc_list)\n",
    "\n",
    "# ---------------train dm doc2vec-----------------------------------------------------\n",
    "for i in range(10):\n",
    "    print(datetime.now(),'pass:',i)\n",
    "#     run_cmd('shuf alldata-id.txt > alldata-id-shuf.txt')\n",
    "    doc_list = Doc_list('alldata-id.txt')\n",
    "    d2v.train(doc_list,total_examples=d2v.corpus_count, epochs=d2v.epochs)\n",
    "    X_d2v = np.array([d2v.docvecs[i] for i in range(100000)])\n",
    "    for lb in [\"Education\",'age','gender']:\n",
    "        scores = cross_val_score(LogisticRegression(C=3),X_d2v,ys[lb],cv=5)\n",
    "        print('dm',lb,scores,np.mean(scores))\n",
    "d2v.save(cfg.data_path + 'dm_d2v.model')\n",
    "print(datetime.now(),'save done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-09-18 20:38:37.330051 pass: 0\n",
      "dm Education [0.61333867 0.61888811 0.61776911 0.6179618  0.61109166] 0.6158098697591743\n",
      "dm age [0.57194281 0.57454255 0.5704     0.57122856 0.56273441] 0.5701696646108898\n",
      "dm gender [0.8180591  0.8177     0.82405    0.8241     0.81424071] 0.8196299618161499\n",
      "2018-09-18 20:44:31.884588 pass: 1\n",
      "dm Education [0.61393861 0.61968803 0.61921904 0.61951195 0.61259189] 0.6169899032725501\n",
      "dm age [0.57224278 0.57519248 0.5708     0.57187859 0.5619843 ] 0.5704196296097391\n",
      "dm gender [0.81770911 0.8176     0.82475    0.8225     0.81514076] 0.8195399743164249\n",
      "2018-09-18 20:50:26.656293 pass: 2\n",
      "dm Education [0.61648835 0.62128787 0.61966902 0.6219622  0.61614242] 0.6191099713019522\n",
      "dm age [0.57359264 0.57684232 0.5721     0.57297865 0.5646347 ] 0.5720296601282154\n",
      "dm gender [0.81840908 0.8177     0.8252     0.8246     0.81674084] 0.8205299833175749\n",
      "2018-09-18 20:56:19.028115 pass: 3\n",
      "dm Education [0.61738826 0.62278772 0.61881906 0.6209621  0.61834275] 0.619659977814228\n",
      "dm age [0.57414259 0.57769223 0.5713     0.57612881 0.56488473] 0.5728296711337153\n",
      "dm gender [0.81965902 0.8186     0.82485    0.8268     0.81894095] 0.8217699928193\n",
      "2018-09-18 21:02:36.773531 pass: 4\n",
      "dm Education [0.6180382  0.62183782 0.62091895 0.62171217 0.61719258] 0.6199399433110024\n",
      "dm age [0.57409259 0.57864214 0.57385    0.57632882 0.56653498] 0.5738897046430413\n",
      "dm gender [0.82090895 0.81865    0.82505    0.82675    0.81944097] 0.8221599853201751\n",
      "2018-09-18 21:08:57.777950 pass: 5\n",
      "dm Education [0.61958804 0.62083792 0.62181891 0.62271227 0.61944292] 0.6208800108246791\n",
      "dm age [0.57544246 0.57949205 0.5737     0.57697885 0.56748512] 0.5746196956520414\n",
      "dm gender [0.82170891 0.81905    0.8244     0.82795    0.81989099] 0.8225999818207999\n",
      "2018-09-18 21:15:15.130915 pass: 6\n",
      "dm Education [0.62073793 0.62163784 0.62431878 0.62341234 0.61909286] 0.6218399503296534\n",
      "dm age [0.57464254 0.57949205 0.5723     0.57622881 0.5686353 ] 0.5742597386552424\n",
      "dm gender [0.82065897 0.8188     0.82505    0.8272     0.82109105] 0.8225600043208751\n",
      "2018-09-18 21:21:33.382324 pass: 7\n",
      "dm Education [0.62283772 0.62233777 0.62486876 0.62416242 0.6206431 ] 0.622969950344004\n",
      "dm age [0.57654235 0.58054195 0.57445    0.57722886 0.57028554] 0.575809739169068\n",
      "dm gender [0.82070896 0.8197     0.8241     0.82935    0.82179109] 0.8231300108212501\n",
      "2018-09-18 21:28:05.485432 pass: 8\n",
      "dm Education [0.62333767 0.62248775 0.6240688  0.62331233 0.62114317] 0.6228699433454542\n",
      "dm age [0.5770423  0.58129187 0.5746     0.5779289  0.57053558] 0.5762797286730429\n",
      "dm gender [0.82180891 0.81915    0.82465    0.82935    0.82179109] 0.8233499998218001\n",
      "2018-09-18 21:34:46.666058 pass: 9\n",
      "dm Education [0.62273773 0.62278772 0.62491875 0.62281228 0.62209331] 0.6230699593485547\n",
      "dm age [0.57829217 0.58154185 0.57415    0.57937897 0.57218583] 0.5771097626841938\n",
      "dm gender [0.82245888 0.81855    0.8256     0.8272     0.82179109] 0.8231199933221249\n",
      "2018-09-18 21:41:35.267472 save done\n"
     ]
    }
   ],
   "source": [
    "d2v = Doc2Vec.load(cfg.data_path + 'dm_d2v.model')\n",
    "for i in range(10):\n",
    "    print(datetime.now(),'pass:',i)\n",
    "#     run_cmd('shuf alldata-id.txt > alldata-id-shuf.txt')\n",
    "    doc_list = Doc_list('alldata-id.txt')\n",
    "    d2v.train(doc_list,total_examples=d2v.corpus_count, epochs=d2v.epochs)\n",
    "    X_d2v = np.array([d2v.docvecs[i] for i in range(100000)])\n",
    "    for lb in [\"Education\",'age','gender']:\n",
    "        scores = cross_val_score(LogisticRegression(C=3),X_d2v,ys[lb],cv=5)\n",
    "        print('dm',lb,scores,np.mean(scores))\n",
    "d2v.save(cfg.data_path + 'dm_d2v.model')\n",
    "print(datetime.now(),'save done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(d2v.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "斯卡哈\t我们之中\t张宏胜\tpandakill第二季\t为什么叫pdd扔蛇狂魔\t张宏圣\t金轮转生爆\t二代火影的雷神之剑\t真三国无双7猛将传吕布传if结局\t为什么叫pdd嫖老师\tfate斯卡哈\t守候高塔上的公主\t真三国无双7猛将传唤醒技能\t仙剑vr版\t办公室打游戏,我只能说一句话,哥们带我\t三国杀徐晃\t阿尔托莉雅拔出石中剑\t元十三限\t直至死亡\t战棋游戏,讲封神榜的\t战旗桃子和熊猫桃子\t最强反派糸统\t自知之明\t真三国无双7猛将传吕布传三处老虎\t九尾双狮掌\t皆非歌词\t银行开通网银盾流程\t南山南歌词\t我生君老,锦绣天下你却看不到\t炉石传说打玛克扎尔王子用牺牲契约\t快乐时光影院\t河图三世故事\t我的学妹不可能那么萌吧\t真三国无双7猛将传樊城之战怎么选徐庶\t百度输入法手机版\t择天记\t坚毅忍传\t拳皇14剧情\t织女竟给夏侯四十一用歹毒手法制住了,而他?uno牌的玩法\t炉石传说双人现开赛战报\t你以为我是谁\t熊猫tv狼人杀第二季\t白色相簿\t七里香歌词\t东方月初\t阵法\t炉石传说怎么得到泰兰德\t地下城堡2熊地精宝藏\t东华理工枫林校区到江西师范大学\t择天记电视剧播出时间\t真三国无双7猛将传动画怎么获得\t熊猫狼人杀第二季\t离歌歌词\t国足2-3不敌韩国\t守候高塔上的公主txt\t战网官网\t起点中文网\t地下城堡2攻略\t神话版三国\t真三国无双7猛将传动画\t何休\t无双大蛇z吴第三关逃脱地点\t桃子去了战旗\t东方剑客奇谭传\t重生犬夜叉之修罗丸\t来吧冠军\t中国建设银行\t穿越犬夜叉之我是桔梗\t寄生兽电影图片\t炉石传说龙牧\tim\tbigbang\t阴天快乐歌词\t幻想乡战记\t阿求\t火影之鸣人风流\t公主,如果你打出这张牌你就会出局\tdota是暴雪的吗\t放置江湖\t炉石传说官网积分兑换\t大宋提刑官片尾曲\t真姬\t二尾人柱力\t曹宁\t炉石传说官网\t折木奉太郎\t三鞭道人\t有整片星空和一只老狗\t东华理工大学官网\t真三国无双7猛将传吕布传\t游戏王5ds漫画和动画的区别\t九九八十一歌曲\t九九八十一\t舞娘歌词\t炉石传说怎么获得积分\t真三国无双7猛将传吕布传结局\t起点\t英灵斯卡哈\t真三国无双7猛将传护卫支援按键\t熊猫狼人杀第二季改名\t思乡未敢听琵琶\t太极螺旋丸\tsuperliae第二季\t苹果qq怎么设置红包提醒功能\t三国之我是丁原\t无双大蛇z切换地图\t超凡兵王\t情歌王歌词\t陈长生百度百科\t炉石传说官网怎么获得积分\t界限突破贾诩\tzafkiel\t一寸后宫一寸血 半尺白绫半寸心\t三国杀官网\t千智风声美图版\t苹果qq怎么开启红包提醒功能\t鞍马八云\tpandakill\t真三国无双7猛将传陈仓之战\tbbc\t办公室打游戏,我只能说一句话\t小鸟游六花\t战旗狼人杀第五季\t游戏王5ds漫画版十龙\t人质难道蒸发了\t大宋提刑官片尾曲谁唱的\t麻将胡牌公式\t无双大蛇z吴第四关逃脱地点在哪里\t银行开通网银盾\t朝天一棍\t三大邪教\tlol6.16版本更新内容\t外道魔像\t不败传说\t超能外星女友\t寄生兽中国票房\t夏侯四十一\t东华理工到江西师范大学\t618版本lol更新\t将夜\t桌游碟影重重\t炉石传说吧\t\"一个男人握着加温的酒,有整片星空和一只老\t维多利亚的秘密歌词\t黑人乔治\t寄生兽电影影评\t十年歌词\t地下城堡2囚徒之塔钥匙\t单美仙百度百科\t许嵩天干物燥\t寄生兽定妆照\t樱花草歌词\tlol6.18版本更新内容\t幻想乡初代博丽\t快乐时光影城今日影讯\t真三国无双7猛将传樊城之战\t面基\tae86\t火影忍者黑人乔治\t甲午崛起\t《大唐双龙传之重生边不负\t他把纪录片放给老人看,这盛世如你所愿\tlm第五季\t我的大宝剑学霸殿下\t二尾\t无双大蛇z发现重要物品\t南山南\t童年歌词\t情非得已歌词\t这盛世如你所愿\t东华理工大学\t丑八怪歌词\t牧昏者约里克\t卡拉赞之夜彩蛋\t真三国无双7猛将传吕布传if\t自在门\t千智风声\t无双大蛇z吴第四关逃脱地点\t+1s\t90小游戏\t快乐时光影院影讯\t一夜终极狼人\t择天记周独夫\t三鞭道\t话说我的房间是c栋3楼呢\t夏一可的未来夫君\t绅士歌词\tx1\t李沉舟\t真三国无双7猛将传吕不传看不到结局\t曹宁陆文龙\t真三国无双7猛将传\t择天记周独副\t战网\tgamesofdesire.com\t618版本lol\t你的名字\t随身炉石传说\t单美仙\t讨论组和群有什么区别\t巨人导演德\t甲午崛起txt下载\t炉石传说双人现开赛\t当歌词\t森近霖之助和犬夜叉\t阿尔托莉雅\t秋名山上行人稀 图\tqq邮箱\t天津教案\t四季映姬\t狼人杀白狼\t大宋提刑官\t剑娘\t战神录\t如果人类人口变为一半\t折木奉太郎的名言\t真三国无双7猛将传陈仓之战图文\texo me什么意思\t我真是大明星\t限韩令\t狼人杀狼兄狼弟\t超神师兄\t择天记起点\t电竞bbc\t鞭道人\t创界山\t电视剧一寸山河一寸血\tfate斯卡哈本子\t三坟五典八索九丘\t四大天王有五个\t陈长生\tbigbang歌词\t英雄联盟\t火影之幻想乡大弟子\t真三国无双7猛将传吴国if\t真三国无双7猛将传真无双乱舞\t铁十郎\tlm第五季第一集\tqq怎么设置红包提醒\t八百里开外一枪干掉鬼子机枪手\t桌游情书\t何休剑公子\t铁十郎百度百科\t儒道至圣\t我家wifi信号一闪一闪\t云隐村的黑人乔治\tv字仇杀队\t女装山脉\t这盛世如你所愿作文\t狼人杀白狼第几天开始可以刀人\t步步为营规则\t中国建设银行app下载\t搜狗小说进不去\t真三国无双7猛将传援助武将\t真三国无双\t魔兽世界\t炉石传说打麻克扎尔王子用牺牲契约\t寄生兽开头\t火影红豆结局\t韩娱我的外星女友\t一股清流什么意思\t我一穷二白却有三妻四妾\t寄生兽\t守望先锋把球打进篮筐\t隙间罪袋英雄23号\t寄生兽开头的那句话\t寄生兽真人版开篇语句\t剑娘txt下载\t真三国无双7猛将传护卫支援\t小九尾人柱力\t微微一笑很倾城\t白色相簿百度百科\t怎么把群退回讨论组\n",
      "\n",
      "====================\n",
      "['斯', '卡哈', '斯_*_卡哈', '我们', '之中', '我们_*_之中', '张宏胜', 'pandakill', '第二季', 'pandakill_*_第二季', '为什么', '叫', 'pdd', '扔', '蛇', '狂', '魔', '为什么_*_叫', '叫_*_pdd', 'pdd_*_扔', '扔_*_蛇', '蛇_*_狂', '狂_*_魔', '张宏圣', '金轮', '转生', '爆', '金轮_*_转生', '转生_*_爆', '二代', '火影', '的', '雷神', '之', '剑', '二代_*_火影', '火影_*_的', '的_*_雷神', '雷神_*_之', '之_*_剑', '真三国', '无双', '7', '猛将传', '吕布', '传', 'if', '结局', '真三国_*_无双', '无双_*_7', '7_*_猛将传', '猛将传_*_吕布', '吕布_*_传', '传_*_if', 'if_*_结局', '为什么', '叫', 'pdd', '嫖', '老师', '为什么_*_叫', '叫_*_pdd', 'pdd_*_嫖', '嫖_*_老师', 'fate', '斯', '卡哈', 'fate_*_斯', '斯_*_卡哈', '守候', '高塔', '上', '的', '公主', '守候_*_高塔', '高塔_*_上', '上_*_的', '的_*_公主', '真三国', '无双', '7', '猛将传', '唤醒', '技能', '真三国_*_无双', '无双_*_7', '7_*_猛将传', '猛将传_*_唤醒', '唤醒_*_技能', '仙剑', 'vr', '版', '仙剑_*_vr', 'vr_*_版', '办公室', '打游戏', ',', '我', '只能', '说', '一句', '话', ',', '哥们', '带', '我', '办公室_*_打游戏', '打游戏_*_,', ',_*_我', '我_*_只能', '只能_*_说', '说_*_一句', '一句_*_话', '话_*_,', ',_*_哥们', '哥们_*_带', '带_*_我', '三国', '杀', '徐晃', '三国_*_杀', '杀_*_徐晃', '阿尔托', '莉雅', '拔出', '石中剑', '阿尔托_*_莉雅', '莉雅_*_拔出', '拔出_*_石中剑', '元', '十三', '限', '元_*_十三', '十三_*_限', '直至', '死亡', '直至_*_死亡', '战棋', '游戏', ',', '讲', '封神榜', '的', '战棋_*_游戏', '游戏_*_,', ',_*_讲', '讲_*_封神榜', '封神榜_*_的', '战旗', '桃子', '和', '熊猫', '桃子', '战旗_*_桃子', '桃子_*_和', '和_*_熊猫', '熊猫_*_桃子', '最强', '反派', '糸', '统', '最强_*_反派', '反派_*_糸', '糸_*_统', '自知之明', '真三国', '无双', '7', '猛将传', '吕布', '传', '三处', '老虎', '真三国_*_无双', '无双_*_7', '7_*_猛将传', '猛将传_*_吕布', '吕布_*_传', '传_*_三处', '三处_*_老虎', '九尾', '双狮', '掌', '九尾_*_双狮', '双狮_*_掌', '皆', '非', '歌词', '皆_*_非', '非_*_歌词', '银行', '开通', '网银盾', '流程', '银行_*_开通', '开通_*_网银盾', '网银盾_*_流程', '南', '山南', '歌词', '南_*_山南', '山南_*_歌词', '我', '生君', '老', ',', '锦绣', '天下', '你', '却', '看不到', '我_*_生君', '生君_*_老', '老_*_,', ',_*_锦绣', '锦绣_*_天下', '天下_*_你', '你_*_却', '却_*_看不到', '炉石', '传说', '打玛克', '扎尔', '王子', '用', '牺牲', '契约', '炉石_*_传说', '传说_*_打玛克', '打玛克_*_扎尔', '扎尔_*_王子', '王子_*_用', '用_*_牺牲', '牺牲_*_契约', '快乐', '时光', '影院', '快乐_*_时光', '时光_*_影院', '河图', '三世', '故事', '河图_*_三世', '三世_*_故事', '我', '的', '学妹', '不', '可能', '那么', '萌', '吧', '我_*_的', '的_*_学妹', '学妹_*_不', '不_*_可能', '可能_*_那么', '那么_*_萌', '萌_*_吧', '真三国', '无双', '7', '猛将传', '樊城', '之战', '怎么', '选徐', '庶', '真三国_*_无双', '无双_*_7', '7_*_猛将传', '猛将传_*_樊城', '樊城_*_之战', '之战_*_怎么', '怎么_*_选徐', '选徐_*_庶', '百度', '输入法', '手机', '版', '百度_*_输入法', '输入法_*_手机', '手机_*_版', '择天记', '坚毅', '忍传', '坚毅_*_忍传', '拳皇', '14', '剧情', '拳皇_*_14', '14_*_剧情', '织女', '竟', '给', '夏侯', '四十一', '用', '歹毒', '手', '法制', '住', '了', ',', '而', '他', '?', 'uno', '牌', '的', '玩法', '织女_*_竟', '竟_*_给', '给_*_夏侯', '夏侯_*_四十一', '四十一_*_用', '用_*_歹毒', '歹毒_*_手', '手_*_法制', '法制_*_住', '住_*_了', '了_*_,', ',_*_而', '而_*_他', '他_*_?', '?_*_uno', 'uno_*_牌', '牌_*_的', '的_*_玩法', '炉石', '传说', '双人', '现', '开赛', '战报', '炉石_*_传说', '传说_*_双人', '双人_*_现', '现_*_开赛', '开赛_*_战报', '你', '以为', '我', '是', '谁', '你_*_以为', '以为_*_我', '我_*_是', '是_*_谁', '熊猫', 'tv', '狼人', '杀', '第二季', '熊猫_*_tv', 'tv_*_狼人', '狼人_*_杀', '杀_*_第二季', '白色', '相簿', '白色_*_相簿', '七里香', '歌词', '七里香_*_歌词', '东方', '月初', '东方_*_月初', '阵法', '炉石', '传说', '怎么', '得到', '泰', '兰德', '炉石_*_传说', '传说_*_怎么', '怎么_*_得到', '得到_*_泰', '泰_*_兰德', '地下', '城堡', '2', '熊地', '精', '宝藏', '地下_*_城堡', '城堡_*_2', '2_*_熊地', '熊地_*_精', '精_*_宝藏', '东华', '理工', '枫林', '校区', '到', '江西师范大学', '东华_*_理工', '理工_*_枫林', '枫林_*_校区', '校区_*_到', '到_*_江西师范大学', '择天记', '电视剧', '播出', '时间', '择天记_*_电视剧', '电视剧_*_播出', '播出_*_时间', '真三国', '无双', '7', '猛将传', '动画', '怎么', '获得', '真三国_*_无双', '无双_*_7', '7_*_猛将传', '猛将传_*_动画', '动画_*_怎么', '怎么_*_获得', '熊猫', '狼人', '杀', '第二季', '熊猫_*_狼人', '狼人_*_杀', '杀_*_第二季', '离歌', '歌词', '离歌_*_歌词', '国足', '2', '-', '3', '不敌', '韩国', '国足_*_2', '2_*_-', '-_*_3', '3_*_不敌', '不敌_*_韩国', '守候', '高塔', '上', '的', '公主', 'txt', '守候_*_高塔', '高塔_*_上', '上_*_的', '的_*_公主', '公主_*_txt', '战网', '官网', '战网_*_官网', '起点', '中文网', '起点_*_中文网', '地下', '城堡', '2', '攻略', '地下_*_城堡', '城堡_*_2', '2_*_攻略', '神话', '版', '三国', '神话_*_版', '版_*_三国', '真三国', '无双', '7', '猛将传', '动画', '真三国_*_无双', '无双_*_7', '7_*_猛将传', '猛将传_*_动画', '何休', '无双', '大蛇', 'z', '吴', '第三关', '逃脱', '地点', '无双_*_大蛇', '大蛇_*_z', 'z_*_吴', '吴_*_第三关', '第三关_*_逃脱', '逃脱_*_地点', '桃子', '去', '了', '战旗', '桃子_*_去', '去_*_了', '了_*_战旗', '东方', '剑客', '奇谭', '传', '东方_*_剑客', '剑客_*_奇谭', '奇谭_*_传', '重生', '犬夜叉', '之', '修罗', '丸', '重生_*_犬夜叉', '犬夜叉_*_之', '之_*_修罗', '修罗_*_丸', '来', '吧', '冠军', '来_*_吧', '吧_*_冠军', '中国建设银行', '穿越', '犬夜叉', '之', '我', '是', '桔梗', '穿越_*_犬夜叉', '犬夜叉_*_之', '之_*_我', '我_*_是', '是_*_桔梗', '寄生兽', '电影', '图片', '寄生兽_*_电影', '电影_*_图片', '炉石', '传说', '龙牧', '炉石_*_传说', '传说_*_龙牧', 'im', 'bigbang', '阴天', '快乐', '歌词', '阴天_*_快乐', '快乐_*_歌词', '幻想', '乡', '战记', '幻想_*_乡', '乡_*_战记', '阿求', '火影', '之鸣', '人', '风流', '火影_*_之鸣', '之鸣_*_人', '人_*_风流', '公主', ',', '如果', '你', '打出', '这', '张牌', '你', '就', '会', '出局', '公主_*_,', ',_*_如果', '如果_*_你', '你_*_打出', '打出_*_这', '这_*_张牌', '张牌_*_你', '你_*_就', '就_*_会', '会_*_出局', 'dota', '是', '暴雪', '的', '吗', 'dota_*_是', '是_*_暴雪', '暴雪_*_的', '的_*_吗', '放置', '江湖', '放置_*_江湖', '炉石', '传说', '官网', '积分', '兑换', '炉石_*_传说', '传说_*_官网', '官网_*_积分', '积分_*_兑换', '大宋', '提刑官', '片尾曲', '大宋_*_提刑官', '提刑官_*_片尾曲', '真姬', '二尾', '人柱力', '二尾_*_人柱力', '曹宁', '炉石', '传说', '官网', '炉石_*_传说', '传说_*_官网', '折木奉', '太郎', '折木奉_*_太郎', '三鞭', '道人', '三鞭_*_道人', '有', '整片', '星空', '和', '一只', '老狗', '有_*_整片', '整片_*_星空', '星空_*_和', '和_*_一只', '一只_*_老狗', '东华', '理工大学', '官网', '东华_*_理工大学', '理工大学_*_官网', '真三国', '无双', '7', '猛将传', '吕布', '传', '真三国_*_无双', '无双_*_7', '7_*_猛将传', '猛将传_*_吕布', '吕布_*_传', '游戏王', '5ds', '漫画', '和', '动画', '的', '区别', '游戏王_*_5ds', '5ds_*_漫画', '漫画_*_和', '和_*_动画', '动画_*_的', '的_*_区别', '九九八十一', '歌曲', '九九八十一_*_歌曲', '九九八十一', '舞娘', '歌词', '舞娘_*_歌词', '炉石', '传说', '怎么', '获得', '积分', '炉石_*_传说', '传说_*_怎么', '怎么_*_获得', '获得_*_积分', '真三国', '无双', '7', '猛将传', '吕布', '传', '结局', '真三国_*_无双', '无双_*_7', '7_*_猛将传', '猛将传_*_吕布', '吕布_*_传', '传_*_结局', '起点', '英灵', '斯', '卡哈', '英灵_*_斯', '斯_*_卡哈', '真三国', '无双', '7', '猛将传', '护卫', '支援', '按键', '真三国_*_无双', '无双_*_7', '7_*_猛将传', '猛将传_*_护卫', '护卫_*_支援', '支援_*_按键', '熊猫', '狼人', '杀', '第二季', '改名', '熊猫_*_狼人', '狼人_*_杀', '杀_*_第二季', '第二季_*_改名', '思乡', '未敢', '听', '琵琶', '思乡_*_未敢', '未敢_*_听', '听_*_琵琶', '太极', '螺旋', '丸', '太极_*_螺旋', '螺旋_*_丸', 'superliae', '第二季', 'superliae_*_第二季', '苹果', 'qq', '怎么', '设置', '红包', '提醒', '功能', '苹果_*_qq', 'qq_*_怎么', '怎么_*_设置', '设置_*_红包', '红包_*_提醒', '提醒_*_功能', '三国', '之', '我', '是', '丁原', '三国_*_之', '之_*_我', '我_*_是', '是_*_丁原', '无双', '大蛇', 'z', '切换', '地图', '无双_*_大蛇', '大蛇_*_z', 'z_*_切换', '切换_*_地图', '超凡', '兵王', '超凡_*_兵王', '情歌', '王', '歌词', '情歌_*_王', '王_*_歌词', '陈', '长生', '百度', '百科', '陈_*_长生', '长生_*_百度', '百度_*_百科', '炉石', '传说', '官网', '怎么', '获得', '积分', '炉石_*_传说', '传说_*_官网', '官网_*_怎么', '怎么_*_获得', '获得_*_积分', '界限', '突破', '贾诩', '界限_*_突破', '突破_*_贾诩', 'zafkiel', '一寸', '后宫', '一寸', '血', ' ', '半尺', '白绫', '半寸', '心', '一寸_*_后宫', '后宫_*_一寸', '一寸_*_血', '血_*_ ', ' _*_半尺', '半尺_*_白绫', '白绫_*_半寸', '半寸_*_心', '三国', '杀', '官网', '三国_*_杀', '杀_*_官网', '千智', '风声', '美', '图版', '千智_*_风声', '风声_*_美', '美_*_图版', '苹果', 'qq', '怎么', '开启', '红包', '提醒', '功能', '苹果_*_qq', 'qq_*_怎么', '怎么_*_开启', '开启_*_红包', '红包_*_提醒', '提醒_*_功能', '鞍马', '八云', '鞍马_*_八云', 'pandakill', '真三国', '无双', '7', '猛将传', '陈仓', '之战', '真三国_*_无双', '无双_*_7', '7_*_猛将传', '猛将传_*_陈仓', '陈仓_*_之战', 'bbc', '办公室', '打游戏', ',', '我', '只能', '说', '一句', '话', '办公室_*_打游戏', '打游戏_*_,', ',_*_我', '我_*_只能', '只能_*_说', '说_*_一句', '一句_*_话', '小鸟', '游六花', '小鸟_*_游六花', '战旗', '狼人', '杀', '第五', '季', '战旗_*_狼人', '狼人_*_杀', '杀_*_第五', '第五_*_季', '游戏王', '5ds', '漫画版', '十龙', '游戏王_*_5ds', '5ds_*_漫画版', '漫画版_*_十龙', '人质', '难道', '蒸发', '了', '人质_*_难道', '难道_*_蒸发', '蒸发_*_了', '大宋', '提刑官', '片尾曲', '谁', '唱', '的', '大宋_*_提刑官', '提刑官_*_片尾曲', '片尾曲_*_谁', '谁_*_唱', '唱_*_的', '麻将', '胡牌', '公式', '麻将_*_胡牌', '胡牌_*_公式', '无双', '大蛇', 'z', '吴', '第四', '关', '逃脱', '地点', '在', '哪里', '无双_*_大蛇', '大蛇_*_z', 'z_*_吴', '吴_*_第四', '第四_*_关', '关_*_逃脱', '逃脱_*_地点', '地点_*_在', '在_*_哪里', '银行', '开通', '网银盾', '银行_*_开通', '开通_*_网银盾', '朝', '天一', '棍', '朝_*_天一', '天一_*_棍', '三大', '邪教', '三大_*_邪教', 'lol6.16', '版本', '更新', '内容', 'lol6.16_*_版本', '版本_*_更新', '更新_*_内容', '外道', '魔', '像', '外道_*_魔', '魔_*_像', '不败', '传说', '不败_*_传说', '超', '能', '外星', '女友', '超_*_能', '能_*_外星', '外星_*_女友', '寄生兽', '中国', '票房', '寄生兽_*_中国', '中国_*_票房', '夏侯', '四十一', '夏侯_*_四十一', '东华', '理工', '到', '江西师范大学', '东华_*_理工', '理工_*_到', '到_*_江西师范大学', '618', '版本', 'lol', '更新', '618_*_版本', '版本_*_lol', 'lol_*_更新', '将夜', '桌游', '碟影', '重重', '桌游_*_碟影', '碟影_*_重重', '炉石', '传说', '吧', '炉石_*_传说', '传说_*_吧', '\"', '一个', '男人', '握', '着', '加温', '的', '酒', ',', '有', '整片', '星空', '和', '一只', '老', '\"_*_一个', '一个_*_男人', '男人_*_握', '握_*_着', '着_*_加温', '加温_*_的', '的_*_酒', '酒_*_,', ',_*_有', '有_*_整片', '整片_*_星空', '星空_*_和', '和_*_一只', '一只_*_老', '维多利亚', '的', '秘密', '歌词', '维多利亚_*_的', '的_*_秘密', '秘密_*_歌词', '黑人', '乔治', '黑人_*_乔治', '寄生兽', '电影', '影评', '寄生兽_*_电影', '电影_*_影评', '十年', '歌词', '十年_*_歌词', '地下', '城堡', '2', '囚徒', '之塔', '钥匙', '地下_*_城堡', '城堡_*_2', '2_*_囚徒', '囚徒_*_之塔', '之塔_*_钥匙', '单美仙', '百度', '百科', '单美仙_*_百度', '百度_*_百科', '许嵩', '天干', '物燥', '许嵩_*_天干', '天干_*_物燥', '寄生兽', '定妆', '照', '寄生兽_*_定妆', '定妆_*_照', '樱花', '草', '歌词', '樱花_*_草', '草_*_歌词', 'lol6.18', '版本', '更新', '内容', 'lol6.18_*_版本', '版本_*_更新', '更新_*_内容', '幻想', '乡', '初代博丽', '幻想_*_乡', '乡_*_初代博丽', '快乐', '时光', '影城', '今日', '影讯', '快乐_*_时光', '时光_*_影城', '影城_*_今日', '今日_*_影讯', '真三国', '无双', '7', '猛将传', '樊城', '之战', '真三国_*_无双', '无双_*_7', '7_*_猛将传', '猛将传_*_樊城', '樊城_*_之战', '面基', 'ae86', '火影忍者', '黑人', '乔治', '火影忍者_*_黑人', '黑人_*_乔治', '甲午', '崛起', '甲午_*_崛起', '《', '大唐', '双龙传', '之', '重生', '边', '不负', '《_*_大唐', '大唐_*_双龙传', '双龙传_*_之', '之_*_重生', '重生_*_边', '边_*_不负', '他', '把', '纪录片', '放', '给', '老人', '看', ',', '这', '盛世', '如你所愿', '他_*_把', '把_*_纪录片', '纪录片_*_放', '放_*_给', '给_*_老人', '老人_*_看', '看_*_,', ',_*_这', '这_*_盛世', '盛世_*_如你所愿', 'lm', '第五', '季', 'lm_*_第五', '第五_*_季', '我', '的', '大', '宝剑', '学霸', '殿下', '我_*_的', '的_*_大', '大_*_宝剑', '宝剑_*_学霸', '学霸_*_殿下', '二尾', '无双', '大蛇', 'z', '发现', '重要', '物品', '无双_*_大蛇', '大蛇_*_z', 'z_*_发现', '发现_*_重要', '重要_*_物品', '南', '山南', '南_*_山南', '童年', '歌词', '童年_*_歌词', '情非得已', '歌词', '情非得已_*_歌词', '这', '盛世', '如你所愿', '这_*_盛世', '盛世_*_如你所愿', '东华', '理工大学', '东华_*_理工大学', '丑八怪', '歌词', '丑八怪_*_歌词', '牧昏者', '约', '里克', '牧昏者_*_约', '约_*_里克', '卡拉', '赞之夜', '彩蛋', '卡拉_*_赞之夜', '赞之夜_*_彩蛋', '真三国', '无双', '7', '猛将传', '吕布', '传', 'if', '真三国_*_无双', '无双_*_7', '7_*_猛将传', '猛将传_*_吕布', '吕布_*_传', '传_*_if', '自在门', '千智', '风声', '千智_*_风声', '无双', '大蛇', 'z', '吴', '第四', '关', '逃脱', '地点', '无双_*_大蛇', '大蛇_*_z', 'z_*_吴', '吴_*_第四', '第四_*_关', '关_*_逃脱', '逃脱_*_地点', '+', '1s', '+_*_1s', '90', '小游戏', '90_*_小游戏', '快乐', '时光', '影院', '影讯', '快乐_*_时光', '时光_*_影院', '影院_*_影讯', '一夜', '终极', '狼人', '一夜_*_终极', '终极_*_狼人', '择天', '记周', '独夫', '择天_*_记周', '记周_*_独夫', '三鞭', '道', '三鞭_*_道', '话', '说', '我', '的', '房间', '是', 'c', '栋', '3', '楼', '呢', '话_*_说', '说_*_我', '我_*_的', '的_*_房间', '房间_*_是', '是_*_c', 'c_*_栋', '栋_*_3', '3_*_楼', '楼_*_呢', '夏一', '可', '的', '未来', '夫君', '夏一_*_可', '可_*_的', '的_*_未来', '未来_*_夫君', '绅士', '歌词', '绅士_*_歌词', 'x1', '李', '沉舟', '李_*_沉舟', '真三国', '无双', '7', '猛将传', '吕不传', '看不到', '结局', '真三国_*_无双', '无双_*_7', '7_*_猛将传', '猛将传_*_吕不传', '吕不传_*_看不到', '看不到_*_结局', '曹宁陆', '文龙', '曹宁陆_*_文龙', '真三国', '无双', '7', '猛将传', '真三国_*_无双', '无双_*_7', '7_*_猛将传', '择天记', '周独', '副', '择天记_*_周独', '周独_*_副', '战网', 'gamesofdesire', '.', 'com', 'gamesofdesire_*_.', '._*_com', '618', '版本', 'lol', '618_*_版本', '版本_*_lol', '你', '的', '名字', '你_*_的', '的_*_名字', '随身', '炉石', '传说', '随身_*_炉石', '炉石_*_传说', '单美仙', '讨论组', '和', '群有', '什么', '区别', '讨论组_*_和', '和_*_群有', '群有_*_什么', '什么_*_区别', '巨人', '导演', '德', '巨人_*_导演', '导演_*_德', '甲午', '崛起', 'txt', '下载', '甲午_*_崛起', '崛起_*_txt', 'txt_*_下载', '炉石', '传说', '双人', '现', '开赛', '炉石_*_传说', '传说_*_双人', '双人_*_现', '现_*_开赛', '当', '歌词', '当_*_歌词', '森近霖', '之助', '和', '犬夜叉', '森近霖_*_之助', '之助_*_和', '和_*_犬夜叉', '阿尔托', '莉雅', '阿尔托_*_莉雅', '秋', '名山', '上', '行人', '稀', ' ', '图', '秋_*_名山', '名山_*_上', '上_*_行人', '行人_*_稀', '稀_*_ ', ' _*_图', 'qq', '邮箱', 'qq_*_邮箱', '天津', '教案', '天津_*_教案', '四季', '映姬', '四季_*_映姬', '狼人', '杀白', '狼', '狼人_*_杀白', '杀白_*_狼', '大宋', '提刑官', '大宋_*_提刑官', '剑娘', '战神', '录', '战神_*_录', '如果', '人类', '人口', '变为', '一半', '如果_*_人类', '人类_*_人口', '人口_*_变为', '变为_*_一半', '折木奉', '太郎', '的', '名言', '折木奉_*_太郎', '太郎_*_的', '的_*_名言', '真三国', '无双', '7', '猛将传', '陈仓', '之战', '图文', '真三国_*_无双', '无双_*_7', '7_*_猛将传', '猛将传_*_陈仓', '陈仓_*_之战', '之战_*_图文', 'exo', ' ', 'me', '什么', '意思', 'exo_*_ ', ' _*_me', 'me_*_什么', '什么_*_意思', '我', '真是', '大', '明星', '我_*_真是', '真是_*_大', '大_*_明星', '限', '韩令', '限_*_韩令', '狼人', '杀', '狼', '兄狼弟', '狼人_*_杀', '杀_*_狼', '狼_*_兄狼弟', '超神', '师兄', '超神_*_师兄', '择天记', '起点', '择天记_*_起点', '电竞', 'bbc', '电竞_*_bbc', '鞭', '道人', '鞭_*_道人', '创', '界山', '创_*_界山', '电视剧', '一寸', '山河', '一寸', '血', '电视剧_*_一寸', '一寸_*_山河', '山河_*_一寸', '一寸_*_血', 'fate', '斯', '卡哈', '本子', 'fate_*_斯', '斯_*_卡哈', '卡哈_*_本子', '三坟五典', '八索', '九丘', '三坟五典_*_八索', '八索_*_九丘', '四大', '天王', '有', '五个', '四大_*_天王', '天王_*_有', '有_*_五个', '陈', '长生', '陈_*_长生', 'bigbang', '歌词', 'bigbang_*_歌词', '英雄', '联盟', '英雄_*_联盟', '火影', '之', '幻想', '乡大', '弟子', '火影_*_之', '之_*_幻想', '幻想_*_乡大', '乡大_*_弟子', '真三国', '无双', '7', '猛将传', '吴国', 'if', '真三国_*_无双', '无双_*_7', '7_*_猛将传', '猛将传_*_吴国', '吴国_*_if', '真三国', '无双', '7', '猛将传', '真', '无双', '乱舞', '真三国_*_无双', '无双_*_7', '7_*_猛将传', '猛将传_*_真', '真_*_无双', '无双_*_乱舞', '铁十郎', 'lm', '第五', '季', '第一集', 'lm_*_第五', '第五_*_季', '季_*_第一集', 'qq', '怎么', '设置', '红包', '提醒', 'qq_*_怎么', '怎么_*_设置', '设置_*_红包', '红包_*_提醒', '八百里', '开外', '一枪', '干掉', '鬼子', '机枪手', '八百里_*_开外', '开外_*_一枪', '一枪_*_干掉', '干掉_*_鬼子', '鬼子_*_机枪手', '桌游', '情书', '桌游_*_情书', '何休', '剑', '公子', '何休_*_剑', '剑_*_公子', '铁十郎', '百度', '百科', '铁十郎_*_百度', '百度_*_百科', '儒道', '至圣', '儒道_*_至圣', '我家', 'wifi', '信号', '一闪', '一闪', '我家_*_wifi', 'wifi_*_信号', '信号_*_一闪', '一闪_*_一闪', '云隐村', '的', '黑人', '乔治', '云隐村_*_的', '的_*_黑人', '黑人_*_乔治', 'v', '字', '仇杀', '队', 'v_*_字', '字_*_仇杀', '仇杀_*_队', '女装', '山脉', '女装_*_山脉', '这', '盛世', '如你所愿', '作文', '这_*_盛世', '盛世_*_如你所愿', '如你所愿_*_作文', '狼人', '杀白', '狼', '第几天', '开始', '可以', '刀人', '狼人_*_杀白', '杀白_*_狼', '狼_*_第几天', '第几天_*_开始', '开始_*_可以', '可以_*_刀人', '步步为营', '规则', '步步为营_*_规则', '中国建设银行', 'app', '下载', '中国建设银行_*_app', 'app_*_下载', '搜狗', '小说', '进不去', '搜狗_*_小说', '小说_*_进不去', '真三国', '无双', '7', '猛将传', '援助', '武将', '真三国_*_无双', '无双_*_7', '7_*_猛将传', '猛将传_*_援助', '援助_*_武将', '真三国', '无双', '真三国_*_无双', '魔兽', '世界', '魔兽_*_世界', '炉石', '传说', '打麻克', '扎尔', '王子', '用', '牺牲', '契约', '炉石_*_传说', '传说_*_打麻克', '打麻克_*_扎尔', '扎尔_*_王子', '王子_*_用', '用_*_牺牲', '牺牲_*_契约', '寄生兽', '开头', '寄生兽_*_开头', '火影', '红豆', '结局', '火影_*_红豆', '红豆_*_结局', '韩娱', '我', '的', '外星', '女友', '韩娱_*_我', '我_*_的', '的_*_外星', '外星_*_女友', '一股', '清流', '什么', '意思', '一股_*_清流', '清流_*_什么', '什么_*_意思', '我', '一穷二白', '却', '有', '三妻四妾', '我_*_一穷二白', '一穷二白_*_却', '却_*_有', '有_*_三妻四妾', '寄生兽', '守望', '先锋', '把', '球', '打进', '篮筐', '守望_*_先锋', '先锋_*_把', '把_*_球', '球_*_打进', '打进_*_篮筐', '隙间', '罪袋', '英雄', '23', '号', '隙间_*_罪袋', '罪袋_*_英雄', '英雄_*_23', '23_*_号', '寄生兽', '开头', '的', '那句话', '寄生兽_*_开头', '开头_*_的', '的_*_那句话', '寄生兽', '真人版', '开篇', '语句', '寄生兽_*_真人版', '真人版_*_开篇', '开篇_*_语句', '剑娘', 'txt', '下载', '剑娘_*_txt', 'txt_*_下载', '真三国', '无双', '7', '猛将传', '护卫', '支援', '真三国_*_无双', '无双_*_7', '7_*_猛将传', '猛将传_*_护卫', '护卫_*_支援', '小', '九尾', '人柱力', '小_*_九尾', '九尾_*_人柱力', '微微一笑', '很', '倾城', '微微一笑_*_很', '很_*_倾城', '白色', '相簿', '百度', '百科', '白色_*_相簿', '相簿_*_百度', '百度_*_百科', '怎么', '把', '群', '退回', '讨论组', '\\r\\n', '怎么_*_把', '把_*_群', '群_*_退回', '退回_*_讨论组', '讨论组_*_\\r\\n']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000\n",
      "30000\n",
      "40000\n",
      "50000\n",
      "60000\n",
      "70000\n",
      "80000\n",
      "90000\n",
      "100000\n"
     ]
    }
   ],
   "source": [
    "'''tfidf-lr stack for education/age/gender'''\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import jieba\n",
    "import pickle\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cross_validation import KFold\n",
    "from datetime import datetime\n",
    "import cfg\n",
    "\n",
    "#-----------------------myfunc-----------------------\n",
    "def myAcc(y_true,y_pred):\n",
    "    y_pred = np.argmax(y_pred,axis=1)\n",
    "    return np.mean(y_true == y_pred)\n",
    "#-----------------------load data--------------------\n",
    "\n",
    "df_all = pd.read_csv(cfg.data_path + 'all_v2.csv',encoding='utf8',nrows=100000)\n",
    "ys = {}\n",
    "for label in ['Education','age','gender']:\n",
    "    ys[label] = np.array(df_all[label])\n",
    "\n",
    "class Tokenizer():\n",
    "    def __init__(self):\n",
    "        self.n = 0\n",
    "    def __call__(self,line):\n",
    "        tokens = []\n",
    "        for query in line.split('\\t'):\n",
    "            words = [word for word in jieba.cut(query)]\n",
    "            for gram in [1,2]:\n",
    "                for i in range(len(words) - gram + 1):\n",
    "                    tokens += [\"_*_\".join(words[i:i+gram])]\n",
    "        if np.random.rand() < 0.00001:\n",
    "            print(line)\n",
    "            print('='*20)\n",
    "            print(tokens)\n",
    "        self.n += 1\n",
    "        if self.n%10000==0:\n",
    "            print(self.n)\n",
    "        return tokens\n",
    "\n",
    "tfv = TfidfVectorizer(tokenizer=Tokenizer(),min_df=3,max_df=0.95,sublinear_tf=True)\n",
    "X_sp = tfv.fit_transform(df_all['query'])\n",
    "pickle.dump(X_sp,open(cfg.data_path + 'tfidf_10W.feat','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Education\n",
      "2018-09-18 22:16:03.477516 stack:1/5\n",
      "va acc: 0.66125\n",
      "te acc: 0.6602\n",
      "2018-09-18 22:17:47.015585 stack:2/5\n",
      "va acc: 0.6554375\n",
      "te acc: 0.65835\n",
      "2018-09-18 22:19:25.816432 stack:3/5\n",
      "va acc: 0.65325\n",
      "te acc: 0.65775\n",
      "2018-09-18 22:21:02.842497 stack:4/5\n",
      "va acc: 0.65475\n",
      "te acc: 0.65995\n",
      "2018-09-18 22:22:35.819534 stack:5/5\n",
      "va acc: 0.656125\n",
      "te acc: 0.66155\n",
      "age\n",
      "2018-09-18 22:24:08.836014 stack:1/5\n",
      "va acc: 0.6038125\n",
      "te acc: 0.6045\n",
      "2018-09-18 22:25:52.097786 stack:2/5\n",
      "va acc: 0.5934375\n",
      "te acc: 0.60335\n",
      "2018-09-18 22:27:37.722266 stack:3/5\n",
      "va acc: 0.6003125\n",
      "te acc: 0.6023\n",
      "2018-09-18 22:29:23.797412 stack:4/5\n",
      "va acc: 0.599375\n",
      "te acc: 0.6025\n",
      "2018-09-18 22:31:12.819629 stack:5/5\n",
      "va acc: 0.60325\n",
      "te acc: 0.60355\n",
      "gender\n",
      "2018-09-18 22:33:05.620973 stack:1/5\n",
      "va acc: 0.8335\n",
      "te acc: 0.8304\n",
      "2018-09-18 22:33:22.806322 stack:2/5\n",
      "va acc: 0.8331875\n",
      "te acc: 0.83385\n",
      "2018-09-18 22:33:39.735261 stack:3/5\n",
      "va acc: 0.83075\n",
      "te acc: 0.8332\n",
      "2018-09-18 22:33:56.522526 stack:4/5\n",
      "va acc: 0.833625\n",
      "te acc: 0.83275\n",
      "2018-09-18 22:34:13.225000 stack:5/5\n",
      "va acc: 0.8375\n",
      "te acc: 0.83135\n",
      "2018-09-18 22:34:31.916430 save tfidf stack done!\n"
     ]
    }
   ],
   "source": [
    "df_stack = pd.DataFrame(index=range(len(df_all)))\n",
    "\n",
    "# -----------------------stack for education/age/gender------------------\n",
    "for lb in ['Education','age','gender']:\n",
    "    print(lb)\n",
    "    TR = 80000\n",
    "    num_class = len(pd.value_counts(ys[lb]))\n",
    "    n = 5\n",
    "\n",
    "    X = X_sp[:TR]\n",
    "    y = ys[lb][:TR]\n",
    "    X_te = X_sp[TR:]\n",
    "    y_te = ys[lb][TR:]\n",
    "\n",
    "    stack = np.zeros((X.shape[0],num_class))\n",
    "    stack_te = np.zeros((X_te.shape[0],num_class))\n",
    "\n",
    "    for i,(tr,va) in enumerate(KFold(len(y),n_folds=n)):\n",
    "        print('%s stack:%d/%d'%(str(datetime.now()),i+1,n))\n",
    "        clf = LogisticRegression(C=3)\n",
    "        clf.fit(X[tr],y[tr])\n",
    "        y_pred_va = clf.predict_proba(X[va])\n",
    "        y_pred_te = clf.predict_proba(X_te)\n",
    "        print('va acc:',myAcc(y[va],y_pred_va))\n",
    "        print('te acc:',myAcc(y_te,y_pred_te))\n",
    "        stack[va] += y_pred_va\n",
    "        stack_te += y_pred_te\n",
    "    stack_te /= n\n",
    "    stack_all = np.vstack([stack,stack_te])\n",
    "    for i in range(stack_all.shape[1]):\n",
    "        df_stack['tfidf_{}_{}'.format(lb,i)] = stack_all[:,i]\n",
    "\n",
    "df_stack.to_csv(cfg.data_path + 'tfidf_stack_10W.csv',index=None,encoding='utf8')\n",
    "print(datetime.now(),'save tfidf stack done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sun\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "'''dbow-nn stack for education/age/gender'''\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from sklearn.cross_validation import KFold\n",
    "from gensim.models import Doc2Vec\n",
    "from collections import OrderedDict\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.optimizers import SGD, Adam, RMSprop\n",
    "from keras.utils import np_utils\n",
    "import re\n",
    "import cfg\n",
    "\n",
    "# ----------------------- myfunc -----------------------\n",
    "def myAcc(y_true,y_pred):\n",
    "    y_pred = np.argmax(y_pred,axis=1)\n",
    "    return np.mean(y_true == y_pred)\n",
    "\n",
    "# ----------------------- load dataset ----------------------\n",
    "df_all = pd.read_csv(cfg.data_path + 'all_v2.csv',encoding='utf8',usecols=['Id','Education','age','gender'],nrows=100000)\n",
    "ys = {}\n",
    "for label in ['Education','age','gender']:\n",
    "    ys[label] = np.array(df_all[label])\n",
    "    \n",
    "model = Doc2Vec.load(cfg.data_path + 'dbow_d2v.model')\n",
    "X_sp = np.array([model.docvecs[i] for i in range(100000)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-09-18 22:44:08.239094 stack:1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sun\\Anaconda3\\lib\\site-packages\\keras\\models.py:942: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 64000 samples, validate on 20000 samples\n",
      "Epoch 1/35\n",
      " - 2s - loss: 0.9744 - acc: 0.6160 - val_loss: 0.9322 - val_acc: 0.6353\n",
      "Epoch 2/35\n",
      " - 1s - loss: 0.9409 - acc: 0.6296 - val_loss: 0.9270 - val_acc: 0.6355\n",
      "Epoch 3/35\n",
      " - 1s - loss: 0.9314 - acc: 0.6354 - val_loss: 0.9288 - val_acc: 0.6369\n",
      "Epoch 4/35\n",
      " - 1s - loss: 0.9236 - acc: 0.6376 - val_loss: 0.9201 - val_acc: 0.6401\n",
      "Epoch 5/35\n",
      " - 1s - loss: 0.9171 - acc: 0.6395 - val_loss: 0.9164 - val_acc: 0.6408\n",
      "Epoch 6/35\n",
      " - 1s - loss: 0.9098 - acc: 0.6436 - val_loss: 0.9123 - val_acc: 0.6440\n",
      "Epoch 7/35\n",
      " - 1s - loss: 0.9051 - acc: 0.6434 - val_loss: 0.9181 - val_acc: 0.6414\n",
      "Epoch 8/35\n",
      " - 1s - loss: 0.8997 - acc: 0.6466 - val_loss: 0.9133 - val_acc: 0.6448\n",
      "Epoch 9/35\n",
      " - 1s - loss: 0.8962 - acc: 0.6486 - val_loss: 0.9102 - val_acc: 0.6448\n",
      "Epoch 10/35\n",
      " - 1s - loss: 0.8909 - acc: 0.6500 - val_loss: 0.9119 - val_acc: 0.6443\n",
      "Epoch 11/35\n",
      " - 1s - loss: 0.8884 - acc: 0.6522 - val_loss: 0.9069 - val_acc: 0.6474\n",
      "Epoch 12/35\n",
      " - 2s - loss: 0.8822 - acc: 0.6526 - val_loss: 0.9143 - val_acc: 0.6471\n",
      "Epoch 13/35\n",
      " - 1s - loss: 0.8797 - acc: 0.6548 - val_loss: 0.9176 - val_acc: 0.6414\n",
      "Epoch 14/35\n",
      " - 1s - loss: 0.8753 - acc: 0.6580 - val_loss: 0.9053 - val_acc: 0.6461\n",
      "Epoch 15/35\n",
      " - 1s - loss: 0.8712 - acc: 0.6583 - val_loss: 0.9062 - val_acc: 0.6470\n",
      "Epoch 16/35\n",
      " - 1s - loss: 0.8684 - acc: 0.6597 - val_loss: 0.9058 - val_acc: 0.6484\n",
      "Epoch 17/35\n",
      " - 1s - loss: 0.8636 - acc: 0.6622 - val_loss: 0.9072 - val_acc: 0.6469\n",
      "Epoch 18/35\n",
      " - 1s - loss: 0.8594 - acc: 0.6635 - val_loss: 0.9110 - val_acc: 0.6467\n",
      "Epoch 19/35\n",
      " - 1s - loss: 0.8553 - acc: 0.6672 - val_loss: 0.9111 - val_acc: 0.6456\n",
      "Epoch 20/35\n",
      " - 1s - loss: 0.8508 - acc: 0.6667 - val_loss: 0.9092 - val_acc: 0.6462\n",
      "Epoch 21/35\n",
      " - 1s - loss: 0.8456 - acc: 0.6682 - val_loss: 0.9124 - val_acc: 0.6471\n",
      "Epoch 22/35\n",
      " - 1s - loss: 0.8404 - acc: 0.6709 - val_loss: 0.9117 - val_acc: 0.6457\n",
      "Epoch 23/35\n",
      " - 1s - loss: 0.8351 - acc: 0.6728 - val_loss: 0.9199 - val_acc: 0.6473\n",
      "Epoch 24/35\n",
      " - 1s - loss: 0.8304 - acc: 0.6751 - val_loss: 0.9159 - val_acc: 0.6470\n",
      "Epoch 25/35\n",
      " - 1s - loss: 0.8257 - acc: 0.6767 - val_loss: 0.9244 - val_acc: 0.6459\n",
      "Epoch 26/35\n",
      " - 1s - loss: 0.8192 - acc: 0.6789 - val_loss: 0.9225 - val_acc: 0.6422\n",
      "Epoch 27/35\n",
      " - 1s - loss: 0.8144 - acc: 0.6808 - val_loss: 0.9248 - val_acc: 0.6438\n",
      "Epoch 28/35\n",
      " - 1s - loss: 0.8076 - acc: 0.6849 - val_loss: 0.9267 - val_acc: 0.6425\n",
      "Epoch 29/35\n",
      " - 1s - loss: 0.8028 - acc: 0.6844 - val_loss: 0.9302 - val_acc: 0.6392\n",
      "Epoch 30/35\n",
      " - 1s - loss: 0.7951 - acc: 0.6892 - val_loss: 0.9403 - val_acc: 0.6418\n",
      "Epoch 31/35\n",
      " - 1s - loss: 0.7896 - acc: 0.6923 - val_loss: 0.9408 - val_acc: 0.6388\n",
      "Epoch 32/35\n",
      " - 1s - loss: 0.7830 - acc: 0.6925 - val_loss: 0.9552 - val_acc: 0.6402\n",
      "Epoch 33/35\n",
      " - 1s - loss: 0.7773 - acc: 0.6959 - val_loss: 0.9445 - val_acc: 0.6388\n",
      "Epoch 34/35\n",
      " - 1s - loss: 0.7700 - acc: 0.7011 - val_loss: 0.9543 - val_acc: 0.6341\n",
      "Epoch 35/35\n",
      " - 1s - loss: 0.7617 - acc: 0.7026 - val_loss: 0.9510 - val_acc: 0.6348\n",
      "va acc: 0.6335\n",
      "te acc: 0.63475\n",
      "2018-09-18 22:44:59.429920 stack:2/5\n",
      "Train on 64000 samples, validate on 20000 samples\n",
      "Epoch 1/35\n",
      " - 1s - loss: 0.9709 - acc: 0.6166 - val_loss: 0.9377 - val_acc: 0.6349\n",
      "Epoch 2/35\n",
      " - 1s - loss: 0.9383 - acc: 0.6309 - val_loss: 0.9443 - val_acc: 0.6255\n",
      "Epoch 3/35\n",
      " - 1s - loss: 0.9262 - acc: 0.6342 - val_loss: 0.9275 - val_acc: 0.6353\n",
      "Epoch 4/35\n",
      " - 1s - loss: 0.9180 - acc: 0.6384 - val_loss: 0.9283 - val_acc: 0.6367\n",
      "Epoch 5/35\n",
      " - 1s - loss: 0.9107 - acc: 0.6417 - val_loss: 0.9289 - val_acc: 0.6324\n",
      "Epoch 6/35\n",
      " - 1s - loss: 0.9056 - acc: 0.6428 - val_loss: 0.9154 - val_acc: 0.6419\n",
      "Epoch 7/35\n",
      " - 1s - loss: 0.9005 - acc: 0.6456 - val_loss: 0.9124 - val_acc: 0.6419\n",
      "Epoch 8/35\n",
      " - 1s - loss: 0.8948 - acc: 0.6475 - val_loss: 0.9073 - val_acc: 0.6464\n",
      "Epoch 9/35\n",
      " - 1s - loss: 0.8903 - acc: 0.6485 - val_loss: 0.9097 - val_acc: 0.6455\n",
      "Epoch 10/35\n",
      " - 1s - loss: 0.8856 - acc: 0.6519 - val_loss: 0.9050 - val_acc: 0.6467\n",
      "Epoch 11/35\n",
      " - 1s - loss: 0.8832 - acc: 0.6520 - val_loss: 0.9111 - val_acc: 0.6475\n",
      "Epoch 12/35\n",
      " - 1s - loss: 0.8779 - acc: 0.6542 - val_loss: 0.9086 - val_acc: 0.6456\n",
      "Epoch 13/35\n",
      " - 1s - loss: 0.8741 - acc: 0.6563 - val_loss: 0.9115 - val_acc: 0.6470\n",
      "Epoch 14/35\n",
      " - 1s - loss: 0.8702 - acc: 0.6590 - val_loss: 0.9120 - val_acc: 0.6460\n",
      "Epoch 15/35\n",
      " - 1s - loss: 0.8682 - acc: 0.6589 - val_loss: 0.9069 - val_acc: 0.6471\n",
      "Epoch 16/35\n",
      " - 1s - loss: 0.8630 - acc: 0.6602 - val_loss: 0.9091 - val_acc: 0.6466\n",
      "Epoch 17/35\n",
      " - 1s - loss: 0.8598 - acc: 0.6626 - val_loss: 0.9044 - val_acc: 0.6487\n",
      "Epoch 18/35\n",
      " - 1s - loss: 0.8551 - acc: 0.6635 - val_loss: 0.9107 - val_acc: 0.6455\n",
      "Epoch 19/35\n",
      " - 1s - loss: 0.8514 - acc: 0.6667 - val_loss: 0.9109 - val_acc: 0.6491\n",
      "Epoch 20/35\n",
      " - 1s - loss: 0.8467 - acc: 0.6674 - val_loss: 0.9154 - val_acc: 0.6486\n",
      "Epoch 21/35\n",
      " - 1s - loss: 0.8420 - acc: 0.6695 - val_loss: 0.9086 - val_acc: 0.6464\n",
      "Epoch 22/35\n",
      " - 1s - loss: 0.8377 - acc: 0.6729 - val_loss: 0.9193 - val_acc: 0.6432\n",
      "Epoch 23/35\n",
      " - 1s - loss: 0.8326 - acc: 0.6743 - val_loss: 0.9323 - val_acc: 0.6408\n",
      "Epoch 24/35\n",
      " - 1s - loss: 0.8286 - acc: 0.6746 - val_loss: 0.9178 - val_acc: 0.6431\n",
      "Epoch 25/35\n",
      " - 1s - loss: 0.8248 - acc: 0.6791 - val_loss: 0.9250 - val_acc: 0.6417\n",
      "Epoch 26/35\n",
      " - 1s - loss: 0.8177 - acc: 0.6798 - val_loss: 0.9203 - val_acc: 0.6454\n",
      "Epoch 27/35\n",
      " - 1s - loss: 0.8122 - acc: 0.6819 - val_loss: 0.9257 - val_acc: 0.6444\n",
      "Epoch 28/35\n",
      " - 1s - loss: 0.8076 - acc: 0.6848 - val_loss: 0.9269 - val_acc: 0.6442\n",
      "Epoch 29/35\n",
      " - 1s - loss: 0.8021 - acc: 0.6867 - val_loss: 0.9275 - val_acc: 0.6442\n",
      "Epoch 30/35\n",
      " - 1s - loss: 0.7952 - acc: 0.6889 - val_loss: 0.9323 - val_acc: 0.6459\n",
      "Epoch 31/35\n",
      " - 1s - loss: 0.7902 - acc: 0.6914 - val_loss: 0.9366 - val_acc: 0.6414\n",
      "Epoch 32/35\n",
      " - 1s - loss: 0.7830 - acc: 0.6945 - val_loss: 0.9418 - val_acc: 0.6373\n",
      "Epoch 33/35\n",
      " - 1s - loss: 0.7752 - acc: 0.6953 - val_loss: 0.9420 - val_acc: 0.6413\n",
      "Epoch 34/35\n",
      " - 1s - loss: 0.7715 - acc: 0.6970 - val_loss: 0.9503 - val_acc: 0.6356\n",
      "Epoch 35/35\n",
      " - 1s - loss: 0.7632 - acc: 0.7018 - val_loss: 0.9615 - val_acc: 0.6355\n",
      "va acc: 0.637125\n",
      "te acc: 0.6355\n",
      "2018-09-18 22:45:48.934218 stack:3/5\n",
      "Train on 64000 samples, validate on 20000 samples\n",
      "Epoch 1/35\n",
      " - 1s - loss: 0.9707 - acc: 0.6166 - val_loss: 0.9441 - val_acc: 0.6290\n",
      "Epoch 2/35\n",
      " - 1s - loss: 0.9384 - acc: 0.6330 - val_loss: 0.9296 - val_acc: 0.6353\n",
      "Epoch 3/35\n",
      " - 1s - loss: 0.9278 - acc: 0.6358 - val_loss: 0.9209 - val_acc: 0.6405\n",
      "Epoch 4/35\n",
      " - 1s - loss: 0.9205 - acc: 0.6393 - val_loss: 0.9169 - val_acc: 0.6436\n",
      "Epoch 5/35\n",
      " - 1s - loss: 0.9122 - acc: 0.6419 - val_loss: 0.9162 - val_acc: 0.6433\n",
      "Epoch 6/35\n",
      " - 1s - loss: 0.9060 - acc: 0.6435 - val_loss: 0.9125 - val_acc: 0.6425\n",
      "Epoch 7/35\n",
      " - 1s - loss: 0.9001 - acc: 0.6451 - val_loss: 0.9133 - val_acc: 0.6434\n",
      "Epoch 8/35\n",
      " - 1s - loss: 0.8958 - acc: 0.6496 - val_loss: 0.9079 - val_acc: 0.6468\n",
      "Epoch 9/35\n",
      " - 1s - loss: 0.8915 - acc: 0.6506 - val_loss: 0.9045 - val_acc: 0.6468\n",
      "Epoch 10/35\n",
      " - 1s - loss: 0.8864 - acc: 0.6518 - val_loss: 0.9100 - val_acc: 0.6446\n",
      "Epoch 11/35\n",
      " - 1s - loss: 0.8837 - acc: 0.6546 - val_loss: 0.9056 - val_acc: 0.6484\n",
      "Epoch 12/35\n",
      " - 1s - loss: 0.8789 - acc: 0.6554 - val_loss: 0.9139 - val_acc: 0.6434\n",
      "Epoch 13/35\n",
      " - 1s - loss: 0.8760 - acc: 0.6566 - val_loss: 0.9098 - val_acc: 0.6462\n",
      "Epoch 14/35\n",
      " - 1s - loss: 0.8724 - acc: 0.6591 - val_loss: 0.9043 - val_acc: 0.6492\n",
      "Epoch 15/35\n",
      " - 1s - loss: 0.8691 - acc: 0.6586 - val_loss: 0.9040 - val_acc: 0.6489\n",
      "Epoch 16/35\n",
      " - 1s - loss: 0.8649 - acc: 0.6600 - val_loss: 0.9090 - val_acc: 0.6450\n",
      "Epoch 17/35\n",
      " - 1s - loss: 0.8614 - acc: 0.6618 - val_loss: 0.9094 - val_acc: 0.6464\n",
      "Epoch 18/35\n",
      " - 1s - loss: 0.8579 - acc: 0.6639 - val_loss: 0.9068 - val_acc: 0.6466\n",
      "Epoch 19/35\n",
      " - 1s - loss: 0.8533 - acc: 0.6672 - val_loss: 0.9132 - val_acc: 0.6452\n",
      "Epoch 20/35\n",
      " - 1s - loss: 0.8492 - acc: 0.6682 - val_loss: 0.9097 - val_acc: 0.6477\n",
      "Epoch 21/35\n",
      " - 1s - loss: 0.8442 - acc: 0.6702 - val_loss: 0.9128 - val_acc: 0.6454\n",
      "Epoch 22/35\n",
      " - 1s - loss: 0.8406 - acc: 0.6700 - val_loss: 0.9184 - val_acc: 0.6468\n",
      "Epoch 23/35\n",
      " - 1s - loss: 0.8359 - acc: 0.6714 - val_loss: 0.9164 - val_acc: 0.6482\n",
      "Epoch 24/35\n",
      " - 1s - loss: 0.8310 - acc: 0.6743 - val_loss: 0.9169 - val_acc: 0.6459\n",
      "Epoch 25/35\n",
      " - 1s - loss: 0.8273 - acc: 0.6770 - val_loss: 0.9253 - val_acc: 0.6433\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/35\n",
      " - 1s - loss: 0.8222 - acc: 0.6786 - val_loss: 0.9182 - val_acc: 0.6461\n",
      "Epoch 27/35\n",
      " - 1s - loss: 0.8171 - acc: 0.6803 - val_loss: 0.9264 - val_acc: 0.6473\n",
      "Epoch 28/35\n",
      " - 1s - loss: 0.8118 - acc: 0.6831 - val_loss: 0.9274 - val_acc: 0.6441\n",
      "Epoch 29/35\n",
      " - 1s - loss: 0.8053 - acc: 0.6845 - val_loss: 0.9262 - val_acc: 0.6451\n",
      "Epoch 30/35\n",
      " - 1s - loss: 0.8025 - acc: 0.6876 - val_loss: 0.9285 - val_acc: 0.6466\n",
      "Epoch 31/35\n",
      " - 1s - loss: 0.7949 - acc: 0.6889 - val_loss: 0.9362 - val_acc: 0.6397\n",
      "Epoch 32/35\n",
      " - 1s - loss: 0.7879 - acc: 0.6922 - val_loss: 0.9377 - val_acc: 0.6429\n",
      "Epoch 33/35\n",
      " - 1s - loss: 0.7844 - acc: 0.6935 - val_loss: 0.9416 - val_acc: 0.6437\n",
      "Epoch 34/35\n",
      " - 1s - loss: 0.7784 - acc: 0.6958 - val_loss: 0.9474 - val_acc: 0.6380\n",
      "Epoch 35/35\n",
      " - 1s - loss: 0.7704 - acc: 0.6987 - val_loss: 0.9438 - val_acc: 0.6393\n",
      "va acc: 0.63875\n",
      "te acc: 0.6393\n",
      "2018-09-18 22:46:38.383836 stack:4/5\n",
      "Train on 64000 samples, validate on 20000 samples\n",
      "Epoch 1/35\n",
      " - 2s - loss: 0.9706 - acc: 0.6171 - val_loss: 0.9369 - val_acc: 0.6292\n",
      "Epoch 2/35\n",
      " - 1s - loss: 0.9385 - acc: 0.6307 - val_loss: 0.9364 - val_acc: 0.6298\n",
      "Epoch 3/35\n",
      " - 1s - loss: 0.9288 - acc: 0.6334 - val_loss: 0.9248 - val_acc: 0.6392\n",
      "Epoch 4/35\n",
      " - 1s - loss: 0.9207 - acc: 0.6381 - val_loss: 0.9175 - val_acc: 0.6412\n",
      "Epoch 5/35\n",
      " - 1s - loss: 0.9136 - acc: 0.6413 - val_loss: 0.9176 - val_acc: 0.6424\n",
      "Epoch 6/35\n",
      " - 1s - loss: 0.9083 - acc: 0.6431 - val_loss: 0.9171 - val_acc: 0.6409\n",
      "Epoch 7/35\n",
      " - 1s - loss: 0.9020 - acc: 0.6443 - val_loss: 0.9110 - val_acc: 0.6412\n",
      "Epoch 8/35\n",
      " - 1s - loss: 0.8981 - acc: 0.6478 - val_loss: 0.9116 - val_acc: 0.6431\n",
      "Epoch 9/35\n",
      " - 1s - loss: 0.8945 - acc: 0.6483 - val_loss: 0.9076 - val_acc: 0.6455\n",
      "Epoch 10/35\n",
      " - 1s - loss: 0.8906 - acc: 0.6505 - val_loss: 0.9065 - val_acc: 0.6464\n",
      "Epoch 11/35\n",
      " - 1s - loss: 0.8858 - acc: 0.6527 - val_loss: 0.9082 - val_acc: 0.6438\n",
      "Epoch 12/35\n",
      " - 1s - loss: 0.8827 - acc: 0.6531 - val_loss: 0.9062 - val_acc: 0.6462\n",
      "Epoch 13/35\n",
      " - 1s - loss: 0.8779 - acc: 0.6567 - val_loss: 0.9097 - val_acc: 0.6441\n",
      "Epoch 14/35\n",
      " - 1s - loss: 0.8747 - acc: 0.6550 - val_loss: 0.9064 - val_acc: 0.6466\n",
      "Epoch 15/35\n",
      " - 1s - loss: 0.8715 - acc: 0.6569 - val_loss: 0.9069 - val_acc: 0.6476\n",
      "Epoch 16/35\n",
      " - 1s - loss: 0.8668 - acc: 0.6594 - val_loss: 0.9071 - val_acc: 0.6479\n",
      "Epoch 17/35\n",
      " - 1s - loss: 0.8636 - acc: 0.6610 - val_loss: 0.9098 - val_acc: 0.6471\n",
      "Epoch 18/35\n",
      " - 1s - loss: 0.8586 - acc: 0.6641 - val_loss: 0.9083 - val_acc: 0.6482\n",
      "Epoch 19/35\n",
      " - 1s - loss: 0.8565 - acc: 0.6646 - val_loss: 0.9136 - val_acc: 0.6450\n",
      "Epoch 20/35\n",
      " - 1s - loss: 0.8523 - acc: 0.6652 - val_loss: 0.9077 - val_acc: 0.6498\n",
      "Epoch 21/35\n",
      " - 1s - loss: 0.8488 - acc: 0.6675 - val_loss: 0.9086 - val_acc: 0.6503\n",
      "Epoch 22/35\n",
      " - 1s - loss: 0.8435 - acc: 0.6691 - val_loss: 0.9121 - val_acc: 0.6502\n",
      "Epoch 23/35\n",
      " - 1s - loss: 0.8380 - acc: 0.6725 - val_loss: 0.9169 - val_acc: 0.6475\n",
      "Epoch 24/35\n",
      " - 1s - loss: 0.8334 - acc: 0.6743 - val_loss: 0.9116 - val_acc: 0.6453\n",
      "Epoch 25/35\n",
      " - 1s - loss: 0.8288 - acc: 0.6765 - val_loss: 0.9193 - val_acc: 0.6473\n",
      "Epoch 26/35\n",
      " - 1s - loss: 0.8249 - acc: 0.6794 - val_loss: 0.9226 - val_acc: 0.6457\n",
      "Epoch 27/35\n",
      " - 1s - loss: 0.8199 - acc: 0.6771 - val_loss: 0.9219 - val_acc: 0.6463\n",
      "Epoch 28/35\n",
      " - 1s - loss: 0.8134 - acc: 0.6810 - val_loss: 0.9278 - val_acc: 0.6431\n",
      "Epoch 29/35\n",
      " - 1s - loss: 0.8091 - acc: 0.6822 - val_loss: 0.9258 - val_acc: 0.6463\n",
      "Epoch 30/35\n",
      " - 1s - loss: 0.8016 - acc: 0.6870 - val_loss: 0.9282 - val_acc: 0.6419\n",
      "Epoch 31/35\n",
      " - 1s - loss: 0.7954 - acc: 0.6887 - val_loss: 0.9318 - val_acc: 0.6414\n",
      "Epoch 32/35\n",
      " - 1s - loss: 0.7921 - acc: 0.6906 - val_loss: 0.9419 - val_acc: 0.6428\n",
      "Epoch 33/35\n",
      " - 1s - loss: 0.7845 - acc: 0.6942 - val_loss: 0.9430 - val_acc: 0.6421\n",
      "Epoch 34/35\n",
      " - 1s - loss: 0.7788 - acc: 0.6961 - val_loss: 0.9450 - val_acc: 0.6417\n",
      "Epoch 35/35\n",
      " - 1s - loss: 0.7711 - acc: 0.6998 - val_loss: 0.9567 - val_acc: 0.6414\n",
      "va acc: 0.637\n",
      "te acc: 0.6414\n",
      "2018-09-18 22:47:28.183951 stack:5/5\n",
      "Train on 64000 samples, validate on 20000 samples\n",
      "Epoch 1/35\n",
      " - 2s - loss: 0.9705 - acc: 0.6198 - val_loss: 0.9465 - val_acc: 0.6243\n",
      "Epoch 2/35\n",
      " - 1s - loss: 0.9399 - acc: 0.6315 - val_loss: 0.9279 - val_acc: 0.6365\n",
      "Epoch 3/35\n",
      " - 1s - loss: 0.9287 - acc: 0.6350 - val_loss: 0.9256 - val_acc: 0.6414\n",
      "Epoch 4/35\n",
      " - 1s - loss: 0.9212 - acc: 0.6385 - val_loss: 0.9200 - val_acc: 0.6405\n",
      "Epoch 5/35\n",
      " - 1s - loss: 0.9144 - acc: 0.6407 - val_loss: 0.9148 - val_acc: 0.6415\n",
      "Epoch 6/35\n",
      " - 1s - loss: 0.9096 - acc: 0.6417 - val_loss: 0.9171 - val_acc: 0.6420\n",
      "Epoch 7/35\n",
      " - 1s - loss: 0.9049 - acc: 0.6434 - val_loss: 0.9105 - val_acc: 0.6443\n",
      "Epoch 8/35\n",
      " - 1s - loss: 0.9002 - acc: 0.6458 - val_loss: 0.9088 - val_acc: 0.6464\n",
      "Epoch 9/35\n",
      " - 1s - loss: 0.8951 - acc: 0.6485 - val_loss: 0.9084 - val_acc: 0.6481\n",
      "Epoch 10/35\n",
      " - 1s - loss: 0.8927 - acc: 0.6489 - val_loss: 0.9073 - val_acc: 0.6466\n",
      "Epoch 11/35\n",
      " - 1s - loss: 0.8886 - acc: 0.6505 - val_loss: 0.9067 - val_acc: 0.6466\n",
      "Epoch 12/35\n",
      " - 1s - loss: 0.8851 - acc: 0.6518 - val_loss: 0.9054 - val_acc: 0.6482\n",
      "Epoch 13/35\n",
      " - 1s - loss: 0.8815 - acc: 0.6540 - val_loss: 0.9111 - val_acc: 0.6450\n",
      "Epoch 14/35\n",
      " - 1s - loss: 0.8784 - acc: 0.6558 - val_loss: 0.9049 - val_acc: 0.6466\n",
      "Epoch 15/35\n",
      " - 1s - loss: 0.8741 - acc: 0.6555 - val_loss: 0.9091 - val_acc: 0.6470\n",
      "Epoch 16/35\n",
      " - 1s - loss: 0.8712 - acc: 0.6569 - val_loss: 0.9071 - val_acc: 0.6484\n",
      "Epoch 17/35\n",
      " - 1s - loss: 0.8678 - acc: 0.6606 - val_loss: 0.9055 - val_acc: 0.6474\n",
      "Epoch 18/35\n",
      " - 1s - loss: 0.8625 - acc: 0.6612 - val_loss: 0.9044 - val_acc: 0.6482\n",
      "Epoch 19/35\n",
      " - 1s - loss: 0.8599 - acc: 0.6622 - val_loss: 0.9106 - val_acc: 0.6492\n",
      "Epoch 20/35\n",
      " - 1s - loss: 0.8542 - acc: 0.6662 - val_loss: 0.9137 - val_acc: 0.6439\n",
      "Epoch 21/35\n",
      " - 1s - loss: 0.8512 - acc: 0.6675 - val_loss: 0.9101 - val_acc: 0.6492\n",
      "Epoch 22/35\n",
      " - 1s - loss: 0.8466 - acc: 0.6703 - val_loss: 0.9107 - val_acc: 0.6470\n",
      "Epoch 23/35\n",
      " - 1s - loss: 0.8424 - acc: 0.6704 - val_loss: 0.9213 - val_acc: 0.6445\n",
      "Epoch 24/35\n",
      " - 1s - loss: 0.8351 - acc: 0.6734 - val_loss: 0.9254 - val_acc: 0.6427\n",
      "Epoch 25/35\n",
      " - 1s - loss: 0.8320 - acc: 0.6737 - val_loss: 0.9130 - val_acc: 0.6463\n",
      "Epoch 26/35\n",
      " - 1s - loss: 0.8275 - acc: 0.6770 - val_loss: 0.9201 - val_acc: 0.6475\n",
      "Epoch 27/35\n",
      " - 1s - loss: 0.8207 - acc: 0.6801 - val_loss: 0.9210 - val_acc: 0.6455\n",
      "Epoch 28/35\n",
      " - 1s - loss: 0.8138 - acc: 0.6834 - val_loss: 0.9227 - val_acc: 0.6449\n",
      "Epoch 29/35\n",
      " - 1s - loss: 0.8127 - acc: 0.6838 - val_loss: 0.9294 - val_acc: 0.6394\n",
      "Epoch 30/35\n",
      " - 1s - loss: 0.8040 - acc: 0.6842 - val_loss: 0.9388 - val_acc: 0.6407\n",
      "Epoch 31/35\n",
      " - 1s - loss: 0.7984 - acc: 0.6875 - val_loss: 0.9387 - val_acc: 0.6393\n",
      "Epoch 32/35\n",
      " - 1s - loss: 0.7946 - acc: 0.6876 - val_loss: 0.9441 - val_acc: 0.6399\n",
      "Epoch 33/35\n",
      " - 1s - loss: 0.7883 - acc: 0.6930 - val_loss: 0.9414 - val_acc: 0.6403\n",
      "Epoch 34/35\n",
      " - 1s - loss: 0.7826 - acc: 0.6948 - val_loss: 0.9472 - val_acc: 0.6357\n",
      "Epoch 35/35\n",
      " - 1s - loss: 0.7740 - acc: 0.6969 - val_loss: 0.9518 - val_acc: 0.6361\n",
      "va acc: 0.6416875\n",
      "te acc: 0.6361\n",
      "2018-09-18 22:48:18.238314 stack:1/5\n",
      "Train on 64000 samples, validate on 20000 samples\n",
      "Epoch 1/35\n",
      " - 2s - loss: 1.0874 - acc: 0.5752 - val_loss: 1.0502 - val_acc: 0.5938\n",
      "Epoch 2/35\n",
      " - 1s - loss: 1.0519 - acc: 0.5907 - val_loss: 1.0431 - val_acc: 0.5998\n",
      "Epoch 3/35\n",
      " - 1s - loss: 1.0396 - acc: 0.5955 - val_loss: 1.0347 - val_acc: 0.6017\n",
      "Epoch 4/35\n",
      " - 1s - loss: 1.0285 - acc: 0.6001 - val_loss: 1.0195 - val_acc: 0.6064\n",
      "Epoch 5/35\n",
      " - 1s - loss: 1.0188 - acc: 0.6028 - val_loss: 1.0269 - val_acc: 0.6032\n",
      "Epoch 6/35\n",
      " - 1s - loss: 1.0134 - acc: 0.6062 - val_loss: 1.0116 - val_acc: 0.6076\n",
      "Epoch 7/35\n",
      " - 1s - loss: 1.0076 - acc: 0.6073 - val_loss: 1.0111 - val_acc: 0.6102\n",
      "Epoch 8/35\n",
      " - 1s - loss: 1.0035 - acc: 0.6089 - val_loss: 1.0187 - val_acc: 0.6025\n",
      "Epoch 9/35\n",
      " - 1s - loss: 0.9972 - acc: 0.6110 - val_loss: 1.0068 - val_acc: 0.6131\n",
      "Epoch 10/35\n",
      " - 1s - loss: 0.9927 - acc: 0.6150 - val_loss: 1.0069 - val_acc: 0.6124\n",
      "Epoch 11/35\n",
      " - 1s - loss: 0.9884 - acc: 0.6155 - val_loss: 1.0152 - val_acc: 0.6110\n",
      "Epoch 12/35\n",
      " - 1s - loss: 0.9858 - acc: 0.6172 - val_loss: 1.0072 - val_acc: 0.6120\n",
      "Epoch 13/35\n",
      " - 1s - loss: 0.9794 - acc: 0.6181 - val_loss: 1.0048 - val_acc: 0.6151\n",
      "Epoch 14/35\n",
      " - 1s - loss: 0.9765 - acc: 0.6210 - val_loss: 1.0069 - val_acc: 0.6123\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/35\n",
      " - 1s - loss: 0.9721 - acc: 0.6202 - val_loss: 1.0021 - val_acc: 0.6135\n",
      "Epoch 16/35\n",
      " - 1s - loss: 0.9664 - acc: 0.6239 - val_loss: 1.0048 - val_acc: 0.6135\n",
      "Epoch 17/35\n",
      " - 1s - loss: 0.9625 - acc: 0.6254 - val_loss: 1.0032 - val_acc: 0.6135\n",
      "Epoch 18/35\n",
      " - 1s - loss: 0.9591 - acc: 0.6265 - val_loss: 1.0223 - val_acc: 0.6113\n",
      "Epoch 19/35\n",
      " - 2s - loss: 0.9542 - acc: 0.6297 - val_loss: 1.0084 - val_acc: 0.6122\n",
      "Epoch 20/35\n",
      " - 1s - loss: 0.9497 - acc: 0.6304 - val_loss: 1.0095 - val_acc: 0.6095\n",
      "Epoch 21/35\n",
      " - 1s - loss: 0.9457 - acc: 0.6328 - val_loss: 1.0110 - val_acc: 0.6108\n",
      "Epoch 22/35\n",
      " - 1s - loss: 0.9370 - acc: 0.6362 - val_loss: 1.0337 - val_acc: 0.6085\n",
      "Epoch 23/35\n",
      " - 1s - loss: 0.9336 - acc: 0.6370 - val_loss: 1.0108 - val_acc: 0.6111\n",
      "Epoch 24/35\n",
      " - 2s - loss: 0.9275 - acc: 0.6406 - val_loss: 1.0170 - val_acc: 0.6107\n",
      "Epoch 25/35\n",
      " - 2s - loss: 0.9238 - acc: 0.6429 - val_loss: 1.0144 - val_acc: 0.6092\n",
      "Epoch 26/35\n",
      " - 1s - loss: 0.9175 - acc: 0.6446 - val_loss: 1.0194 - val_acc: 0.6062\n",
      "Epoch 27/35\n",
      " - 1s - loss: 0.9119 - acc: 0.6464 - val_loss: 1.0241 - val_acc: 0.6081\n",
      "Epoch 28/35\n",
      " - 1s - loss: 0.9057 - acc: 0.6503 - val_loss: 1.0267 - val_acc: 0.6074\n",
      "Epoch 29/35\n",
      " - 1s - loss: 0.9015 - acc: 0.6518 - val_loss: 1.0345 - val_acc: 0.6038\n",
      "Epoch 30/35\n",
      " - 1s - loss: 0.8948 - acc: 0.6550 - val_loss: 1.0266 - val_acc: 0.6069\n",
      "Epoch 31/35\n",
      " - 1s - loss: 0.8891 - acc: 0.6573 - val_loss: 1.0501 - val_acc: 0.5971\n",
      "Epoch 32/35\n",
      " - 1s - loss: 0.8830 - acc: 0.6565 - val_loss: 1.0400 - val_acc: 0.6058\n",
      "Epoch 33/35\n",
      " - 1s - loss: 0.8757 - acc: 0.6616 - val_loss: 1.0475 - val_acc: 0.6038\n",
      "Epoch 34/35\n",
      " - 1s - loss: 0.8695 - acc: 0.6663 - val_loss: 1.0427 - val_acc: 0.6034\n",
      "Epoch 35/35\n",
      " - 1s - loss: 0.8627 - acc: 0.6688 - val_loss: 1.0487 - val_acc: 0.5997\n",
      "va acc: 0.60175\n",
      "te acc: 0.59965\n",
      "2018-09-18 22:49:09.571968 stack:2/5\n",
      "Train on 64000 samples, validate on 20000 samples\n",
      "Epoch 1/35\n",
      " - 2s - loss: 1.0843 - acc: 0.5759 - val_loss: 1.0434 - val_acc: 0.5949\n",
      "Epoch 2/35\n",
      " - 2s - loss: 1.0498 - acc: 0.5912 - val_loss: 1.0376 - val_acc: 0.5975\n",
      "Epoch 3/35\n",
      " - 2s - loss: 1.0377 - acc: 0.5946 - val_loss: 1.0275 - val_acc: 0.6047\n",
      "Epoch 4/35\n",
      " - 1s - loss: 1.0257 - acc: 0.6001 - val_loss: 1.0234 - val_acc: 0.6026\n",
      "Epoch 5/35\n",
      " - 1s - loss: 1.0168 - acc: 0.6033 - val_loss: 1.0198 - val_acc: 0.6020\n",
      "Epoch 6/35\n",
      " - 1s - loss: 1.0097 - acc: 0.6075 - val_loss: 1.0257 - val_acc: 0.6004\n",
      "Epoch 7/35\n",
      " - 1s - loss: 1.0034 - acc: 0.6101 - val_loss: 1.0113 - val_acc: 0.6100\n",
      "Epoch 8/35\n",
      " - 1s - loss: 0.9994 - acc: 0.6105 - val_loss: 1.0056 - val_acc: 0.6121\n",
      "Epoch 9/35\n",
      " - 1s - loss: 0.9928 - acc: 0.6128 - val_loss: 1.0095 - val_acc: 0.6098\n",
      "Epoch 10/35\n",
      " - 1s - loss: 0.9881 - acc: 0.6156 - val_loss: 1.0025 - val_acc: 0.6131\n",
      "Epoch 11/35\n",
      " - 1s - loss: 0.9844 - acc: 0.6150 - val_loss: 1.0043 - val_acc: 0.6122\n",
      "Epoch 12/35\n",
      " - 1s - loss: 0.9795 - acc: 0.6171 - val_loss: 1.0006 - val_acc: 0.6117\n",
      "Epoch 13/35\n",
      " - 1s - loss: 0.9751 - acc: 0.6200 - val_loss: 1.0061 - val_acc: 0.6142\n",
      "Epoch 14/35\n",
      " - 1s - loss: 0.9705 - acc: 0.6205 - val_loss: 1.0053 - val_acc: 0.6099\n",
      "Epoch 15/35\n",
      " - 1s - loss: 0.9652 - acc: 0.6250 - val_loss: 1.0121 - val_acc: 0.6087\n",
      "Epoch 16/35\n",
      " - 1s - loss: 0.9618 - acc: 0.6267 - val_loss: 1.0043 - val_acc: 0.6139\n",
      "Epoch 17/35\n",
      " - 1s - loss: 0.9581 - acc: 0.6265 - val_loss: 1.0096 - val_acc: 0.6113\n",
      "Epoch 18/35\n",
      " - 1s - loss: 0.9527 - acc: 0.6266 - val_loss: 1.0058 - val_acc: 0.6120\n",
      "Epoch 19/35\n",
      " - 1s - loss: 0.9483 - acc: 0.6298 - val_loss: 1.0065 - val_acc: 0.6158\n",
      "Epoch 20/35\n",
      " - 1s - loss: 0.9436 - acc: 0.6320 - val_loss: 1.0062 - val_acc: 0.6139\n",
      "Epoch 21/35\n",
      " - 1s - loss: 0.9385 - acc: 0.6358 - val_loss: 1.0060 - val_acc: 0.6140\n",
      "Epoch 22/35\n",
      " - 1s - loss: 0.9346 - acc: 0.6365 - val_loss: 1.0051 - val_acc: 0.6159\n",
      "Epoch 23/35\n",
      " - 1s - loss: 0.9291 - acc: 0.6401 - val_loss: 1.0128 - val_acc: 0.6122\n",
      "Epoch 24/35\n",
      " - 1s - loss: 0.9230 - acc: 0.6423 - val_loss: 1.0115 - val_acc: 0.6120\n",
      "Epoch 25/35\n",
      " - 1s - loss: 0.9174 - acc: 0.6447 - val_loss: 1.0120 - val_acc: 0.6120\n",
      "Epoch 26/35\n",
      " - 1s - loss: 0.9105 - acc: 0.6463 - val_loss: 1.0228 - val_acc: 0.6126\n",
      "Epoch 27/35\n",
      " - 1s - loss: 0.9048 - acc: 0.6498 - val_loss: 1.0283 - val_acc: 0.6086\n",
      "Epoch 28/35\n",
      " - 1s - loss: 0.8983 - acc: 0.6528 - val_loss: 1.0207 - val_acc: 0.6133\n",
      "Epoch 29/35\n",
      " - 1s - loss: 0.8943 - acc: 0.6545 - val_loss: 1.0236 - val_acc: 0.6128\n",
      "Epoch 30/35\n",
      " - 2s - loss: 0.8876 - acc: 0.6559 - val_loss: 1.0319 - val_acc: 0.6119\n",
      "Epoch 31/35\n",
      " - 1s - loss: 0.8797 - acc: 0.6614 - val_loss: 1.0349 - val_acc: 0.6133\n",
      "Epoch 32/35\n",
      " - 1s - loss: 0.8706 - acc: 0.6630 - val_loss: 1.0373 - val_acc: 0.6055\n",
      "Epoch 33/35\n",
      " - 1s - loss: 0.8647 - acc: 0.6685 - val_loss: 1.0464 - val_acc: 0.6108\n",
      "Epoch 34/35\n",
      " - 1s - loss: 0.8581 - acc: 0.6681 - val_loss: 1.0465 - val_acc: 0.6078\n",
      "Epoch 35/35\n",
      " - 1s - loss: 0.8499 - acc: 0.6725 - val_loss: 1.0512 - val_acc: 0.6089\n",
      "va acc: 0.59575\n",
      "te acc: 0.60895\n",
      "2018-09-18 22:50:01.788152 stack:3/5\n",
      "Train on 64000 samples, validate on 20000 samples\n",
      "Epoch 1/35\n",
      " - 2s - loss: 1.0884 - acc: 0.5755 - val_loss: 1.0541 - val_acc: 0.5886\n",
      "Epoch 2/35\n",
      " - 1s - loss: 1.0544 - acc: 0.5910 - val_loss: 1.0348 - val_acc: 0.5995\n",
      "Epoch 3/35\n",
      " - 1s - loss: 1.0415 - acc: 0.5949 - val_loss: 1.0366 - val_acc: 0.6017\n",
      "Epoch 4/35\n",
      " - 1s - loss: 1.0290 - acc: 0.5996 - val_loss: 1.0203 - val_acc: 0.6055\n",
      "Epoch 5/35\n",
      " - 1s - loss: 1.0213 - acc: 0.6020 - val_loss: 1.0162 - val_acc: 0.6059\n",
      "Epoch 6/35\n",
      " - 1s - loss: 1.0141 - acc: 0.6058 - val_loss: 1.0134 - val_acc: 0.6082\n",
      "Epoch 7/35\n",
      " - 1s - loss: 1.0078 - acc: 0.6075 - val_loss: 1.0067 - val_acc: 0.6107\n",
      "Epoch 8/35\n",
      " - 1s - loss: 1.0019 - acc: 0.6085 - val_loss: 1.0107 - val_acc: 0.6106\n",
      "Epoch 9/35\n",
      " - 1s - loss: 0.9989 - acc: 0.6112 - val_loss: 1.0157 - val_acc: 0.6089\n",
      "Epoch 10/35\n",
      " - 2s - loss: 0.9922 - acc: 0.6148 - val_loss: 1.0033 - val_acc: 0.6120\n",
      "Epoch 11/35\n",
      " - 1s - loss: 0.9897 - acc: 0.6132 - val_loss: 1.0095 - val_acc: 0.6109\n",
      "Epoch 12/35\n",
      " - 1s - loss: 0.9857 - acc: 0.6149 - val_loss: 1.0054 - val_acc: 0.6121\n",
      "Epoch 13/35\n",
      " - 1s - loss: 0.9808 - acc: 0.6170 - val_loss: 1.0043 - val_acc: 0.6107\n",
      "Epoch 14/35\n",
      " - 2s - loss: 0.9780 - acc: 0.6189 - val_loss: 1.0051 - val_acc: 0.6130\n",
      "Epoch 15/35\n",
      " - 1s - loss: 0.9725 - acc: 0.6202 - val_loss: 1.0081 - val_acc: 0.6095\n",
      "Epoch 16/35\n",
      " - 1s - loss: 0.9699 - acc: 0.6222 - val_loss: 1.0030 - val_acc: 0.6146\n",
      "Epoch 17/35\n",
      " - 2s - loss: 0.9661 - acc: 0.6228 - val_loss: 1.0043 - val_acc: 0.6142\n",
      "Epoch 18/35\n",
      " - 2s - loss: 0.9615 - acc: 0.6254 - val_loss: 1.0141 - val_acc: 0.6098\n",
      "Epoch 19/35\n",
      " - 2s - loss: 0.9571 - acc: 0.6266 - val_loss: 1.0096 - val_acc: 0.6111\n",
      "Epoch 20/35\n",
      " - 2s - loss: 0.9510 - acc: 0.6296 - val_loss: 1.0101 - val_acc: 0.6120\n",
      "Epoch 21/35\n",
      " - 1s - loss: 0.9467 - acc: 0.6313 - val_loss: 1.0046 - val_acc: 0.6126\n",
      "Epoch 22/35\n",
      " - 1s - loss: 0.9439 - acc: 0.6327 - val_loss: 1.0123 - val_acc: 0.6136\n",
      "Epoch 23/35\n",
      " - 1s - loss: 0.9373 - acc: 0.6364 - val_loss: 1.0152 - val_acc: 0.6115\n",
      "Epoch 24/35\n",
      " - 1s - loss: 0.9332 - acc: 0.6372 - val_loss: 1.0121 - val_acc: 0.6120\n",
      "Epoch 25/35\n",
      " - 1s - loss: 0.9286 - acc: 0.6380 - val_loss: 1.0197 - val_acc: 0.6098\n",
      "Epoch 26/35\n",
      " - 1s - loss: 0.9220 - acc: 0.6407 - val_loss: 1.0163 - val_acc: 0.6101\n",
      "Epoch 27/35\n",
      " - 1s - loss: 0.9173 - acc: 0.6428 - val_loss: 1.0225 - val_acc: 0.6098\n",
      "Epoch 28/35\n",
      " - 2s - loss: 0.9101 - acc: 0.6477 - val_loss: 1.0262 - val_acc: 0.6083\n",
      "Epoch 29/35\n",
      " - 1s - loss: 0.9067 - acc: 0.6489 - val_loss: 1.0319 - val_acc: 0.6032\n",
      "Epoch 30/35\n",
      " - 1s - loss: 0.8984 - acc: 0.6516 - val_loss: 1.0327 - val_acc: 0.6038\n",
      "Epoch 31/35\n",
      " - 1s - loss: 0.8914 - acc: 0.6558 - val_loss: 1.0348 - val_acc: 0.6077\n",
      "Epoch 32/35\n",
      " - 1s - loss: 0.8880 - acc: 0.6557 - val_loss: 1.0364 - val_acc: 0.6036\n",
      "Epoch 33/35\n",
      " - 1s - loss: 0.8806 - acc: 0.6605 - val_loss: 1.0420 - val_acc: 0.6058\n",
      "Epoch 34/35\n",
      " - 2s - loss: 0.8742 - acc: 0.6639 - val_loss: 1.0442 - val_acc: 0.6063\n",
      "Epoch 35/35\n",
      " - 1s - loss: 0.8678 - acc: 0.6649 - val_loss: 1.0515 - val_acc: 0.6039\n",
      "va acc: 0.600375\n",
      "te acc: 0.60395\n",
      "2018-09-18 22:50:54.514030 stack:4/5\n",
      "Train on 64000 samples, validate on 20000 samples\n",
      "Epoch 1/35\n",
      " - 2s - loss: 1.0884 - acc: 0.5740 - val_loss: 1.0473 - val_acc: 0.5951\n",
      "Epoch 2/35\n",
      " - 2s - loss: 1.0548 - acc: 0.5901 - val_loss: 1.0384 - val_acc: 0.5982\n",
      "Epoch 3/35\n",
      " - 2s - loss: 1.0410 - acc: 0.5963 - val_loss: 1.0317 - val_acc: 0.6033\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/35\n",
      " - 2s - loss: 1.0299 - acc: 0.5995 - val_loss: 1.0228 - val_acc: 0.6005\n",
      "Epoch 5/35\n",
      " - 1s - loss: 1.0212 - acc: 0.6018 - val_loss: 1.0170 - val_acc: 0.6073\n",
      "Epoch 6/35\n",
      " - 1s - loss: 1.0146 - acc: 0.6042 - val_loss: 1.0141 - val_acc: 0.6084\n",
      "Epoch 7/35\n",
      " - 2s - loss: 1.0086 - acc: 0.6061 - val_loss: 1.0121 - val_acc: 0.6089\n",
      "Epoch 8/35\n",
      " - 1s - loss: 1.0037 - acc: 0.6091 - val_loss: 1.0058 - val_acc: 0.6073\n",
      "Epoch 9/35\n",
      " - 1s - loss: 0.9985 - acc: 0.6119 - val_loss: 1.0080 - val_acc: 0.6058\n",
      "Epoch 10/35\n",
      " - 1s - loss: 0.9947 - acc: 0.6128 - val_loss: 1.0056 - val_acc: 0.6100\n",
      "Epoch 11/35\n",
      " - 1s - loss: 0.9896 - acc: 0.6136 - val_loss: 1.0068 - val_acc: 0.6120\n",
      "Epoch 12/35\n",
      " - 1s - loss: 0.9858 - acc: 0.6156 - val_loss: 1.0026 - val_acc: 0.6109\n",
      "Epoch 13/35\n",
      " - 1s - loss: 0.9812 - acc: 0.6187 - val_loss: 1.0053 - val_acc: 0.6123\n",
      "Epoch 14/35\n",
      " - 1s - loss: 0.9780 - acc: 0.6195 - val_loss: 1.0074 - val_acc: 0.6116\n",
      "Epoch 15/35\n",
      " - 1s - loss: 0.9722 - acc: 0.6208 - val_loss: 1.0061 - val_acc: 0.6108\n",
      "Epoch 16/35\n",
      " - 2s - loss: 0.9693 - acc: 0.6237 - val_loss: 1.0045 - val_acc: 0.6109\n",
      "Epoch 17/35\n",
      " - 2s - loss: 0.9624 - acc: 0.6250 - val_loss: 1.0024 - val_acc: 0.6112\n",
      "Epoch 18/35\n",
      " - 2s - loss: 0.9602 - acc: 0.6276 - val_loss: 1.0048 - val_acc: 0.6126\n",
      "Epoch 19/35\n",
      " - 1s - loss: 0.9543 - acc: 0.6292 - val_loss: 1.0046 - val_acc: 0.6112\n",
      "Epoch 20/35\n",
      " - 1s - loss: 0.9514 - acc: 0.6302 - val_loss: 1.0145 - val_acc: 0.6086\n",
      "Epoch 21/35\n",
      " - 1s - loss: 0.9450 - acc: 0.6331 - val_loss: 1.0057 - val_acc: 0.6113\n",
      "Epoch 22/35\n",
      " - 1s - loss: 0.9400 - acc: 0.6370 - val_loss: 1.0095 - val_acc: 0.6111\n",
      "Epoch 23/35\n",
      " - 2s - loss: 0.9347 - acc: 0.6350 - val_loss: 1.0128 - val_acc: 0.6116\n",
      "Epoch 24/35\n",
      " - 2s - loss: 0.9304 - acc: 0.6394 - val_loss: 1.0176 - val_acc: 0.6101\n",
      "Epoch 25/35\n",
      " - 1s - loss: 0.9251 - acc: 0.6419 - val_loss: 1.0160 - val_acc: 0.6109\n",
      "Epoch 26/35\n",
      " - 2s - loss: 0.9178 - acc: 0.6445 - val_loss: 1.0277 - val_acc: 0.6085\n",
      "Epoch 27/35\n",
      " - 1s - loss: 0.9135 - acc: 0.6462 - val_loss: 1.0259 - val_acc: 0.6075\n",
      "Epoch 28/35\n",
      " - 1s - loss: 0.9069 - acc: 0.6510 - val_loss: 1.0236 - val_acc: 0.6049\n",
      "Epoch 29/35\n",
      " - 1s - loss: 0.9003 - acc: 0.6516 - val_loss: 1.0283 - val_acc: 0.6045\n",
      "Epoch 30/35\n",
      " - 1s - loss: 0.8950 - acc: 0.6540 - val_loss: 1.0356 - val_acc: 0.6059\n",
      "Epoch 31/35\n",
      " - 1s - loss: 0.8881 - acc: 0.6567 - val_loss: 1.0330 - val_acc: 0.6052\n",
      "Epoch 32/35\n",
      " - 1s - loss: 0.8801 - acc: 0.6617 - val_loss: 1.0381 - val_acc: 0.6051\n",
      "Epoch 33/35\n",
      " - 1s - loss: 0.8719 - acc: 0.6637 - val_loss: 1.0435 - val_acc: 0.6046\n",
      "Epoch 34/35\n",
      " - 1s - loss: 0.8657 - acc: 0.6683 - val_loss: 1.0577 - val_acc: 0.6018\n",
      "Epoch 35/35\n",
      " - 1s - loss: 0.8598 - acc: 0.6695 - val_loss: 1.0531 - val_acc: 0.6058\n",
      "va acc: 0.60225\n",
      "te acc: 0.60585\n",
      "2018-09-18 22:51:47.743684 stack:5/5\n",
      "Train on 64000 samples, validate on 20000 samples\n",
      "Epoch 1/35\n",
      " - 2s - loss: 1.0905 - acc: 0.5740 - val_loss: 1.0524 - val_acc: 0.5937\n",
      "Epoch 2/35\n",
      " - 1s - loss: 1.0557 - acc: 0.5902 - val_loss: 1.0396 - val_acc: 0.5971\n",
      "Epoch 3/35\n",
      " - 1s - loss: 1.0423 - acc: 0.5954 - val_loss: 1.0263 - val_acc: 0.6038\n",
      "Epoch 4/35\n",
      " - 1s - loss: 1.0316 - acc: 0.5972 - val_loss: 1.0208 - val_acc: 0.6032\n",
      "Epoch 5/35\n",
      " - 1s - loss: 1.0223 - acc: 0.6004 - val_loss: 1.0123 - val_acc: 0.6112\n",
      "Epoch 6/35\n",
      " - 1s - loss: 1.0147 - acc: 0.6049 - val_loss: 1.0098 - val_acc: 0.6118\n",
      "Epoch 7/35\n",
      " - 1s - loss: 1.0086 - acc: 0.6078 - val_loss: 1.0073 - val_acc: 0.6121\n",
      "Epoch 8/35\n",
      " - 1s - loss: 1.0037 - acc: 0.6094 - val_loss: 1.0088 - val_acc: 0.6100\n",
      "Epoch 9/35\n",
      " - 1s - loss: 0.9989 - acc: 0.6093 - val_loss: 1.0053 - val_acc: 0.6157\n",
      "Epoch 10/35\n",
      " - 1s - loss: 0.9943 - acc: 0.6118 - val_loss: 1.0028 - val_acc: 0.6136\n",
      "Epoch 11/35\n",
      " - 1s - loss: 0.9910 - acc: 0.6152 - val_loss: 1.0001 - val_acc: 0.6132\n",
      "Epoch 12/35\n",
      " - 1s - loss: 0.9858 - acc: 0.6143 - val_loss: 1.0065 - val_acc: 0.6139\n",
      "Epoch 13/35\n",
      " - 2s - loss: 0.9822 - acc: 0.6176 - val_loss: 1.0081 - val_acc: 0.6143\n",
      "Epoch 14/35\n",
      " - 2s - loss: 0.9789 - acc: 0.6182 - val_loss: 0.9994 - val_acc: 0.6145\n",
      "Epoch 15/35\n",
      " - 2s - loss: 0.9742 - acc: 0.6200 - val_loss: 1.0040 - val_acc: 0.6127\n",
      "Epoch 16/35\n",
      " - 1s - loss: 0.9703 - acc: 0.6221 - val_loss: 1.0020 - val_acc: 0.6149\n",
      "Epoch 17/35\n",
      " - 1s - loss: 0.9649 - acc: 0.6225 - val_loss: 1.0036 - val_acc: 0.6163\n",
      "Epoch 18/35\n",
      " - 1s - loss: 0.9611 - acc: 0.6256 - val_loss: 1.0085 - val_acc: 0.6100\n",
      "Epoch 19/35\n",
      " - 2s - loss: 0.9576 - acc: 0.6269 - val_loss: 1.0052 - val_acc: 0.6126\n",
      "Epoch 20/35\n",
      " - 1s - loss: 0.9523 - acc: 0.6290 - val_loss: 1.0076 - val_acc: 0.6139\n",
      "Epoch 21/35\n",
      " - 1s - loss: 0.9478 - acc: 0.6323 - val_loss: 1.0052 - val_acc: 0.6174\n",
      "Epoch 22/35\n",
      " - 2s - loss: 0.9421 - acc: 0.6326 - val_loss: 1.0093 - val_acc: 0.6101\n",
      "Epoch 23/35\n",
      " - 2s - loss: 0.9379 - acc: 0.6360 - val_loss: 1.0105 - val_acc: 0.6130\n",
      "Epoch 24/35\n",
      " - 2s - loss: 0.9322 - acc: 0.6386 - val_loss: 1.0102 - val_acc: 0.6154\n",
      "Epoch 25/35\n",
      " - 2s - loss: 0.9265 - acc: 0.6408 - val_loss: 1.0102 - val_acc: 0.6155\n",
      "Epoch 26/35\n",
      " - 2s - loss: 0.9211 - acc: 0.6446 - val_loss: 1.0239 - val_acc: 0.6090\n",
      "Epoch 27/35\n",
      " - 2s - loss: 0.9153 - acc: 0.6452 - val_loss: 1.0172 - val_acc: 0.6093\n",
      "Epoch 28/35\n",
      " - 2s - loss: 0.9094 - acc: 0.6478 - val_loss: 1.0215 - val_acc: 0.6100\n",
      "Epoch 29/35\n",
      " - 1s - loss: 0.9029 - acc: 0.6506 - val_loss: 1.0314 - val_acc: 0.6092\n",
      "Epoch 30/35\n",
      " - 1s - loss: 0.8964 - acc: 0.6535 - val_loss: 1.0295 - val_acc: 0.6101\n",
      "Epoch 31/35\n",
      " - 2s - loss: 0.8908 - acc: 0.6561 - val_loss: 1.0408 - val_acc: 0.6073\n",
      "Epoch 32/35\n",
      " - 2s - loss: 0.8844 - acc: 0.6589 - val_loss: 1.0379 - val_acc: 0.6074\n",
      "Epoch 33/35\n",
      " - 1s - loss: 0.8758 - acc: 0.6616 - val_loss: 1.0431 - val_acc: 0.6082\n",
      "Epoch 34/35\n",
      " - 1s - loss: 0.8709 - acc: 0.6639 - val_loss: 1.0441 - val_acc: 0.6076\n",
      "Epoch 35/35\n",
      " - 2s - loss: 0.8648 - acc: 0.6678 - val_loss: 1.0465 - val_acc: 0.6057\n",
      "va acc: 0.59825\n",
      "te acc: 0.60565\n",
      "2018-09-18 22:52:40.969701 stack:1/5\n",
      "Train on 64000 samples, validate on 20000 samples\n",
      "Epoch 1/35\n",
      " - 2s - loss: 0.4382 - acc: 0.8255 - val_loss: 0.4309 - val_acc: 0.8353\n",
      "Epoch 2/35\n",
      " - 1s - loss: 0.4253 - acc: 0.8343 - val_loss: 0.4245 - val_acc: 0.8384\n",
      "Epoch 3/35\n",
      " - 1s - loss: 0.4206 - acc: 0.8367 - val_loss: 0.4248 - val_acc: 0.8323\n",
      "Epoch 4/35\n",
      " - 1s - loss: 0.4170 - acc: 0.8381 - val_loss: 0.4197 - val_acc: 0.8357\n",
      "Epoch 5/35\n",
      " - 1s - loss: 0.4138 - acc: 0.8380 - val_loss: 0.4167 - val_acc: 0.8380\n",
      "Epoch 6/35\n",
      " - 1s - loss: 0.4103 - acc: 0.8396 - val_loss: 0.4135 - val_acc: 0.8391\n",
      "Epoch 7/35\n",
      " - 1s - loss: 0.4074 - acc: 0.8401 - val_loss: 0.4120 - val_acc: 0.8399\n",
      "Epoch 8/35\n",
      " - 1s - loss: 0.4056 - acc: 0.8413 - val_loss: 0.4129 - val_acc: 0.8401\n",
      "Epoch 9/35\n",
      " - 1s - loss: 0.4040 - acc: 0.8411 - val_loss: 0.4092 - val_acc: 0.8415\n",
      "Epoch 10/35\n",
      " - 1s - loss: 0.4022 - acc: 0.8423 - val_loss: 0.4140 - val_acc: 0.8360\n",
      "Epoch 11/35\n",
      " - 1s - loss: 0.4009 - acc: 0.8426 - val_loss: 0.4071 - val_acc: 0.8409\n",
      "Epoch 12/35\n",
      " - 1s - loss: 0.3993 - acc: 0.8429 - val_loss: 0.4099 - val_acc: 0.8387\n",
      "Epoch 13/35\n",
      " - 1s - loss: 0.3984 - acc: 0.8429 - val_loss: 0.4115 - val_acc: 0.8420\n",
      "Epoch 14/35\n",
      " - 1s - loss: 0.3967 - acc: 0.8435 - val_loss: 0.4074 - val_acc: 0.8428\n",
      "Epoch 15/35\n",
      " - 1s - loss: 0.3957 - acc: 0.8440 - val_loss: 0.4066 - val_acc: 0.8424\n",
      "Epoch 16/35\n",
      " - 1s - loss: 0.3952 - acc: 0.8448 - val_loss: 0.4096 - val_acc: 0.8418\n",
      "Epoch 17/35\n",
      " - 1s - loss: 0.3931 - acc: 0.8440 - val_loss: 0.4077 - val_acc: 0.8417\n",
      "Epoch 18/35\n",
      " - 1s - loss: 0.3919 - acc: 0.8453 - val_loss: 0.4076 - val_acc: 0.8418\n",
      "Epoch 19/35\n",
      " - 1s - loss: 0.3916 - acc: 0.8458 - val_loss: 0.4100 - val_acc: 0.8424\n",
      "Epoch 20/35\n",
      " - 1s - loss: 0.3899 - acc: 0.8460 - val_loss: 0.4085 - val_acc: 0.8418\n",
      "Epoch 21/35\n",
      " - 1s - loss: 0.3878 - acc: 0.8475 - val_loss: 0.4119 - val_acc: 0.8415\n",
      "Epoch 22/35\n",
      " - 1s - loss: 0.3862 - acc: 0.8471 - val_loss: 0.4105 - val_acc: 0.8426\n",
      "Epoch 23/35\n",
      " - 1s - loss: 0.3857 - acc: 0.8474 - val_loss: 0.4122 - val_acc: 0.8406\n",
      "Epoch 24/35\n",
      " - 1s - loss: 0.3844 - acc: 0.8480 - val_loss: 0.4084 - val_acc: 0.8418\n",
      "Epoch 25/35\n",
      " - 1s - loss: 0.3825 - acc: 0.8493 - val_loss: 0.4132 - val_acc: 0.8427\n",
      "Epoch 26/35\n",
      " - 1s - loss: 0.3814 - acc: 0.8484 - val_loss: 0.4102 - val_acc: 0.8416\n",
      "Epoch 27/35\n",
      " - 1s - loss: 0.3781 - acc: 0.8498 - val_loss: 0.4183 - val_acc: 0.8407\n",
      "Epoch 28/35\n",
      " - 1s - loss: 0.3763 - acc: 0.8504 - val_loss: 0.4188 - val_acc: 0.8407\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/35\n",
      " - 1s - loss: 0.3750 - acc: 0.8512 - val_loss: 0.4135 - val_acc: 0.8414\n",
      "Epoch 30/35\n",
      " - 1s - loss: 0.3724 - acc: 0.8511 - val_loss: 0.4154 - val_acc: 0.8377\n",
      "Epoch 31/35\n",
      " - 1s - loss: 0.3707 - acc: 0.8515 - val_loss: 0.4185 - val_acc: 0.8397\n",
      "Epoch 32/35\n",
      " - 1s - loss: 0.3681 - acc: 0.8532 - val_loss: 0.4175 - val_acc: 0.8393\n",
      "Epoch 33/35\n",
      " - 1s - loss: 0.3661 - acc: 0.8544 - val_loss: 0.4229 - val_acc: 0.8374\n",
      "Epoch 34/35\n",
      " - 1s - loss: 0.3646 - acc: 0.8539 - val_loss: 0.4211 - val_acc: 0.8401\n",
      "Epoch 35/35\n",
      " - 1s - loss: 0.3608 - acc: 0.8558 - val_loss: 0.4336 - val_acc: 0.8347\n",
      "va acc: 0.8308125\n",
      "te acc: 0.83475\n",
      "2018-09-18 22:53:32.291557 stack:2/5\n",
      "Train on 64000 samples, validate on 20000 samples\n",
      "Epoch 1/35\n",
      " - 2s - loss: 0.4388 - acc: 0.8272 - val_loss: 0.4300 - val_acc: 0.8355\n",
      "Epoch 2/35\n",
      " - 1s - loss: 0.4256 - acc: 0.8357 - val_loss: 0.4241 - val_acc: 0.8367\n",
      "Epoch 3/35\n",
      " - 1s - loss: 0.4207 - acc: 0.8368 - val_loss: 0.4214 - val_acc: 0.8398\n",
      "Epoch 4/35\n",
      " - 1s - loss: 0.4170 - acc: 0.8384 - val_loss: 0.4176 - val_acc: 0.8392\n",
      "Epoch 5/35\n",
      " - 1s - loss: 0.4139 - acc: 0.8386 - val_loss: 0.4139 - val_acc: 0.8391\n",
      "Epoch 6/35\n",
      " - 1s - loss: 0.4105 - acc: 0.8396 - val_loss: 0.4121 - val_acc: 0.8392\n",
      "Epoch 7/35\n",
      " - 1s - loss: 0.4078 - acc: 0.8403 - val_loss: 0.4153 - val_acc: 0.8371\n",
      "Epoch 8/35\n",
      " - 1s - loss: 0.4061 - acc: 0.8415 - val_loss: 0.4111 - val_acc: 0.8408\n",
      "Epoch 9/35\n",
      " - 1s - loss: 0.4050 - acc: 0.8411 - val_loss: 0.4162 - val_acc: 0.8397\n",
      "Epoch 10/35\n",
      " - 1s - loss: 0.4036 - acc: 0.8413 - val_loss: 0.4116 - val_acc: 0.8407\n",
      "Epoch 11/35\n",
      " - 1s - loss: 0.4020 - acc: 0.8422 - val_loss: 0.4097 - val_acc: 0.8399\n",
      "Epoch 12/35\n",
      " - 1s - loss: 0.4006 - acc: 0.8431 - val_loss: 0.4123 - val_acc: 0.8403\n",
      "Epoch 13/35\n",
      " - 1s - loss: 0.3997 - acc: 0.8438 - val_loss: 0.4075 - val_acc: 0.8416\n",
      "Epoch 14/35\n",
      " - 1s - loss: 0.3985 - acc: 0.8440 - val_loss: 0.4085 - val_acc: 0.8411\n",
      "Epoch 15/35\n",
      " - 1s - loss: 0.3963 - acc: 0.8446 - val_loss: 0.4082 - val_acc: 0.8420\n",
      "Epoch 16/35\n",
      " - 1s - loss: 0.3960 - acc: 0.8446 - val_loss: 0.4103 - val_acc: 0.8427\n",
      "Epoch 17/35\n",
      " - 1s - loss: 0.3935 - acc: 0.8455 - val_loss: 0.4072 - val_acc: 0.8424\n",
      "Epoch 18/35\n",
      " - 1s - loss: 0.3932 - acc: 0.8461 - val_loss: 0.4100 - val_acc: 0.8435\n",
      "Epoch 19/35\n",
      " - 1s - loss: 0.3927 - acc: 0.8463 - val_loss: 0.4066 - val_acc: 0.8424\n",
      "Epoch 20/35\n",
      " - 1s - loss: 0.3904 - acc: 0.8472 - val_loss: 0.4083 - val_acc: 0.8420\n",
      "Epoch 21/35\n",
      " - 1s - loss: 0.3887 - acc: 0.8472 - val_loss: 0.4077 - val_acc: 0.8419\n",
      "Epoch 22/35\n",
      " - 1s - loss: 0.3873 - acc: 0.8477 - val_loss: 0.4167 - val_acc: 0.8431\n",
      "Epoch 23/35\n",
      " - 1s - loss: 0.3859 - acc: 0.8482 - val_loss: 0.4123 - val_acc: 0.8417\n",
      "Epoch 24/35\n",
      " - 1s - loss: 0.3845 - acc: 0.8483 - val_loss: 0.4138 - val_acc: 0.8391\n",
      "Epoch 25/35\n",
      " - 1s - loss: 0.3830 - acc: 0.8497 - val_loss: 0.4199 - val_acc: 0.8413\n",
      "Epoch 26/35\n",
      " - 1s - loss: 0.3807 - acc: 0.8492 - val_loss: 0.4180 - val_acc: 0.8410\n",
      "Epoch 27/35\n",
      " - 1s - loss: 0.3787 - acc: 0.8510 - val_loss: 0.4128 - val_acc: 0.8407\n",
      "Epoch 28/35\n",
      " - 1s - loss: 0.3769 - acc: 0.8505 - val_loss: 0.4124 - val_acc: 0.8410\n",
      "Epoch 29/35\n",
      " - 1s - loss: 0.3759 - acc: 0.8516 - val_loss: 0.4183 - val_acc: 0.8410\n",
      "Epoch 30/35\n",
      " - 1s - loss: 0.3732 - acc: 0.8521 - val_loss: 0.4183 - val_acc: 0.8404\n",
      "Epoch 31/35\n",
      " - 1s - loss: 0.3712 - acc: 0.8533 - val_loss: 0.4202 - val_acc: 0.8415\n",
      "Epoch 32/35\n",
      " - 1s - loss: 0.3704 - acc: 0.8532 - val_loss: 0.4182 - val_acc: 0.8407\n",
      "Epoch 33/35\n",
      " - 1s - loss: 0.3670 - acc: 0.8553 - val_loss: 0.4213 - val_acc: 0.8406\n",
      "Epoch 34/35\n",
      " - 1s - loss: 0.3660 - acc: 0.8541 - val_loss: 0.4244 - val_acc: 0.8390\n",
      "Epoch 35/35\n",
      " - 1s - loss: 0.3627 - acc: 0.8550 - val_loss: 0.4241 - val_acc: 0.8387\n",
      "va acc: 0.8348125\n",
      "te acc: 0.8387\n",
      "2018-09-18 22:54:23.245545 stack:3/5\n",
      "Train on 64000 samples, validate on 20000 samples\n",
      "Epoch 1/35\n",
      " - 2s - loss: 0.4366 - acc: 0.8270 - val_loss: 0.4290 - val_acc: 0.8374\n",
      "Epoch 2/35\n",
      " - 1s - loss: 0.4247 - acc: 0.8345 - val_loss: 0.4252 - val_acc: 0.8345\n",
      "Epoch 3/35\n",
      " - 1s - loss: 0.4203 - acc: 0.8363 - val_loss: 0.4224 - val_acc: 0.8369\n",
      "Epoch 4/35\n",
      " - 1s - loss: 0.4159 - acc: 0.8381 - val_loss: 0.4171 - val_acc: 0.8381\n",
      "Epoch 5/35\n",
      " - 1s - loss: 0.4120 - acc: 0.8385 - val_loss: 0.4141 - val_acc: 0.8365\n",
      "Epoch 6/35\n",
      " - 1s - loss: 0.4087 - acc: 0.8398 - val_loss: 0.4111 - val_acc: 0.8395\n",
      "Epoch 7/35\n",
      " - 1s - loss: 0.4064 - acc: 0.8397 - val_loss: 0.4098 - val_acc: 0.8394\n",
      "Epoch 8/35\n",
      " - 1s - loss: 0.4051 - acc: 0.8408 - val_loss: 0.4116 - val_acc: 0.8406\n",
      "Epoch 9/35\n",
      " - 1s - loss: 0.4036 - acc: 0.8407 - val_loss: 0.4079 - val_acc: 0.8397\n",
      "Epoch 10/35\n",
      " - 1s - loss: 0.4026 - acc: 0.8417 - val_loss: 0.4067 - val_acc: 0.8411\n",
      "Epoch 11/35\n",
      " - 1s - loss: 0.4007 - acc: 0.8424 - val_loss: 0.4112 - val_acc: 0.8412\n",
      "Epoch 12/35\n",
      " - 1s - loss: 0.4002 - acc: 0.8417 - val_loss: 0.4063 - val_acc: 0.8408\n",
      "Epoch 13/35\n",
      " - 1s - loss: 0.3984 - acc: 0.8426 - val_loss: 0.4084 - val_acc: 0.8416\n",
      "Epoch 14/35\n",
      " - 1s - loss: 0.3965 - acc: 0.8434 - val_loss: 0.4074 - val_acc: 0.8414\n",
      "Epoch 15/35\n",
      " - 1s - loss: 0.3951 - acc: 0.8451 - val_loss: 0.4052 - val_acc: 0.8431\n",
      "Epoch 16/35\n",
      " - 1s - loss: 0.3936 - acc: 0.8446 - val_loss: 0.4090 - val_acc: 0.8417\n",
      "Epoch 17/35\n",
      " - 1s - loss: 0.3936 - acc: 0.8445 - val_loss: 0.4108 - val_acc: 0.8416\n",
      "Epoch 18/35\n",
      " - 1s - loss: 0.3925 - acc: 0.8456 - val_loss: 0.4041 - val_acc: 0.8427\n",
      "Epoch 19/35\n",
      " - 1s - loss: 0.3900 - acc: 0.8463 - val_loss: 0.4061 - val_acc: 0.8425\n",
      "Epoch 20/35\n",
      " - 1s - loss: 0.3897 - acc: 0.8467 - val_loss: 0.4094 - val_acc: 0.8431\n",
      "Epoch 21/35\n",
      " - 1s - loss: 0.3872 - acc: 0.8468 - val_loss: 0.4090 - val_acc: 0.8426\n",
      "Epoch 22/35\n",
      " - 1s - loss: 0.3867 - acc: 0.8466 - val_loss: 0.4067 - val_acc: 0.8431\n",
      "Epoch 23/35\n",
      " - 1s - loss: 0.3833 - acc: 0.8484 - val_loss: 0.4187 - val_acc: 0.8430\n",
      "Epoch 24/35\n",
      " - 1s - loss: 0.3816 - acc: 0.8484 - val_loss: 0.4198 - val_acc: 0.8399\n",
      "Epoch 25/35\n",
      " - 1s - loss: 0.3809 - acc: 0.8483 - val_loss: 0.4099 - val_acc: 0.8418\n",
      "Epoch 26/35\n",
      " - 1s - loss: 0.3785 - acc: 0.8488 - val_loss: 0.4112 - val_acc: 0.8415\n",
      "Epoch 27/35\n",
      " - 1s - loss: 0.3768 - acc: 0.8497 - val_loss: 0.4123 - val_acc: 0.8397\n",
      "Epoch 28/35\n",
      " - 1s - loss: 0.3748 - acc: 0.8500 - val_loss: 0.4122 - val_acc: 0.8428\n",
      "Epoch 29/35\n",
      " - 1s - loss: 0.3727 - acc: 0.8513 - val_loss: 0.4170 - val_acc: 0.8421\n",
      "Epoch 30/35\n",
      " - 1s - loss: 0.3702 - acc: 0.8510 - val_loss: 0.4140 - val_acc: 0.8422\n",
      "Epoch 31/35\n",
      " - 1s - loss: 0.3684 - acc: 0.8540 - val_loss: 0.4192 - val_acc: 0.8403\n",
      "Epoch 32/35\n",
      " - 1s - loss: 0.3664 - acc: 0.8530 - val_loss: 0.4190 - val_acc: 0.8410\n",
      "Epoch 33/35\n",
      " - 1s - loss: 0.3641 - acc: 0.8546 - val_loss: 0.4216 - val_acc: 0.8401\n",
      "Epoch 34/35\n",
      " - 1s - loss: 0.3607 - acc: 0.8560 - val_loss: 0.4181 - val_acc: 0.8403\n",
      "Epoch 35/35\n",
      " - 1s - loss: 0.3591 - acc: 0.8556 - val_loss: 0.4181 - val_acc: 0.8407\n",
      "va acc: 0.834\n",
      "te acc: 0.8407\n",
      "2018-09-18 22:55:13.249886 stack:4/5\n",
      "Train on 64000 samples, validate on 20000 samples\n",
      "Epoch 1/35\n",
      " - 2s - loss: 0.4389 - acc: 0.8250 - val_loss: 0.4282 - val_acc: 0.8352\n",
      "Epoch 2/35\n",
      " - 1s - loss: 0.4272 - acc: 0.8338 - val_loss: 0.4260 - val_acc: 0.8366\n",
      "Epoch 3/35\n",
      " - 1s - loss: 0.4223 - acc: 0.8364 - val_loss: 0.4269 - val_acc: 0.8377\n",
      "Epoch 4/35\n",
      " - 1s - loss: 0.4187 - acc: 0.8361 - val_loss: 0.4191 - val_acc: 0.8374\n",
      "Epoch 5/35\n",
      " - 1s - loss: 0.4152 - acc: 0.8377 - val_loss: 0.4174 - val_acc: 0.8381\n",
      "Epoch 6/35\n",
      " - 1s - loss: 0.4129 - acc: 0.8379 - val_loss: 0.4187 - val_acc: 0.8385\n",
      "Epoch 7/35\n",
      " - 1s - loss: 0.4094 - acc: 0.8399 - val_loss: 0.4140 - val_acc: 0.8395\n",
      "Epoch 8/35\n",
      " - 1s - loss: 0.4076 - acc: 0.8402 - val_loss: 0.4100 - val_acc: 0.8393\n",
      "Epoch 9/35\n",
      " - 1s - loss: 0.4057 - acc: 0.8396 - val_loss: 0.4100 - val_acc: 0.8412\n",
      "Epoch 10/35\n",
      " - 1s - loss: 0.4036 - acc: 0.8414 - val_loss: 0.4107 - val_acc: 0.8405\n",
      "Epoch 11/35\n",
      " - 1s - loss: 0.4026 - acc: 0.8420 - val_loss: 0.4071 - val_acc: 0.8411\n",
      "Epoch 12/35\n",
      " - 1s - loss: 0.4010 - acc: 0.8423 - val_loss: 0.4084 - val_acc: 0.8417\n",
      "Epoch 13/35\n",
      " - 1s - loss: 0.3995 - acc: 0.8434 - val_loss: 0.4064 - val_acc: 0.8421\n",
      "Epoch 14/35\n",
      " - 1s - loss: 0.3982 - acc: 0.8437 - val_loss: 0.4076 - val_acc: 0.8414\n",
      "Epoch 15/35\n",
      " - 1s - loss: 0.3967 - acc: 0.8438 - val_loss: 0.4076 - val_acc: 0.8413\n",
      "Epoch 16/35\n",
      " - 1s - loss: 0.3950 - acc: 0.8450 - val_loss: 0.4061 - val_acc: 0.8424\n",
      "Epoch 17/35\n",
      " - 1s - loss: 0.3945 - acc: 0.8446 - val_loss: 0.4108 - val_acc: 0.8397\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/35\n",
      " - 1s - loss: 0.3934 - acc: 0.8446 - val_loss: 0.4111 - val_acc: 0.8424\n",
      "Epoch 19/35\n",
      " - 1s - loss: 0.3920 - acc: 0.8456 - val_loss: 0.4099 - val_acc: 0.8420\n",
      "Epoch 20/35\n",
      " - 1s - loss: 0.3910 - acc: 0.8457 - val_loss: 0.4051 - val_acc: 0.8417\n",
      "Epoch 21/35\n",
      " - 1s - loss: 0.3876 - acc: 0.8467 - val_loss: 0.4076 - val_acc: 0.8427\n",
      "Epoch 22/35\n",
      " - 1s - loss: 0.3881 - acc: 0.8462 - val_loss: 0.4096 - val_acc: 0.8432\n",
      "Epoch 23/35\n",
      " - 1s - loss: 0.3856 - acc: 0.8480 - val_loss: 0.4099 - val_acc: 0.8435\n",
      "Epoch 24/35\n",
      " - 1s - loss: 0.3838 - acc: 0.8475 - val_loss: 0.4195 - val_acc: 0.8394\n",
      "Epoch 25/35\n",
      " - 1s - loss: 0.3827 - acc: 0.8475 - val_loss: 0.4122 - val_acc: 0.8404\n",
      "Epoch 26/35\n",
      " - 1s - loss: 0.3815 - acc: 0.8480 - val_loss: 0.4098 - val_acc: 0.8422\n",
      "Epoch 27/35\n",
      " - 1s - loss: 0.3786 - acc: 0.8501 - val_loss: 0.4159 - val_acc: 0.8420\n",
      "Epoch 28/35\n",
      " - 1s - loss: 0.3774 - acc: 0.8500 - val_loss: 0.4112 - val_acc: 0.8411\n",
      "Epoch 29/35\n",
      " - 1s - loss: 0.3758 - acc: 0.8500 - val_loss: 0.4192 - val_acc: 0.8378\n",
      "Epoch 30/35\n",
      " - 1s - loss: 0.3736 - acc: 0.8507 - val_loss: 0.4135 - val_acc: 0.8415\n",
      "Epoch 31/35\n",
      " - 1s - loss: 0.3712 - acc: 0.8524 - val_loss: 0.4143 - val_acc: 0.8412\n",
      "Epoch 32/35\n",
      " - 1s - loss: 0.3703 - acc: 0.8512 - val_loss: 0.4174 - val_acc: 0.8412\n",
      "Epoch 33/35\n",
      " - 1s - loss: 0.3673 - acc: 0.8528 - val_loss: 0.4160 - val_acc: 0.8415\n",
      "Epoch 34/35\n",
      " - 1s - loss: 0.3659 - acc: 0.8534 - val_loss: 0.4176 - val_acc: 0.8384\n",
      "Epoch 35/35\n",
      " - 1s - loss: 0.3639 - acc: 0.8536 - val_loss: 0.4231 - val_acc: 0.8378\n",
      "va acc: 0.8380625\n",
      "te acc: 0.8378\n",
      "2018-09-18 22:56:03.484323 stack:5/5\n",
      "Train on 64000 samples, validate on 20000 samples\n",
      "Epoch 1/35\n",
      " - 2s - loss: 0.4418 - acc: 0.8229 - val_loss: 0.4284 - val_acc: 0.8343\n",
      "Epoch 2/35\n",
      " - 1s - loss: 0.4282 - acc: 0.8327 - val_loss: 0.4278 - val_acc: 0.8309\n",
      "Epoch 3/35\n",
      " - 2s - loss: 0.4237 - acc: 0.8352 - val_loss: 0.4204 - val_acc: 0.8369\n",
      "Epoch 4/35\n",
      " - 1s - loss: 0.4200 - acc: 0.8353 - val_loss: 0.4188 - val_acc: 0.8357\n",
      "Epoch 5/35\n",
      " - 1s - loss: 0.4171 - acc: 0.8364 - val_loss: 0.4156 - val_acc: 0.8388\n",
      "Epoch 6/35\n",
      " - 1s - loss: 0.4138 - acc: 0.8364 - val_loss: 0.4150 - val_acc: 0.8370\n",
      "Epoch 7/35\n",
      " - 1s - loss: 0.4103 - acc: 0.8376 - val_loss: 0.4119 - val_acc: 0.8388\n",
      "Epoch 8/35\n",
      " - 1s - loss: 0.4084 - acc: 0.8394 - val_loss: 0.4115 - val_acc: 0.8399\n",
      "Epoch 9/35\n",
      " - 1s - loss: 0.4068 - acc: 0.8397 - val_loss: 0.4095 - val_acc: 0.8384\n",
      "Epoch 10/35\n",
      " - 1s - loss: 0.4051 - acc: 0.8407 - val_loss: 0.4101 - val_acc: 0.8407\n",
      "Epoch 11/35\n",
      " - 1s - loss: 0.4041 - acc: 0.8402 - val_loss: 0.4084 - val_acc: 0.8414\n",
      "Epoch 12/35\n",
      " - 1s - loss: 0.4023 - acc: 0.8416 - val_loss: 0.4093 - val_acc: 0.8414\n",
      "Epoch 13/35\n",
      " - 1s - loss: 0.4012 - acc: 0.8418 - val_loss: 0.4072 - val_acc: 0.8414\n",
      "Epoch 14/35\n",
      " - 1s - loss: 0.4001 - acc: 0.8420 - val_loss: 0.4072 - val_acc: 0.8417\n",
      "Epoch 15/35\n",
      " - 1s - loss: 0.3986 - acc: 0.8423 - val_loss: 0.4089 - val_acc: 0.8431\n",
      "Epoch 16/35\n",
      " - 1s - loss: 0.3967 - acc: 0.8433 - val_loss: 0.4066 - val_acc: 0.8423\n",
      "Epoch 17/35\n",
      " - 1s - loss: 0.3968 - acc: 0.8434 - val_loss: 0.4066 - val_acc: 0.8409\n",
      "Epoch 18/35\n",
      " - 1s - loss: 0.3943 - acc: 0.8451 - val_loss: 0.4076 - val_acc: 0.8428\n",
      "Epoch 19/35\n",
      " - 1s - loss: 0.3932 - acc: 0.8449 - val_loss: 0.4091 - val_acc: 0.8434\n",
      "Epoch 20/35\n",
      " - 1s - loss: 0.3921 - acc: 0.8452 - val_loss: 0.4149 - val_acc: 0.8408\n",
      "Epoch 21/35\n",
      " - 1s - loss: 0.3913 - acc: 0.8460 - val_loss: 0.4074 - val_acc: 0.8418\n",
      "Epoch 22/35\n",
      " - 1s - loss: 0.3888 - acc: 0.8458 - val_loss: 0.4062 - val_acc: 0.8421\n",
      "Epoch 23/35\n",
      " - 1s - loss: 0.3873 - acc: 0.8461 - val_loss: 0.4128 - val_acc: 0.8438\n",
      "Epoch 24/35\n",
      " - 1s - loss: 0.3859 - acc: 0.8466 - val_loss: 0.4098 - val_acc: 0.8433\n",
      "Epoch 25/35\n",
      " - 1s - loss: 0.3849 - acc: 0.8472 - val_loss: 0.4093 - val_acc: 0.8410\n",
      "Epoch 26/35\n",
      " - 1s - loss: 0.3830 - acc: 0.8488 - val_loss: 0.4127 - val_acc: 0.8421\n",
      "Epoch 27/35\n",
      " - 1s - loss: 0.3809 - acc: 0.8483 - val_loss: 0.4189 - val_acc: 0.8417\n",
      "Epoch 28/35\n",
      " - 1s - loss: 0.3790 - acc: 0.8491 - val_loss: 0.4103 - val_acc: 0.8408\n",
      "Epoch 29/35\n",
      " - 1s - loss: 0.3766 - acc: 0.8502 - val_loss: 0.4124 - val_acc: 0.8417\n",
      "Epoch 30/35\n",
      " - 1s - loss: 0.3762 - acc: 0.8501 - val_loss: 0.4122 - val_acc: 0.8410\n",
      "Epoch 31/35\n",
      " - 1s - loss: 0.3737 - acc: 0.8504 - val_loss: 0.4126 - val_acc: 0.8408\n",
      "Epoch 32/35\n",
      " - 1s - loss: 0.3713 - acc: 0.8507 - val_loss: 0.4236 - val_acc: 0.8389\n",
      "Epoch 33/35\n",
      " - 1s - loss: 0.3686 - acc: 0.8532 - val_loss: 0.4170 - val_acc: 0.8389\n",
      "Epoch 34/35\n",
      " - 1s - loss: 0.3677 - acc: 0.8524 - val_loss: 0.4198 - val_acc: 0.8397\n",
      "Epoch 35/35\n",
      " - 1s - loss: 0.3660 - acc: 0.8535 - val_loss: 0.4197 - val_acc: 0.8406\n",
      "va acc: 0.8444375\n",
      "te acc: 0.84055\n",
      "2018-09-18 22:56:57.350828 save dbowd2v stack done!\n"
     ]
    }
   ],
   "source": [
    "# ----------------------dbowd2v stack for Education/age/gender---------------------------\n",
    "df_stack = pd.DataFrame(index=range(len(df_all)))\n",
    "TR = 80000\n",
    "n = 5\n",
    "\n",
    "X = X_sp[:TR]\n",
    "X_te = X_sp[TR:]\n",
    "\n",
    "feat = 'dbowd2v'\n",
    "for i,lb in enumerate(['Education','age','gender']):\n",
    "    num_class = len(pd.value_counts(ys[lb]))\n",
    "    y = ys[lb][:TR]\n",
    "    y_te = ys[lb][TR:]\n",
    "    \n",
    "    stack = np.zeros((X.shape[0],num_class))\n",
    "    stack_te = np.zeros((X_te.shape[0],num_class))\n",
    "    \n",
    "    for k,(tr,va) in enumerate(KFold(len(y),n_folds=n)):\n",
    "        print('{} stack:{}/{}'.format(datetime.now(),k+1,n))\n",
    "        nb_classes = num_class\n",
    "        X_train = X[tr]\n",
    "        y_train = y[tr]\n",
    "        X_test = X_te\n",
    "        y_test = y_te\n",
    "\n",
    "        X_train = X_train.astype('float32')\n",
    "        X_test = X_test.astype('float32')\n",
    "        Y_train = np_utils.to_categorical(y_train, nb_classes)\n",
    "        Y_test = np_utils.to_categorical(y_test, nb_classes)\n",
    "\n",
    "\n",
    "        model = Sequential()\n",
    "        model.add(Dense(300,input_shape=(X_train.shape[1],)))\n",
    "        model.add(Dropout(0.1))\n",
    "        model.add(Activation('tanh'))\n",
    "        model.add(Dense(nb_classes))\n",
    "        model.add(Activation('softmax'))\n",
    "\n",
    "        model.compile(loss='categorical_crossentropy',\n",
    "                      optimizer='adadelta',\n",
    "                      metrics=['accuracy'])\n",
    "\n",
    "        history = model.fit(X_train, Y_train,shuffle=True,\n",
    "                            batch_size=128, nb_epoch=35,\n",
    "                            verbose=2, validation_data=(X_test, Y_test))\n",
    "        y_pred_va = model.predict_proba(X[va])\n",
    "        y_pred_te = model.predict_proba(X_te)\n",
    "        print('va acc:',myAcc(y[va],y_pred_va))\n",
    "        print('te acc:',myAcc(y_te,y_pred_te))\n",
    "        stack[va] += y_pred_va\n",
    "        stack_te += y_pred_te\n",
    "    stack_te /= n\n",
    "    stack_all = np.vstack([stack,stack_te])\n",
    "    for l in range(stack_all.shape[1]):\n",
    "        df_stack['{}_{}_{}'.format(feat,lb,l)] = stack_all[:,l]\n",
    "df_stack.to_csv(cfg.data_path + 'dbowd2v_stack_10W.csv',encoding='utf8',index=None)\n",
    "print(datetime.now(),'save dbowd2v stack done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''dm-nn stack for education/age/gender'''\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from sklearn.cross_validation import KFold\n",
    "from gensim.models import Doc2Vec\n",
    "from collections import OrderedDict\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.optimizers import SGD, Adam, RMSprop\n",
    "from keras.utils import np_utils\n",
    "import re\n",
    "import cfg\n",
    "\n",
    "#-----------------------myfunc-----------------------\n",
    "def myAcc(y_true,y_pred):\n",
    "    y_pred = np.argmax(y_pred,axis=1)\n",
    "    return np.mean(y_true == y_pred)\n",
    "\n",
    "#-----------------------load dataset----------------------\n",
    "df_all = pd.read_csv(cfg.data_path + 'all_v2.csv',encoding='utf8',usecols=['Id','Education','age','gender'],nrows=100000)\n",
    "ys = {}\n",
    "for label in ['Education','age','gender']:\n",
    "    ys[label] = np.array(df_all[label])\n",
    "    \n",
    "model = Doc2Vec.load(cfg.data_path + 'dm_d2v.model')\n",
    "X_sp = np.array([model.docvecs[i] for i in range(100000)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-09-18 23:02:12.276668 stack:1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sun\\Anaconda3\\lib\\site-packages\\keras\\models.py:942: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 64000 samples, validate on 20000 samples\n",
      "Epoch 1/35\n",
      " - 2s - loss: 1.0232 - acc: 0.5899 - val_loss: 0.9509 - val_acc: 0.6243\n",
      "Epoch 2/35\n",
      " - 2s - loss: 0.9356 - acc: 0.6279 - val_loss: 0.9436 - val_acc: 0.6282\n",
      "Epoch 3/35\n",
      " - 2s - loss: 0.9008 - acc: 0.6434 - val_loss: 0.9532 - val_acc: 0.6281\n",
      "Epoch 4/35\n",
      " - 2s - loss: 0.8658 - acc: 0.6585 - val_loss: 0.9523 - val_acc: 0.6290\n",
      "Epoch 5/35\n",
      " - 2s - loss: 0.8279 - acc: 0.6763 - val_loss: 0.9735 - val_acc: 0.6232\n",
      "Epoch 6/35\n",
      " - 2s - loss: 0.7829 - acc: 0.6952 - val_loss: 0.9761 - val_acc: 0.6280\n",
      "Epoch 7/35\n",
      " - 2s - loss: 0.7410 - acc: 0.7141 - val_loss: 1.0004 - val_acc: 0.6250\n",
      "Epoch 8/35\n",
      " - 2s - loss: 0.6979 - acc: 0.7341 - val_loss: 1.0287 - val_acc: 0.6180\n",
      "Epoch 9/35\n",
      " - 2s - loss: 0.6567 - acc: 0.7521 - val_loss: 1.0644 - val_acc: 0.6076\n",
      "Epoch 10/35\n",
      " - 2s - loss: 0.6216 - acc: 0.7629 - val_loss: 1.0977 - val_acc: 0.6100\n",
      "Epoch 11/35\n",
      " - 2s - loss: 0.5856 - acc: 0.7785 - val_loss: 1.1169 - val_acc: 0.6066\n",
      "Epoch 12/35\n",
      " - 2s - loss: 0.5527 - acc: 0.7914 - val_loss: 1.1427 - val_acc: 0.6013\n",
      "Epoch 13/35\n",
      " - 2s - loss: 0.5245 - acc: 0.8022 - val_loss: 1.1673 - val_acc: 0.6044\n",
      "Epoch 14/35\n",
      " - 2s - loss: 0.4989 - acc: 0.8108 - val_loss: 1.2133 - val_acc: 0.6041\n",
      "Epoch 15/35\n",
      " - 2s - loss: 0.4753 - acc: 0.8220 - val_loss: 1.2650 - val_acc: 0.5978\n",
      "Epoch 16/35\n",
      " - 2s - loss: 0.4578 - acc: 0.8275 - val_loss: 1.2739 - val_acc: 0.5881\n",
      "Epoch 17/35\n",
      " - 2s - loss: 0.4361 - acc: 0.8350 - val_loss: 1.3251 - val_acc: 0.5867\n",
      "Epoch 18/35\n",
      " - 2s - loss: 0.4223 - acc: 0.8404 - val_loss: 1.3424 - val_acc: 0.5898\n",
      "Epoch 19/35\n",
      " - 2s - loss: 0.4044 - acc: 0.8478 - val_loss: 1.3651 - val_acc: 0.5900\n",
      "Epoch 20/35\n",
      " - 2s - loss: 0.3889 - acc: 0.8528 - val_loss: 1.3843 - val_acc: 0.5837\n",
      "Epoch 21/35\n",
      " - 2s - loss: 0.3748 - acc: 0.8573 - val_loss: 1.4494 - val_acc: 0.5797\n",
      "Epoch 22/35\n",
      " - 2s - loss: 0.3611 - acc: 0.8651 - val_loss: 1.4527 - val_acc: 0.5868\n",
      "Epoch 23/35\n",
      " - 2s - loss: 0.3478 - acc: 0.8695 - val_loss: 1.5121 - val_acc: 0.5695\n",
      "Epoch 24/35\n",
      " - 2s - loss: 0.3383 - acc: 0.8740 - val_loss: 1.5320 - val_acc: 0.5849\n",
      "Epoch 25/35\n",
      " - 2s - loss: 0.3295 - acc: 0.8767 - val_loss: 1.5480 - val_acc: 0.5895\n",
      "Epoch 26/35\n",
      " - 2s - loss: 0.3200 - acc: 0.8798 - val_loss: 1.5945 - val_acc: 0.5767\n",
      "Epoch 27/35\n",
      " - 2s - loss: 0.3108 - acc: 0.8833 - val_loss: 1.5963 - val_acc: 0.5843\n",
      "Epoch 28/35\n",
      " - 2s - loss: 0.3022 - acc: 0.8870 - val_loss: 1.6179 - val_acc: 0.5862\n",
      "Epoch 29/35\n",
      " - 2s - loss: 0.2972 - acc: 0.8897 - val_loss: 1.6561 - val_acc: 0.5805\n",
      "Epoch 30/35\n",
      " - 2s - loss: 0.2888 - acc: 0.8906 - val_loss: 1.6580 - val_acc: 0.5828\n",
      "Epoch 31/35\n",
      " - 2s - loss: 0.2811 - acc: 0.8953 - val_loss: 1.7058 - val_acc: 0.5835\n",
      "Epoch 32/35\n",
      " - 2s - loss: 0.2705 - acc: 0.8981 - val_loss: 1.7540 - val_acc: 0.5858\n",
      "Epoch 33/35\n",
      " - 2s - loss: 0.2667 - acc: 0.9002 - val_loss: 1.7454 - val_acc: 0.5823\n",
      "Epoch 34/35\n",
      " - 2s - loss: 0.2586 - acc: 0.9035 - val_loss: 1.7706 - val_acc: 0.5851\n",
      "Epoch 35/35\n",
      " - 2s - loss: 0.2567 - acc: 0.9044 - val_loss: 1.7729 - val_acc: 0.5769\n",
      "va acc: 0.5555\n",
      "te acc: 0.5769\n",
      "2018-09-18 23:03:10.486889 stack:2/5\n",
      "Train on 64000 samples, validate on 20000 samples\n",
      "Epoch 1/35\n",
      " - 3s - loss: 1.0231 - acc: 0.5918 - val_loss: 0.9542 - val_acc: 0.6286\n",
      "Epoch 2/35\n",
      " - 2s - loss: 0.9342 - acc: 0.6291 - val_loss: 0.9513 - val_acc: 0.6244\n",
      "Epoch 3/35\n",
      " - 2s - loss: 0.8978 - acc: 0.6433 - val_loss: 0.9494 - val_acc: 0.6294\n",
      "Epoch 4/35\n",
      " - 2s - loss: 0.8618 - acc: 0.6586 - val_loss: 0.9520 - val_acc: 0.6271\n",
      "Epoch 5/35\n",
      " - 2s - loss: 0.8215 - acc: 0.6781 - val_loss: 0.9659 - val_acc: 0.6281\n",
      "Epoch 6/35\n",
      " - 2s - loss: 0.7780 - acc: 0.6975 - val_loss: 0.9905 - val_acc: 0.6244\n",
      "Epoch 7/35\n",
      " - 2s - loss: 0.7356 - acc: 0.7145 - val_loss: 1.0057 - val_acc: 0.6185\n",
      "Epoch 8/35\n",
      " - 2s - loss: 0.6926 - acc: 0.7321 - val_loss: 1.0386 - val_acc: 0.6095\n",
      "Epoch 9/35\n",
      " - 2s - loss: 0.6559 - acc: 0.7489 - val_loss: 1.0598 - val_acc: 0.6088\n",
      "Epoch 10/35\n",
      " - 2s - loss: 0.6151 - acc: 0.7657 - val_loss: 1.1008 - val_acc: 0.6098\n",
      "Epoch 11/35\n",
      " - 2s - loss: 0.5799 - acc: 0.7800 - val_loss: 1.1197 - val_acc: 0.5987\n",
      "Epoch 12/35\n",
      " - 2s - loss: 0.5484 - acc: 0.7920 - val_loss: 1.1780 - val_acc: 0.5933\n",
      "Epoch 13/35\n",
      " - 2s - loss: 0.5222 - acc: 0.8022 - val_loss: 1.2038 - val_acc: 0.6049\n",
      "Epoch 14/35\n",
      " - 2s - loss: 0.4982 - acc: 0.8120 - val_loss: 1.2171 - val_acc: 0.5986\n",
      "Epoch 15/35\n",
      " - 2s - loss: 0.4765 - acc: 0.8205 - val_loss: 1.2872 - val_acc: 0.5921\n",
      "Epoch 16/35\n",
      " - 2s - loss: 0.4527 - acc: 0.8292 - val_loss: 1.2950 - val_acc: 0.5955\n",
      "Epoch 17/35\n",
      " - 2s - loss: 0.4347 - acc: 0.8368 - val_loss: 1.3347 - val_acc: 0.5967\n",
      "Epoch 18/35\n",
      " - 2s - loss: 0.4161 - acc: 0.8427 - val_loss: 1.3710 - val_acc: 0.5984\n",
      "Epoch 19/35\n",
      " - 2s - loss: 0.4026 - acc: 0.8476 - val_loss: 1.3978 - val_acc: 0.5925\n",
      "Epoch 20/35\n",
      " - 2s - loss: 0.3822 - acc: 0.8565 - val_loss: 1.4023 - val_acc: 0.5878\n",
      "Epoch 21/35\n",
      " - 2s - loss: 0.3727 - acc: 0.8600 - val_loss: 1.4500 - val_acc: 0.5838\n",
      "Epoch 22/35\n",
      " - 2s - loss: 0.3573 - acc: 0.8639 - val_loss: 1.4795 - val_acc: 0.5914\n",
      "Epoch 23/35\n",
      " - 2s - loss: 0.3499 - acc: 0.8689 - val_loss: 1.5150 - val_acc: 0.5801\n",
      "Epoch 24/35\n",
      " - 2s - loss: 0.3369 - acc: 0.8736 - val_loss: 1.5419 - val_acc: 0.5876\n",
      "Epoch 25/35\n",
      " - 2s - loss: 0.3265 - acc: 0.8775 - val_loss: 1.5810 - val_acc: 0.5829\n",
      "Epoch 26/35\n",
      " - 2s - loss: 0.3169 - acc: 0.8807 - val_loss: 1.5874 - val_acc: 0.5794\n",
      "Epoch 27/35\n",
      " - 2s - loss: 0.3067 - acc: 0.8852 - val_loss: 1.6165 - val_acc: 0.5821\n",
      "Epoch 28/35\n",
      " - 2s - loss: 0.3011 - acc: 0.8870 - val_loss: 1.6505 - val_acc: 0.5888\n",
      "Epoch 29/35\n",
      " - 2s - loss: 0.2922 - acc: 0.8895 - val_loss: 1.6749 - val_acc: 0.5820\n",
      "Epoch 30/35\n",
      " - 2s - loss: 0.2836 - acc: 0.8934 - val_loss: 1.7224 - val_acc: 0.5849\n",
      "Epoch 31/35\n",
      " - 2s - loss: 0.2758 - acc: 0.8960 - val_loss: 1.7384 - val_acc: 0.5841\n",
      "Epoch 32/35\n",
      " - 2s - loss: 0.2679 - acc: 0.8993 - val_loss: 1.7524 - val_acc: 0.5836\n",
      "Epoch 33/35\n",
      " - 2s - loss: 0.2679 - acc: 0.8988 - val_loss: 1.7744 - val_acc: 0.5726\n",
      "Epoch 34/35\n",
      " - 2s - loss: 0.2558 - acc: 0.9037 - val_loss: 1.8037 - val_acc: 0.5824\n",
      "Epoch 35/35\n",
      " - 2s - loss: 0.2496 - acc: 0.9060 - val_loss: 1.8114 - val_acc: 0.5773\n",
      "va acc: 0.56225\n",
      "te acc: 0.5773\n",
      "2018-09-18 23:04:10.218319 stack:3/5\n",
      "Train on 64000 samples, validate on 20000 samples\n",
      "Epoch 1/35\n",
      " - 2s - loss: 1.0255 - acc: 0.5907 - val_loss: 0.9601 - val_acc: 0.6228\n",
      "Epoch 2/35\n",
      " - 2s - loss: 0.9350 - acc: 0.6304 - val_loss: 0.9526 - val_acc: 0.6268\n",
      "Epoch 3/35\n",
      " - 2s - loss: 0.8993 - acc: 0.6420 - val_loss: 0.9474 - val_acc: 0.6310\n",
      "Epoch 4/35\n",
      " - 2s - loss: 0.8635 - acc: 0.6595 - val_loss: 0.9531 - val_acc: 0.6323\n",
      "Epoch 5/35\n",
      " - 2s - loss: 0.8246 - acc: 0.6750 - val_loss: 0.9644 - val_acc: 0.6280\n",
      "Epoch 6/35\n",
      " - 2s - loss: 0.7790 - acc: 0.6957 - val_loss: 0.9862 - val_acc: 0.6235\n",
      "Epoch 7/35\n",
      " - 2s - loss: 0.7344 - acc: 0.7152 - val_loss: 1.0253 - val_acc: 0.6192\n",
      "Epoch 8/35\n",
      " - 2s - loss: 0.6907 - acc: 0.7346 - val_loss: 1.0307 - val_acc: 0.6113\n",
      "Epoch 9/35\n",
      " - 2s - loss: 0.6495 - acc: 0.7518 - val_loss: 1.0990 - val_acc: 0.6092\n",
      "Epoch 10/35\n",
      " - 2s - loss: 0.6128 - acc: 0.7680 - val_loss: 1.0809 - val_acc: 0.6087\n",
      "Epoch 11/35\n",
      " - 2s - loss: 0.5763 - acc: 0.7822 - val_loss: 1.1288 - val_acc: 0.6065\n",
      "Epoch 12/35\n",
      " - 2s - loss: 0.5445 - acc: 0.7950 - val_loss: 1.1510 - val_acc: 0.5978\n",
      "Epoch 13/35\n",
      " - 2s - loss: 0.5169 - acc: 0.8051 - val_loss: 1.1966 - val_acc: 0.6049\n",
      "Epoch 14/35\n",
      " - 2s - loss: 0.4943 - acc: 0.8135 - val_loss: 1.2141 - val_acc: 0.5998\n",
      "Epoch 15/35\n",
      " - 2s - loss: 0.4693 - acc: 0.8223 - val_loss: 1.2651 - val_acc: 0.5849\n",
      "Epoch 16/35\n",
      " - 2s - loss: 0.4500 - acc: 0.8300 - val_loss: 1.3095 - val_acc: 0.5968\n",
      "Epoch 17/35\n",
      " - 2s - loss: 0.4298 - acc: 0.8382 - val_loss: 1.3493 - val_acc: 0.5889\n",
      "Epoch 18/35\n",
      " - 2s - loss: 0.4149 - acc: 0.8445 - val_loss: 1.3589 - val_acc: 0.5797\n",
      "Epoch 19/35\n",
      " - 2s - loss: 0.3965 - acc: 0.8518 - val_loss: 1.3795 - val_acc: 0.5916\n",
      "Epoch 20/35\n",
      " - 2s - loss: 0.3846 - acc: 0.8562 - val_loss: 1.4026 - val_acc: 0.5828\n",
      "Epoch 21/35\n",
      " - 2s - loss: 0.3734 - acc: 0.8603 - val_loss: 1.4507 - val_acc: 0.5894\n",
      "Epoch 22/35\n",
      " - 2s - loss: 0.3579 - acc: 0.8651 - val_loss: 1.4582 - val_acc: 0.5839\n",
      "Epoch 23/35\n",
      " - 2s - loss: 0.3445 - acc: 0.8692 - val_loss: 1.5142 - val_acc: 0.5884\n",
      "Epoch 24/35\n",
      " - 2s - loss: 0.3342 - acc: 0.8751 - val_loss: 1.5210 - val_acc: 0.5874\n",
      "Epoch 25/35\n",
      " - 2s - loss: 0.3231 - acc: 0.8804 - val_loss: 1.5682 - val_acc: 0.5880\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/35\n",
      " - 2s - loss: 0.3167 - acc: 0.8799 - val_loss: 1.5832 - val_acc: 0.5874\n",
      "Epoch 27/35\n",
      " - 2s - loss: 0.3051 - acc: 0.8853 - val_loss: 1.6142 - val_acc: 0.5824\n",
      "Epoch 28/35\n",
      " - 2s - loss: 0.2983 - acc: 0.8873 - val_loss: 1.6622 - val_acc: 0.5861\n",
      "Epoch 29/35\n",
      " - 2s - loss: 0.2888 - acc: 0.8910 - val_loss: 1.6841 - val_acc: 0.5707\n",
      "Epoch 30/35\n",
      " - 2s - loss: 0.2823 - acc: 0.8939 - val_loss: 1.6784 - val_acc: 0.5869\n",
      "Epoch 31/35\n",
      " - 2s - loss: 0.2767 - acc: 0.8961 - val_loss: 1.7360 - val_acc: 0.5812\n",
      "Epoch 32/35\n",
      " - 2s - loss: 0.2681 - acc: 0.9000 - val_loss: 1.7248 - val_acc: 0.5839\n",
      "Epoch 33/35\n",
      " - 2s - loss: 0.2620 - acc: 0.9027 - val_loss: 1.7810 - val_acc: 0.5859\n",
      "Epoch 34/35\n",
      " - 2s - loss: 0.2566 - acc: 0.9041 - val_loss: 1.7654 - val_acc: 0.5844\n",
      "Epoch 35/35\n",
      " - 2s - loss: 0.2506 - acc: 0.9060 - val_loss: 1.7926 - val_acc: 0.5798\n",
      "va acc: 0.55875\n",
      "te acc: 0.5798\n",
      "2018-09-18 23:05:08.484074 stack:4/5\n",
      "Train on 64000 samples, validate on 20000 samples\n",
      "Epoch 1/35\n",
      " - 2s - loss: 1.0276 - acc: 0.5895 - val_loss: 0.9556 - val_acc: 0.6248\n",
      "Epoch 2/35\n",
      " - 2s - loss: 0.9367 - acc: 0.6283 - val_loss: 0.9504 - val_acc: 0.6260\n",
      "Epoch 3/35\n",
      " - 2s - loss: 0.8982 - acc: 0.6457 - val_loss: 0.9457 - val_acc: 0.6288\n",
      "Epoch 4/35\n",
      " - 2s - loss: 0.8611 - acc: 0.6605 - val_loss: 0.9533 - val_acc: 0.6285\n",
      "Epoch 5/35\n",
      " - 2s - loss: 0.8191 - acc: 0.6794 - val_loss: 0.9681 - val_acc: 0.6270\n",
      "Epoch 6/35\n",
      " - 2s - loss: 0.7752 - acc: 0.6986 - val_loss: 0.9989 - val_acc: 0.6152\n",
      "Epoch 7/35\n",
      " - 2s - loss: 0.7334 - acc: 0.7162 - val_loss: 1.0007 - val_acc: 0.6200\n",
      "Epoch 8/35\n",
      " - 2s - loss: 0.6874 - acc: 0.7376 - val_loss: 1.0375 - val_acc: 0.6180\n",
      "Epoch 9/35\n",
      " - 2s - loss: 0.6508 - acc: 0.7500 - val_loss: 1.0730 - val_acc: 0.6150\n",
      "Epoch 10/35\n",
      " - 2s - loss: 0.6105 - acc: 0.7691 - val_loss: 1.1012 - val_acc: 0.6050\n",
      "Epoch 11/35\n",
      " - 2s - loss: 0.5792 - acc: 0.7814 - val_loss: 1.1366 - val_acc: 0.6095\n",
      "Epoch 12/35\n",
      " - 2s - loss: 0.5494 - acc: 0.7915 - val_loss: 1.1615 - val_acc: 0.6040\n",
      "Epoch 13/35\n",
      " - 2s - loss: 0.5215 - acc: 0.8034 - val_loss: 1.1910 - val_acc: 0.6056\n",
      "Epoch 14/35\n",
      " - 2s - loss: 0.4936 - acc: 0.8132 - val_loss: 1.2122 - val_acc: 0.6012\n",
      "Epoch 15/35\n",
      " - 2s - loss: 0.4725 - acc: 0.8212 - val_loss: 1.2605 - val_acc: 0.5999\n",
      "Epoch 16/35\n",
      " - 2s - loss: 0.4533 - acc: 0.8295 - val_loss: 1.2833 - val_acc: 0.5924\n",
      "Epoch 17/35\n",
      " - 2s - loss: 0.4335 - acc: 0.8357 - val_loss: 1.3119 - val_acc: 0.5924\n",
      "Epoch 18/35\n",
      " - 2s - loss: 0.4184 - acc: 0.8427 - val_loss: 1.4013 - val_acc: 0.5788\n",
      "Epoch 19/35\n",
      " - 2s - loss: 0.4020 - acc: 0.8501 - val_loss: 1.3767 - val_acc: 0.5850\n",
      "Epoch 20/35\n",
      " - 2s - loss: 0.3850 - acc: 0.8553 - val_loss: 1.4091 - val_acc: 0.5913\n",
      "Epoch 21/35\n",
      " - 2s - loss: 0.3723 - acc: 0.8578 - val_loss: 1.4326 - val_acc: 0.5881\n",
      "Epoch 22/35\n",
      " - 2s - loss: 0.3587 - acc: 0.8641 - val_loss: 1.4927 - val_acc: 0.5769\n",
      "Epoch 23/35\n",
      " - 2s - loss: 0.3492 - acc: 0.8690 - val_loss: 1.5115 - val_acc: 0.5823\n",
      "Epoch 24/35\n",
      " - 2s - loss: 0.3358 - acc: 0.8731 - val_loss: 1.5309 - val_acc: 0.5858\n",
      "Epoch 25/35\n",
      " - 2s - loss: 0.3284 - acc: 0.8770 - val_loss: 1.5365 - val_acc: 0.5857\n",
      "Epoch 26/35\n",
      " - 2s - loss: 0.3123 - acc: 0.8822 - val_loss: 1.5798 - val_acc: 0.5760\n",
      "Epoch 27/35\n",
      " - 2s - loss: 0.3088 - acc: 0.8832 - val_loss: 1.6094 - val_acc: 0.5819\n",
      "Epoch 28/35\n",
      " - 2s - loss: 0.2957 - acc: 0.8890 - val_loss: 1.6323 - val_acc: 0.5823\n",
      "Epoch 29/35\n",
      " - 2s - loss: 0.2921 - acc: 0.8905 - val_loss: 1.6557 - val_acc: 0.5814\n",
      "Epoch 30/35\n",
      " - 2s - loss: 0.2824 - acc: 0.8938 - val_loss: 1.6814 - val_acc: 0.5766\n",
      "Epoch 31/35\n",
      " - 2s - loss: 0.2760 - acc: 0.8959 - val_loss: 1.7197 - val_acc: 0.5823\n",
      "Epoch 32/35\n",
      " - 2s - loss: 0.2701 - acc: 0.8972 - val_loss: 1.7381 - val_acc: 0.5754\n",
      "Epoch 33/35\n",
      " - 2s - loss: 0.2649 - acc: 0.9008 - val_loss: 1.7754 - val_acc: 0.5840\n",
      "Epoch 34/35\n",
      " - 2s - loss: 0.2614 - acc: 0.9017 - val_loss: 1.7850 - val_acc: 0.5828\n",
      "Epoch 35/35\n",
      " - 2s - loss: 0.2530 - acc: 0.9060 - val_loss: 1.8256 - val_acc: 0.5837\n",
      "va acc: 0.5748125\n",
      "te acc: 0.5837\n",
      "2018-09-18 23:06:05.546341 stack:5/5\n",
      "Train on 64000 samples, validate on 20000 samples\n",
      "Epoch 1/35\n",
      " - 2s - loss: 1.0269 - acc: 0.5912 - val_loss: 0.9530 - val_acc: 0.6262\n",
      "Epoch 2/35\n",
      " - 2s - loss: 0.9357 - acc: 0.6302 - val_loss: 0.9520 - val_acc: 0.6271\n",
      "Epoch 3/35\n",
      " - 2s - loss: 0.8994 - acc: 0.6437 - val_loss: 0.9526 - val_acc: 0.6292\n",
      "Epoch 4/35\n",
      " - 2s - loss: 0.8636 - acc: 0.6579 - val_loss: 0.9563 - val_acc: 0.6308\n",
      "Epoch 5/35\n",
      " - 2s - loss: 0.8221 - acc: 0.6797 - val_loss: 0.9697 - val_acc: 0.6308\n",
      "Epoch 6/35\n",
      " - 2s - loss: 0.7766 - acc: 0.6984 - val_loss: 0.9826 - val_acc: 0.6260\n",
      "Epoch 7/35\n",
      " - 2s - loss: 0.7323 - acc: 0.7177 - val_loss: 1.0259 - val_acc: 0.6138\n",
      "Epoch 8/35\n",
      " - 2s - loss: 0.6870 - acc: 0.7375 - val_loss: 1.0527 - val_acc: 0.6106\n",
      "Epoch 9/35\n",
      " - 2s - loss: 0.6458 - acc: 0.7536 - val_loss: 1.0895 - val_acc: 0.6166\n",
      "Epoch 10/35\n",
      " - 2s - loss: 0.6076 - acc: 0.7688 - val_loss: 1.1008 - val_acc: 0.6065\n",
      "Epoch 11/35\n",
      " - 2s - loss: 0.5741 - acc: 0.7811 - val_loss: 1.1210 - val_acc: 0.6095\n",
      "Epoch 12/35\n",
      " - 2s - loss: 0.5428 - acc: 0.7948 - val_loss: 1.1538 - val_acc: 0.6031\n",
      "Epoch 13/35\n",
      " - 2s - loss: 0.5163 - acc: 0.8060 - val_loss: 1.2142 - val_acc: 0.5980\n",
      "Epoch 14/35\n",
      " - 2s - loss: 0.4901 - acc: 0.8151 - val_loss: 1.2581 - val_acc: 0.6049\n",
      "Epoch 15/35\n",
      " - 2s - loss: 0.4733 - acc: 0.8213 - val_loss: 1.2614 - val_acc: 0.5999\n",
      "Epoch 16/35\n",
      " - 2s - loss: 0.4494 - acc: 0.8298 - val_loss: 1.2864 - val_acc: 0.5937\n",
      "Epoch 17/35\n",
      " - 2s - loss: 0.4301 - acc: 0.8383 - val_loss: 1.3130 - val_acc: 0.5955\n",
      "Epoch 18/35\n",
      " - 2s - loss: 0.4113 - acc: 0.8439 - val_loss: 1.3528 - val_acc: 0.5978\n",
      "Epoch 19/35\n",
      " - 2s - loss: 0.3984 - acc: 0.8497 - val_loss: 1.3897 - val_acc: 0.5920\n",
      "Epoch 20/35\n",
      " - 2s - loss: 0.3813 - acc: 0.8565 - val_loss: 1.4094 - val_acc: 0.5930\n",
      "Epoch 21/35\n",
      " - 2s - loss: 0.3687 - acc: 0.8604 - val_loss: 1.4552 - val_acc: 0.5956\n",
      "Epoch 22/35\n",
      " - 2s - loss: 0.3588 - acc: 0.8645 - val_loss: 1.4844 - val_acc: 0.5875\n",
      "Epoch 23/35\n",
      " - 2s - loss: 0.3477 - acc: 0.8695 - val_loss: 1.4901 - val_acc: 0.5857\n",
      "Epoch 24/35\n",
      " - 2s - loss: 0.3270 - acc: 0.8764 - val_loss: 1.5483 - val_acc: 0.5910\n",
      "Epoch 25/35\n",
      " - 2s - loss: 0.3254 - acc: 0.8768 - val_loss: 1.5607 - val_acc: 0.5871\n",
      "Epoch 26/35\n",
      " - 2s - loss: 0.3154 - acc: 0.8807 - val_loss: 1.5856 - val_acc: 0.5854\n",
      "Epoch 27/35\n",
      " - 2s - loss: 0.3044 - acc: 0.8842 - val_loss: 1.6040 - val_acc: 0.5863\n",
      "Epoch 28/35\n",
      " - 2s - loss: 0.2943 - acc: 0.8897 - val_loss: 1.6358 - val_acc: 0.5841\n",
      "Epoch 29/35\n",
      " - 2s - loss: 0.2909 - acc: 0.8912 - val_loss: 1.6910 - val_acc: 0.5885\n",
      "Epoch 30/35\n",
      " - 2s - loss: 0.2779 - acc: 0.8969 - val_loss: 1.7064 - val_acc: 0.5846\n",
      "Epoch 31/35\n",
      " - 2s - loss: 0.2765 - acc: 0.8957 - val_loss: 1.7053 - val_acc: 0.5829\n",
      "Epoch 32/35\n",
      " - 2s - loss: 0.2666 - acc: 0.9002 - val_loss: 1.7719 - val_acc: 0.5836\n",
      "Epoch 33/35\n",
      " - 2s - loss: 0.2653 - acc: 0.9000 - val_loss: 1.7811 - val_acc: 0.5907\n",
      "Epoch 34/35\n",
      " - 2s - loss: 0.2549 - acc: 0.9040 - val_loss: 1.7547 - val_acc: 0.5791\n",
      "Epoch 35/35\n",
      " - 2s - loss: 0.2525 - acc: 0.9047 - val_loss: 1.8047 - val_acc: 0.5841\n",
      "va acc: 0.5709375\n",
      "te acc: 0.5841\n",
      "2018-09-18 23:07:03.644262 stack:1/5\n",
      "Train on 64000 samples, validate on 20000 samples\n",
      "Epoch 1/35\n",
      " - 2s - loss: 1.1455 - acc: 0.5510 - val_loss: 1.0773 - val_acc: 0.5765\n",
      "Epoch 2/35\n",
      " - 2s - loss: 1.0477 - acc: 0.5902 - val_loss: 1.0563 - val_acc: 0.5865\n",
      "Epoch 3/35\n",
      " - 2s - loss: 1.0062 - acc: 0.6083 - val_loss: 1.0532 - val_acc: 0.5910\n",
      "Epoch 4/35\n",
      " - 2s - loss: 0.9681 - acc: 0.6259 - val_loss: 1.0623 - val_acc: 0.5864\n",
      "Epoch 5/35\n",
      " - 2s - loss: 0.9258 - acc: 0.6467 - val_loss: 1.0767 - val_acc: 0.5847\n",
      "Epoch 6/35\n",
      " - 2s - loss: 0.8819 - acc: 0.6637 - val_loss: 1.1057 - val_acc: 0.5789\n",
      "Epoch 7/35\n",
      " - 2s - loss: 0.8335 - acc: 0.6852 - val_loss: 1.1229 - val_acc: 0.5774\n",
      "Epoch 8/35\n",
      " - 2s - loss: 0.7877 - acc: 0.7045 - val_loss: 1.1643 - val_acc: 0.5746\n",
      "Epoch 9/35\n",
      " - 2s - loss: 0.7462 - acc: 0.7207 - val_loss: 1.1729 - val_acc: 0.5716\n",
      "Epoch 10/35\n",
      " - 2s - loss: 0.7069 - acc: 0.7366 - val_loss: 1.2046 - val_acc: 0.5677\n",
      "Epoch 11/35\n",
      " - 2s - loss: 0.6750 - acc: 0.7497 - val_loss: 1.2405 - val_acc: 0.5665\n",
      "Epoch 12/35\n",
      " - 2s - loss: 0.6422 - acc: 0.7617 - val_loss: 1.2829 - val_acc: 0.5561\n",
      "Epoch 13/35\n",
      " - 2s - loss: 0.6159 - acc: 0.7711 - val_loss: 1.3104 - val_acc: 0.5619\n",
      "Epoch 14/35\n",
      " - 2s - loss: 0.5935 - acc: 0.7803 - val_loss: 1.3234 - val_acc: 0.5522\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/35\n",
      " - 2s - loss: 0.5659 - acc: 0.7930 - val_loss: 1.3567 - val_acc: 0.5517\n",
      "Epoch 16/35\n",
      " - 2s - loss: 0.5426 - acc: 0.7986 - val_loss: 1.3863 - val_acc: 0.5542\n",
      "Epoch 17/35\n",
      " - 2s - loss: 0.5238 - acc: 0.8083 - val_loss: 1.4269 - val_acc: 0.5466\n",
      "Epoch 18/35\n",
      " - 2s - loss: 0.5036 - acc: 0.8133 - val_loss: 1.4633 - val_acc: 0.5464\n",
      "Epoch 19/35\n",
      " - 2s - loss: 0.4863 - acc: 0.8201 - val_loss: 1.4748 - val_acc: 0.5507\n",
      "Epoch 20/35\n",
      " - 2s - loss: 0.4677 - acc: 0.8266 - val_loss: 1.5178 - val_acc: 0.5467\n",
      "Epoch 21/35\n",
      " - 2s - loss: 0.4538 - acc: 0.8327 - val_loss: 1.5445 - val_acc: 0.5502\n",
      "Epoch 22/35\n",
      " - 2s - loss: 0.4424 - acc: 0.8371 - val_loss: 1.5675 - val_acc: 0.5432\n",
      "Epoch 23/35\n",
      " - 2s - loss: 0.4297 - acc: 0.8422 - val_loss: 1.6059 - val_acc: 0.5488\n",
      "Epoch 24/35\n",
      " - 2s - loss: 0.4148 - acc: 0.8467 - val_loss: 1.6412 - val_acc: 0.5443\n",
      "Epoch 25/35\n",
      " - 2s - loss: 0.4044 - acc: 0.8501 - val_loss: 1.6694 - val_acc: 0.5472\n",
      "Epoch 26/35\n",
      " - 2s - loss: 0.3966 - acc: 0.8538 - val_loss: 1.6873 - val_acc: 0.5386\n",
      "Epoch 27/35\n",
      " - 2s - loss: 0.3841 - acc: 0.8578 - val_loss: 1.7092 - val_acc: 0.5463\n",
      "Epoch 28/35\n",
      " - 2s - loss: 0.3755 - acc: 0.8610 - val_loss: 1.7394 - val_acc: 0.5452\n",
      "Epoch 29/35\n",
      " - 2s - loss: 0.3685 - acc: 0.8640 - val_loss: 1.7509 - val_acc: 0.5389\n",
      "Epoch 30/35\n",
      " - 2s - loss: 0.3565 - acc: 0.8671 - val_loss: 1.7818 - val_acc: 0.5410\n",
      "Epoch 31/35\n",
      " - 2s - loss: 0.3527 - acc: 0.8701 - val_loss: 1.8099 - val_acc: 0.5363\n",
      "Epoch 32/35\n",
      " - 2s - loss: 0.3389 - acc: 0.8742 - val_loss: 1.8367 - val_acc: 0.5404\n",
      "Epoch 33/35\n",
      " - 2s - loss: 0.3366 - acc: 0.8760 - val_loss: 1.8727 - val_acc: 0.5409\n",
      "Epoch 34/35\n",
      " - 2s - loss: 0.3274 - acc: 0.8786 - val_loss: 1.8815 - val_acc: 0.5441\n",
      "Epoch 35/35\n",
      " - 2s - loss: 0.3209 - acc: 0.8809 - val_loss: 1.8916 - val_acc: 0.5402\n",
      "va acc: 0.515125\n",
      "te acc: 0.5402\n",
      "2018-09-18 23:08:02.700436 stack:2/5\n",
      "Train on 64000 samples, validate on 20000 samples\n",
      "Epoch 1/35\n",
      " - 2s - loss: 1.1435 - acc: 0.5524 - val_loss: 1.0740 - val_acc: 0.5825\n",
      "Epoch 2/35\n",
      " - 2s - loss: 1.0444 - acc: 0.5912 - val_loss: 1.0583 - val_acc: 0.5884\n",
      "Epoch 3/35\n",
      " - 2s - loss: 1.0047 - acc: 0.6064 - val_loss: 1.0628 - val_acc: 0.5841\n",
      "Epoch 4/35\n",
      " - 2s - loss: 0.9669 - acc: 0.6264 - val_loss: 1.0705 - val_acc: 0.5884\n",
      "Epoch 5/35\n",
      " - 2s - loss: 0.9244 - acc: 0.6437 - val_loss: 1.0835 - val_acc: 0.5790\n",
      "Epoch 6/35\n",
      " - 2s - loss: 0.8784 - acc: 0.6630 - val_loss: 1.1010 - val_acc: 0.5847\n",
      "Epoch 7/35\n",
      " - 2s - loss: 0.8296 - acc: 0.6860 - val_loss: 1.1379 - val_acc: 0.5673\n",
      "Epoch 8/35\n",
      " - 2s - loss: 0.7881 - acc: 0.7030 - val_loss: 1.1645 - val_acc: 0.5677\n",
      "Epoch 9/35\n",
      " - 2s - loss: 0.7435 - acc: 0.7216 - val_loss: 1.1854 - val_acc: 0.5653\n",
      "Epoch 10/35\n",
      " - 2s - loss: 0.7026 - acc: 0.7401 - val_loss: 1.2173 - val_acc: 0.5653\n",
      "Epoch 11/35\n",
      " - 2s - loss: 0.6702 - acc: 0.7516 - val_loss: 1.2559 - val_acc: 0.5637\n",
      "Epoch 12/35\n",
      " - 2s - loss: 0.6376 - acc: 0.7648 - val_loss: 1.2865 - val_acc: 0.5667\n",
      "Epoch 13/35\n",
      " - 2s - loss: 0.6084 - acc: 0.7751 - val_loss: 1.3199 - val_acc: 0.5642\n",
      "Epoch 14/35\n",
      " - 2s - loss: 0.5792 - acc: 0.7860 - val_loss: 1.3385 - val_acc: 0.5594\n",
      "Epoch 15/35\n",
      " - 2s - loss: 0.5559 - acc: 0.7930 - val_loss: 1.3877 - val_acc: 0.5602\n",
      "Epoch 16/35\n",
      " - 2s - loss: 0.5372 - acc: 0.8029 - val_loss: 1.4154 - val_acc: 0.5572\n",
      "Epoch 17/35\n",
      " - 2s - loss: 0.5176 - acc: 0.8087 - val_loss: 1.4382 - val_acc: 0.5531\n",
      "Epoch 18/35\n",
      " - 2s - loss: 0.4963 - acc: 0.8165 - val_loss: 1.4721 - val_acc: 0.5524\n",
      "Epoch 19/35\n",
      " - 2s - loss: 0.4781 - acc: 0.8229 - val_loss: 1.5226 - val_acc: 0.5504\n",
      "Epoch 20/35\n",
      " - 2s - loss: 0.4633 - acc: 0.8296 - val_loss: 1.5352 - val_acc: 0.5485\n",
      "Epoch 21/35\n",
      " - 2s - loss: 0.4511 - acc: 0.8340 - val_loss: 1.5693 - val_acc: 0.5528\n",
      "Epoch 22/35\n",
      " - 2s - loss: 0.4352 - acc: 0.8395 - val_loss: 1.5927 - val_acc: 0.5505\n",
      "Epoch 23/35\n",
      " - 2s - loss: 0.4231 - acc: 0.8446 - val_loss: 1.6271 - val_acc: 0.5484\n",
      "Epoch 24/35\n",
      " - 2s - loss: 0.4132 - acc: 0.8456 - val_loss: 1.6720 - val_acc: 0.5512\n",
      "Epoch 25/35\n",
      " - 2s - loss: 0.3988 - acc: 0.8525 - val_loss: 1.6753 - val_acc: 0.5421\n",
      "Epoch 26/35\n",
      " - 2s - loss: 0.3892 - acc: 0.8548 - val_loss: 1.6948 - val_acc: 0.5471\n",
      "Epoch 27/35\n",
      " - 2s - loss: 0.3805 - acc: 0.8586 - val_loss: 1.7297 - val_acc: 0.5464\n",
      "Epoch 28/35\n",
      " - 2s - loss: 0.3697 - acc: 0.8622 - val_loss: 1.7742 - val_acc: 0.5473\n",
      "Epoch 29/35\n",
      " - 2s - loss: 0.3633 - acc: 0.8630 - val_loss: 1.7782 - val_acc: 0.5472\n",
      "Epoch 30/35\n",
      " - 2s - loss: 0.3623 - acc: 0.8655 - val_loss: 1.8099 - val_acc: 0.5474\n",
      "Epoch 31/35\n",
      " - 2s - loss: 0.3500 - acc: 0.8706 - val_loss: 1.8457 - val_acc: 0.5393\n",
      "Epoch 32/35\n",
      " - 2s - loss: 0.3380 - acc: 0.8738 - val_loss: 1.8812 - val_acc: 0.5433\n",
      "Epoch 33/35\n",
      " - 2s - loss: 0.3334 - acc: 0.8763 - val_loss: 1.8834 - val_acc: 0.5467\n",
      "Epoch 34/35\n",
      " - 2s - loss: 0.3226 - acc: 0.8796 - val_loss: 1.9102 - val_acc: 0.5442\n",
      "Epoch 35/35\n",
      " - 2s - loss: 0.3157 - acc: 0.8812 - val_loss: 1.9224 - val_acc: 0.5444\n",
      "va acc: 0.52075\n",
      "te acc: 0.5444\n",
      "2018-09-18 23:09:02.593394 stack:3/5\n",
      "Train on 64000 samples, validate on 20000 samples\n",
      "Epoch 1/35\n",
      " - 2s - loss: 1.1396 - acc: 0.5529 - val_loss: 1.0685 - val_acc: 0.5813\n",
      "Epoch 2/35\n",
      " - 2s - loss: 1.0472 - acc: 0.5895 - val_loss: 1.0618 - val_acc: 0.5861\n",
      "Epoch 3/35\n",
      " - 2s - loss: 1.0090 - acc: 0.6048 - val_loss: 1.0728 - val_acc: 0.5880\n",
      "Epoch 4/35\n",
      " - 2s - loss: 0.9723 - acc: 0.6230 - val_loss: 1.0645 - val_acc: 0.5864\n",
      "Epoch 5/35\n",
      " - 2s - loss: 0.9265 - acc: 0.6439 - val_loss: 1.0760 - val_acc: 0.5868\n",
      "Epoch 6/35\n",
      " - 2s - loss: 0.8810 - acc: 0.6631 - val_loss: 1.0956 - val_acc: 0.5808\n",
      "Epoch 7/35\n",
      " - 2s - loss: 0.8359 - acc: 0.6838 - val_loss: 1.1108 - val_acc: 0.5785\n",
      "Epoch 8/35\n",
      " - 2s - loss: 0.7896 - acc: 0.7030 - val_loss: 1.1270 - val_acc: 0.5754\n",
      "Epoch 9/35\n",
      " - 2s - loss: 0.7513 - acc: 0.7191 - val_loss: 1.1639 - val_acc: 0.5697\n",
      "Epoch 10/35\n",
      " - 2s - loss: 0.7097 - acc: 0.7345 - val_loss: 1.1909 - val_acc: 0.5720\n",
      "Epoch 11/35\n",
      " - 2s - loss: 0.6716 - acc: 0.7498 - val_loss: 1.2350 - val_acc: 0.5675\n",
      "Epoch 12/35\n",
      " - 2s - loss: 0.6412 - acc: 0.7606 - val_loss: 1.2905 - val_acc: 0.5606\n",
      "Epoch 13/35\n",
      " - 2s - loss: 0.6095 - acc: 0.7743 - val_loss: 1.2866 - val_acc: 0.5635\n",
      "Epoch 14/35\n",
      " - 2s - loss: 0.5828 - acc: 0.7841 - val_loss: 1.3511 - val_acc: 0.5589\n",
      "Epoch 15/35\n",
      " - 2s - loss: 0.5637 - acc: 0.7906 - val_loss: 1.3565 - val_acc: 0.5590\n",
      "Epoch 16/35\n",
      " - 2s - loss: 0.5414 - acc: 0.7978 - val_loss: 1.3928 - val_acc: 0.5607\n",
      "Epoch 17/35\n",
      " - 2s - loss: 0.5202 - acc: 0.8075 - val_loss: 1.4401 - val_acc: 0.5581\n",
      "Epoch 18/35\n",
      " - 2s - loss: 0.4994 - acc: 0.8142 - val_loss: 1.4425 - val_acc: 0.5539\n",
      "Epoch 19/35\n",
      " - 2s - loss: 0.4853 - acc: 0.8208 - val_loss: 1.4860 - val_acc: 0.5545\n",
      "Epoch 20/35\n",
      " - 2s - loss: 0.4702 - acc: 0.8256 - val_loss: 1.5155 - val_acc: 0.5539\n",
      "Epoch 21/35\n",
      " - 2s - loss: 0.4488 - acc: 0.8338 - val_loss: 1.5569 - val_acc: 0.5419\n",
      "Epoch 22/35\n",
      " - 2s - loss: 0.4413 - acc: 0.8353 - val_loss: 1.5622 - val_acc: 0.5540\n",
      "Epoch 23/35\n",
      " - 2s - loss: 0.4285 - acc: 0.8408 - val_loss: 1.5909 - val_acc: 0.5496\n",
      "Epoch 24/35\n",
      " - 2s - loss: 0.4191 - acc: 0.8452 - val_loss: 1.6498 - val_acc: 0.5484\n",
      "Epoch 25/35\n",
      " - 2s - loss: 0.4022 - acc: 0.8513 - val_loss: 1.6511 - val_acc: 0.5505\n",
      "Epoch 26/35\n",
      " - 2s - loss: 0.3903 - acc: 0.8555 - val_loss: 1.7005 - val_acc: 0.5500\n",
      "Epoch 27/35\n",
      " - 2s - loss: 0.3841 - acc: 0.8569 - val_loss: 1.6984 - val_acc: 0.5470\n",
      "Epoch 28/35\n",
      " - 2s - loss: 0.3734 - acc: 0.8614 - val_loss: 1.7336 - val_acc: 0.5494\n",
      "Epoch 29/35\n",
      " - 2s - loss: 0.3631 - acc: 0.8656 - val_loss: 1.7548 - val_acc: 0.5471\n",
      "Epoch 30/35\n",
      " - 2s - loss: 0.3587 - acc: 0.8645 - val_loss: 1.7775 - val_acc: 0.5446\n",
      "Epoch 31/35\n",
      " - 2s - loss: 0.3488 - acc: 0.8702 - val_loss: 1.7972 - val_acc: 0.5424\n",
      "Epoch 32/35\n",
      " - 2s - loss: 0.3372 - acc: 0.8751 - val_loss: 1.8155 - val_acc: 0.5406\n",
      "Epoch 33/35\n",
      " - 2s - loss: 0.3336 - acc: 0.8743 - val_loss: 1.8396 - val_acc: 0.5444\n",
      "Epoch 34/35\n",
      " - 2s - loss: 0.3258 - acc: 0.8797 - val_loss: 1.8642 - val_acc: 0.5452\n",
      "Epoch 35/35\n",
      " - 2s - loss: 0.3223 - acc: 0.8803 - val_loss: 1.9015 - val_acc: 0.5449\n",
      "va acc: 0.526875\n",
      "te acc: 0.5449\n",
      "2018-09-18 23:10:03.377182 stack:4/5\n",
      "Train on 64000 samples, validate on 20000 samples\n",
      "Epoch 1/35\n",
      " - 2s - loss: 1.1448 - acc: 0.5515 - val_loss: 1.0759 - val_acc: 0.5776\n",
      "Epoch 2/35\n",
      " - 2s - loss: 1.0490 - acc: 0.5899 - val_loss: 1.0563 - val_acc: 0.5880\n",
      "Epoch 3/35\n",
      " - 2s - loss: 1.0092 - acc: 0.6073 - val_loss: 1.0569 - val_acc: 0.5876\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/35\n",
      " - 2s - loss: 0.9689 - acc: 0.6261 - val_loss: 1.0590 - val_acc: 0.5914\n",
      "Epoch 5/35\n",
      " - 2s - loss: 0.9241 - acc: 0.6454 - val_loss: 1.0661 - val_acc: 0.5881\n",
      "Epoch 6/35\n",
      " - 2s - loss: 0.8805 - acc: 0.6655 - val_loss: 1.1093 - val_acc: 0.5727\n",
      "Epoch 7/35\n",
      " - 2s - loss: 0.8336 - acc: 0.6854 - val_loss: 1.1302 - val_acc: 0.5790\n",
      "Epoch 8/35\n",
      " - 2s - loss: 0.7873 - acc: 0.7045 - val_loss: 1.1437 - val_acc: 0.5754\n",
      "Epoch 9/35\n",
      " - 2s - loss: 0.7469 - acc: 0.7204 - val_loss: 1.1655 - val_acc: 0.5696\n",
      "Epoch 10/35\n",
      " - 2s - loss: 0.7079 - acc: 0.7379 - val_loss: 1.2113 - val_acc: 0.5693\n",
      "Epoch 11/35\n",
      " - 2s - loss: 0.6727 - acc: 0.7513 - val_loss: 1.2599 - val_acc: 0.5685\n",
      "Epoch 12/35\n",
      " - 2s - loss: 0.6388 - acc: 0.7638 - val_loss: 1.2856 - val_acc: 0.5646\n",
      "Epoch 13/35\n",
      " - 2s - loss: 0.6140 - acc: 0.7725 - val_loss: 1.3714 - val_acc: 0.5525\n",
      "Epoch 14/35\n",
      " - 2s - loss: 0.5847 - acc: 0.7847 - val_loss: 1.3528 - val_acc: 0.5613\n",
      "Epoch 15/35\n",
      " - 2s - loss: 0.5625 - acc: 0.7934 - val_loss: 1.3817 - val_acc: 0.5579\n",
      "Epoch 16/35\n",
      " - 2s - loss: 0.5425 - acc: 0.8002 - val_loss: 1.3970 - val_acc: 0.5564\n",
      "Epoch 17/35\n",
      " - 2s - loss: 0.5206 - acc: 0.8069 - val_loss: 1.4244 - val_acc: 0.5577\n",
      "Epoch 18/35\n",
      " - 2s - loss: 0.5041 - acc: 0.8135 - val_loss: 1.4611 - val_acc: 0.5544\n",
      "Epoch 19/35\n",
      " - 2s - loss: 0.4851 - acc: 0.8204 - val_loss: 1.4823 - val_acc: 0.5515\n",
      "Epoch 20/35\n",
      " - 2s - loss: 0.4668 - acc: 0.8281 - val_loss: 1.5161 - val_acc: 0.5513\n",
      "Epoch 21/35\n",
      " - 2s - loss: 0.4574 - acc: 0.8300 - val_loss: 1.5522 - val_acc: 0.5523\n",
      "Epoch 22/35\n",
      " - 2s - loss: 0.4422 - acc: 0.8362 - val_loss: 1.5726 - val_acc: 0.5503\n",
      "Epoch 23/35\n",
      " - 2s - loss: 0.4248 - acc: 0.8431 - val_loss: 1.6147 - val_acc: 0.5477\n",
      "Epoch 24/35\n",
      " - 2s - loss: 0.4167 - acc: 0.8471 - val_loss: 1.6589 - val_acc: 0.5520\n",
      "Epoch 25/35\n",
      " - 2s - loss: 0.4063 - acc: 0.8505 - val_loss: 1.6759 - val_acc: 0.5497\n",
      "Epoch 26/35\n",
      " - 2s - loss: 0.3990 - acc: 0.8524 - val_loss: 1.6741 - val_acc: 0.5472\n",
      "Epoch 27/35\n",
      " - 2s - loss: 0.3881 - acc: 0.8570 - val_loss: 1.7079 - val_acc: 0.5501\n",
      "Epoch 28/35\n",
      " - 2s - loss: 0.3776 - acc: 0.8604 - val_loss: 1.7283 - val_acc: 0.5494\n",
      "Epoch 29/35\n",
      " - 2s - loss: 0.3696 - acc: 0.8626 - val_loss: 1.7550 - val_acc: 0.5500\n",
      "Epoch 30/35\n",
      " - 2s - loss: 0.3565 - acc: 0.8675 - val_loss: 1.7898 - val_acc: 0.5448\n",
      "Epoch 31/35\n",
      " - 2s - loss: 0.3538 - acc: 0.8681 - val_loss: 1.8163 - val_acc: 0.5457\n",
      "Epoch 32/35\n",
      " - 2s - loss: 0.3437 - acc: 0.8728 - val_loss: 1.8246 - val_acc: 0.5493\n",
      "Epoch 33/35\n",
      " - 2s - loss: 0.3327 - acc: 0.8769 - val_loss: 1.8606 - val_acc: 0.5471\n",
      "Epoch 34/35\n",
      " - 2s - loss: 0.3306 - acc: 0.8765 - val_loss: 1.8929 - val_acc: 0.5405\n",
      "Epoch 35/35\n",
      " - 2s - loss: 0.3229 - acc: 0.8786 - val_loss: 1.9046 - val_acc: 0.5445\n",
      "va acc: 0.529625\n",
      "te acc: 0.5445\n",
      "2018-09-18 23:11:03.371771 stack:5/5\n",
      "Train on 64000 samples, validate on 20000 samples\n",
      "Epoch 1/35\n",
      " - 2s - loss: 1.1511 - acc: 0.5475 - val_loss: 1.0679 - val_acc: 0.5848\n",
      "Epoch 2/35\n",
      " - 2s - loss: 1.0507 - acc: 0.5863 - val_loss: 1.0540 - val_acc: 0.5893\n",
      "Epoch 3/35\n",
      " - 2s - loss: 1.0083 - acc: 0.6071 - val_loss: 1.0585 - val_acc: 0.5875\n",
      "Epoch 4/35\n",
      " - 2s - loss: 0.9705 - acc: 0.6241 - val_loss: 1.0655 - val_acc: 0.5859\n",
      "Epoch 5/35\n",
      " - 2s - loss: 0.9260 - acc: 0.6442 - val_loss: 1.0887 - val_acc: 0.5842\n",
      "Epoch 6/35\n",
      " - 2s - loss: 0.8797 - acc: 0.6649 - val_loss: 1.0946 - val_acc: 0.5818\n",
      "Epoch 7/35\n",
      " - 2s - loss: 0.8318 - acc: 0.6845 - val_loss: 1.1354 - val_acc: 0.5769\n",
      "Epoch 8/35\n",
      " - 2s - loss: 0.7892 - acc: 0.7034 - val_loss: 1.1437 - val_acc: 0.5740\n",
      "Epoch 9/35\n",
      " - 2s - loss: 0.7403 - acc: 0.7228 - val_loss: 1.1787 - val_acc: 0.5724\n",
      "Epoch 10/35\n",
      " - 2s - loss: 0.7059 - acc: 0.7378 - val_loss: 1.2093 - val_acc: 0.5662\n",
      "Epoch 11/35\n",
      " - 2s - loss: 0.6685 - acc: 0.7532 - val_loss: 1.2428 - val_acc: 0.5621\n",
      "Epoch 12/35\n",
      " - 2s - loss: 0.6388 - acc: 0.7624 - val_loss: 1.2646 - val_acc: 0.5616\n",
      "Epoch 13/35\n",
      " - 2s - loss: 0.6105 - acc: 0.7750 - val_loss: 1.3064 - val_acc: 0.5636\n",
      "Epoch 14/35\n",
      " - 2s - loss: 0.5829 - acc: 0.7846 - val_loss: 1.3264 - val_acc: 0.5635\n",
      "Epoch 15/35\n",
      " - 2s - loss: 0.5593 - acc: 0.7930 - val_loss: 1.3755 - val_acc: 0.5606\n",
      "Epoch 16/35\n",
      " - 2s - loss: 0.5361 - acc: 0.8012 - val_loss: 1.4088 - val_acc: 0.5533\n",
      "Epoch 17/35\n",
      " - 2s - loss: 0.5159 - acc: 0.8089 - val_loss: 1.4200 - val_acc: 0.5530\n",
      "Epoch 18/35\n",
      " - 2s - loss: 0.4975 - acc: 0.8166 - val_loss: 1.4567 - val_acc: 0.5531\n",
      "Epoch 19/35\n",
      " - 2s - loss: 0.4808 - acc: 0.8216 - val_loss: 1.4829 - val_acc: 0.5497\n",
      "Epoch 20/35\n",
      " - 2s - loss: 0.4676 - acc: 0.8273 - val_loss: 1.5071 - val_acc: 0.5479\n",
      "Epoch 21/35\n",
      " - 2s - loss: 0.4502 - acc: 0.8345 - val_loss: 1.5572 - val_acc: 0.5455\n",
      "Epoch 22/35\n",
      " - 2s - loss: 0.4344 - acc: 0.8398 - val_loss: 1.5901 - val_acc: 0.5494\n",
      "Epoch 23/35\n",
      " - 2s - loss: 0.4227 - acc: 0.8423 - val_loss: 1.6164 - val_acc: 0.5450\n",
      "Epoch 24/35\n",
      " - 2s - loss: 0.4105 - acc: 0.8473 - val_loss: 1.6303 - val_acc: 0.5514\n",
      "Epoch 25/35\n",
      " - 2s - loss: 0.4004 - acc: 0.8524 - val_loss: 1.6560 - val_acc: 0.5478\n",
      "Epoch 26/35\n",
      " - 2s - loss: 0.3881 - acc: 0.8573 - val_loss: 1.6843 - val_acc: 0.5452\n",
      "Epoch 27/35\n",
      " - 2s - loss: 0.3827 - acc: 0.8574 - val_loss: 1.7063 - val_acc: 0.5433\n",
      "Epoch 28/35\n",
      " - 2s - loss: 0.3750 - acc: 0.8602 - val_loss: 1.7436 - val_acc: 0.5403\n",
      "Epoch 29/35\n",
      " - 2s - loss: 0.3638 - acc: 0.8637 - val_loss: 1.7675 - val_acc: 0.5425\n",
      "Epoch 30/35\n",
      " - 2s - loss: 0.3515 - acc: 0.8712 - val_loss: 1.7938 - val_acc: 0.5415\n",
      "Epoch 31/35\n",
      " - 2s - loss: 0.3428 - acc: 0.8744 - val_loss: 1.8211 - val_acc: 0.5373\n",
      "Epoch 32/35\n",
      " - 2s - loss: 0.3364 - acc: 0.8746 - val_loss: 1.8389 - val_acc: 0.5359\n",
      "Epoch 33/35\n",
      " - 2s - loss: 0.3282 - acc: 0.8776 - val_loss: 1.8595 - val_acc: 0.5340\n",
      "Epoch 34/35\n",
      " - 2s - loss: 0.3243 - acc: 0.8788 - val_loss: 1.8880 - val_acc: 0.5401\n",
      "Epoch 35/35\n",
      " - 2s - loss: 0.3138 - acc: 0.8840 - val_loss: 1.8940 - val_acc: 0.5359\n",
      "va acc: 0.5305625\n",
      "te acc: 0.5359\n",
      "2018-09-18 23:12:02.706018 stack:1/5\n",
      "Train on 64000 samples, validate on 20000 samples\n",
      "Epoch 1/35\n",
      " - 2s - loss: 0.4704 - acc: 0.8027 - val_loss: 0.4447 - val_acc: 0.8154\n",
      "Epoch 2/35\n",
      " - 2s - loss: 0.4293 - acc: 0.8247 - val_loss: 0.4402 - val_acc: 0.8217\n",
      "Epoch 3/35\n",
      " - 2s - loss: 0.4143 - acc: 0.8314 - val_loss: 0.4380 - val_acc: 0.8230\n",
      "Epoch 4/35\n",
      " - 2s - loss: 0.3967 - acc: 0.8377 - val_loss: 0.4431 - val_acc: 0.8225\n",
      "Epoch 5/35\n",
      " - 2s - loss: 0.3722 - acc: 0.8474 - val_loss: 0.4577 - val_acc: 0.8184\n",
      "Epoch 6/35\n",
      " - 2s - loss: 0.3440 - acc: 0.8581 - val_loss: 0.4720 - val_acc: 0.8194\n",
      "Epoch 7/35\n",
      " - 2s - loss: 0.3121 - acc: 0.8716 - val_loss: 0.5443 - val_acc: 0.7918\n",
      "Epoch 8/35\n",
      " - 2s - loss: 0.2827 - acc: 0.8837 - val_loss: 0.5064 - val_acc: 0.8125\n",
      "Epoch 9/35\n",
      " - 2s - loss: 0.2523 - acc: 0.8979 - val_loss: 0.5374 - val_acc: 0.8101\n",
      "Epoch 10/35\n",
      " - 2s - loss: 0.2260 - acc: 0.9088 - val_loss: 0.5505 - val_acc: 0.8055\n",
      "Epoch 11/35\n",
      " - 2s - loss: 0.2036 - acc: 0.9176 - val_loss: 0.5766 - val_acc: 0.8042\n",
      "Epoch 12/35\n",
      " - 2s - loss: 0.1854 - acc: 0.9254 - val_loss: 0.6122 - val_acc: 0.8070\n",
      "Epoch 13/35\n",
      " - 2s - loss: 0.1678 - acc: 0.9331 - val_loss: 0.6401 - val_acc: 0.7974\n",
      "Epoch 14/35\n",
      " - 2s - loss: 0.1500 - acc: 0.9408 - val_loss: 0.6812 - val_acc: 0.8057\n",
      "Epoch 15/35\n",
      " - 2s - loss: 0.1355 - acc: 0.9467 - val_loss: 0.7085 - val_acc: 0.8031\n",
      "Epoch 16/35\n",
      " - 2s - loss: 0.1260 - acc: 0.9517 - val_loss: 0.7296 - val_acc: 0.8040\n",
      "Epoch 17/35\n",
      " - 2s - loss: 0.1161 - acc: 0.9539 - val_loss: 0.7503 - val_acc: 0.7984\n",
      "Epoch 18/35\n",
      " - 2s - loss: 0.1070 - acc: 0.9589 - val_loss: 0.7997 - val_acc: 0.8034\n",
      "Epoch 19/35\n",
      " - 2s - loss: 0.0989 - acc: 0.9619 - val_loss: 0.8052 - val_acc: 0.7964\n",
      "Epoch 20/35\n",
      " - 2s - loss: 0.0913 - acc: 0.9662 - val_loss: 0.8344 - val_acc: 0.7984\n",
      "Epoch 21/35\n",
      " - 2s - loss: 0.0868 - acc: 0.9668 - val_loss: 0.8879 - val_acc: 0.7988\n",
      "Epoch 22/35\n",
      " - 2s - loss: 0.0808 - acc: 0.9696 - val_loss: 0.8829 - val_acc: 0.7994\n",
      "Epoch 23/35\n",
      " - 2s - loss: 0.0768 - acc: 0.9710 - val_loss: 0.9143 - val_acc: 0.7962\n",
      "Epoch 24/35\n",
      " - 2s - loss: 0.0702 - acc: 0.9738 - val_loss: 0.9665 - val_acc: 0.7998\n",
      "Epoch 25/35\n",
      " - 2s - loss: 0.0699 - acc: 0.9735 - val_loss: 0.9915 - val_acc: 0.8008\n",
      "Epoch 26/35\n",
      " - 2s - loss: 0.0650 - acc: 0.9756 - val_loss: 0.9875 - val_acc: 0.8015\n",
      "Epoch 27/35\n",
      " - 2s - loss: 0.0600 - acc: 0.9770 - val_loss: 1.0106 - val_acc: 0.8000\n",
      "Epoch 28/35\n",
      " - 2s - loss: 0.0572 - acc: 0.9779 - val_loss: 1.0144 - val_acc: 0.7994\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/35\n",
      " - 2s - loss: 0.0575 - acc: 0.9774 - val_loss: 1.0452 - val_acc: 0.7959\n",
      "Epoch 30/35\n",
      " - 2s - loss: 0.0535 - acc: 0.9796 - val_loss: 1.0599 - val_acc: 0.7996\n",
      "Epoch 31/35\n",
      " - 2s - loss: 0.0555 - acc: 0.9792 - val_loss: 1.0924 - val_acc: 0.7954\n",
      "Epoch 32/35\n",
      " - 2s - loss: 0.0504 - acc: 0.9809 - val_loss: 1.0802 - val_acc: 0.7983\n",
      "Epoch 33/35\n",
      " - 2s - loss: 0.0474 - acc: 0.9819 - val_loss: 1.0985 - val_acc: 0.7961\n",
      "Epoch 34/35\n",
      " - 2s - loss: 0.0468 - acc: 0.9830 - val_loss: 1.1337 - val_acc: 0.8006\n",
      "Epoch 35/35\n",
      " - 2s - loss: 0.0449 - acc: 0.9835 - val_loss: 1.1330 - val_acc: 0.8007\n",
      "va acc: 0.78925\n",
      "te acc: 0.80075\n",
      "2018-09-18 23:12:59.311035 stack:2/5\n",
      "Train on 64000 samples, validate on 20000 samples\n",
      "Epoch 1/35\n",
      " - 2s - loss: 0.4699 - acc: 0.8027 - val_loss: 0.4497 - val_acc: 0.8175\n",
      "Epoch 2/35\n",
      " - 2s - loss: 0.4290 - acc: 0.8240 - val_loss: 0.4407 - val_acc: 0.8218\n",
      "Epoch 3/35\n",
      " - 2s - loss: 0.4130 - acc: 0.8315 - val_loss: 0.4415 - val_acc: 0.8203\n",
      "Epoch 4/35\n",
      " - 2s - loss: 0.3940 - acc: 0.8393 - val_loss: 0.4612 - val_acc: 0.8102\n",
      "Epoch 5/35\n",
      " - 2s - loss: 0.3701 - acc: 0.8491 - val_loss: 0.4601 - val_acc: 0.8138\n",
      "Epoch 6/35\n",
      " - 2s - loss: 0.3412 - acc: 0.8610 - val_loss: 0.4642 - val_acc: 0.8149\n",
      "Epoch 7/35\n",
      " - 2s - loss: 0.3093 - acc: 0.8730 - val_loss: 0.4961 - val_acc: 0.8078\n",
      "Epoch 8/35\n",
      " - 2s - loss: 0.2799 - acc: 0.8862 - val_loss: 0.5407 - val_acc: 0.8014\n",
      "Epoch 9/35\n",
      " - 2s - loss: 0.2496 - acc: 0.8983 - val_loss: 0.5468 - val_acc: 0.8111\n",
      "Epoch 10/35\n",
      " - 2s - loss: 0.2242 - acc: 0.9098 - val_loss: 0.6208 - val_acc: 0.7873\n",
      "Epoch 11/35\n",
      " - 2s - loss: 0.2028 - acc: 0.9192 - val_loss: 0.6019 - val_acc: 0.8093\n",
      "Epoch 12/35\n",
      " - 2s - loss: 0.1801 - acc: 0.9272 - val_loss: 0.6351 - val_acc: 0.8093\n",
      "Epoch 13/35\n",
      " - 2s - loss: 0.1635 - acc: 0.9362 - val_loss: 0.6496 - val_acc: 0.8013\n",
      "Epoch 14/35\n",
      " - 2s - loss: 0.1505 - acc: 0.9406 - val_loss: 0.6968 - val_acc: 0.7992\n",
      "Epoch 15/35\n",
      " - 2s - loss: 0.1322 - acc: 0.9485 - val_loss: 0.7068 - val_acc: 0.7985\n",
      "Epoch 16/35\n",
      " - 2s - loss: 0.1249 - acc: 0.9514 - val_loss: 0.7510 - val_acc: 0.8024\n",
      "Epoch 17/35\n",
      " - 2s - loss: 0.1131 - acc: 0.9562 - val_loss: 0.7975 - val_acc: 0.8031\n",
      "Epoch 18/35\n",
      " - 2s - loss: 0.1065 - acc: 0.9586 - val_loss: 0.7825 - val_acc: 0.8022\n",
      "Epoch 19/35\n",
      " - 2s - loss: 0.0974 - acc: 0.9632 - val_loss: 0.8249 - val_acc: 0.7998\n",
      "Epoch 20/35\n",
      " - 2s - loss: 0.0928 - acc: 0.9641 - val_loss: 0.8384 - val_acc: 0.7986\n",
      "Epoch 21/35\n",
      " - 2s - loss: 0.0833 - acc: 0.9691 - val_loss: 0.8764 - val_acc: 0.7973\n",
      "Epoch 22/35\n",
      " - 2s - loss: 0.0800 - acc: 0.9697 - val_loss: 0.8811 - val_acc: 0.7989\n",
      "Epoch 23/35\n",
      " - 2s - loss: 0.0751 - acc: 0.9719 - val_loss: 0.9268 - val_acc: 0.8032\n",
      "Epoch 24/35\n",
      " - 2s - loss: 0.0724 - acc: 0.9735 - val_loss: 0.9401 - val_acc: 0.8012\n",
      "Epoch 25/35\n",
      " - 2s - loss: 0.0679 - acc: 0.9742 - val_loss: 0.9799 - val_acc: 0.7951\n",
      "Epoch 26/35\n",
      " - 2s - loss: 0.0648 - acc: 0.9754 - val_loss: 0.9818 - val_acc: 0.7967\n",
      "Epoch 27/35\n",
      " - 2s - loss: 0.0617 - acc: 0.9768 - val_loss: 1.0192 - val_acc: 0.8014\n",
      "Epoch 28/35\n",
      " - 2s - loss: 0.0577 - acc: 0.9782 - val_loss: 1.0082 - val_acc: 0.8002\n",
      "Epoch 29/35\n",
      " - 2s - loss: 0.0564 - acc: 0.9784 - val_loss: 1.0507 - val_acc: 0.8021\n",
      "Epoch 30/35\n",
      " - 2s - loss: 0.0549 - acc: 0.9789 - val_loss: 1.0868 - val_acc: 0.7968\n",
      "Epoch 31/35\n",
      " - 2s - loss: 0.0526 - acc: 0.9802 - val_loss: 1.1047 - val_acc: 0.7983\n",
      "Epoch 32/35\n",
      " - 2s - loss: 0.0484 - acc: 0.9822 - val_loss: 1.1095 - val_acc: 0.8014\n",
      "Epoch 33/35\n",
      " - 2s - loss: 0.0478 - acc: 0.9822 - val_loss: 1.1166 - val_acc: 0.8002\n",
      "Epoch 34/35\n",
      " - 2s - loss: 0.0441 - acc: 0.9833 - val_loss: 1.1222 - val_acc: 0.7978\n",
      "Epoch 35/35\n",
      " - 2s - loss: 0.0442 - acc: 0.9840 - val_loss: 1.1707 - val_acc: 0.7961\n",
      "va acc: 0.782375\n",
      "te acc: 0.79605\n",
      "2018-09-18 23:13:57.116292 stack:3/5\n",
      "Train on 64000 samples, validate on 20000 samples\n",
      "Epoch 1/35\n",
      " - 3s - loss: 0.4693 - acc: 0.8025 - val_loss: 0.4434 - val_acc: 0.8151\n",
      "Epoch 2/35\n",
      " - 2s - loss: 0.4297 - acc: 0.8242 - val_loss: 0.4370 - val_acc: 0.8242\n",
      "Epoch 3/35\n",
      " - 2s - loss: 0.4132 - acc: 0.8316 - val_loss: 0.4378 - val_acc: 0.8217\n",
      "Epoch 4/35\n",
      " - 2s - loss: 0.3946 - acc: 0.8395 - val_loss: 0.4455 - val_acc: 0.8181\n",
      "Epoch 5/35\n",
      " - 2s - loss: 0.3685 - acc: 0.8505 - val_loss: 0.4656 - val_acc: 0.8114\n",
      "Epoch 6/35\n",
      " - 2s - loss: 0.3408 - acc: 0.8595 - val_loss: 0.4701 - val_acc: 0.8154\n",
      "Epoch 7/35\n",
      " - 2s - loss: 0.3073 - acc: 0.8749 - val_loss: 0.4873 - val_acc: 0.8157\n",
      "Epoch 8/35\n",
      " - 2s - loss: 0.2801 - acc: 0.8853 - val_loss: 0.5122 - val_acc: 0.8104\n",
      "Epoch 9/35\n",
      " - 2s - loss: 0.2492 - acc: 0.8997 - val_loss: 0.5602 - val_acc: 0.7982\n",
      "Epoch 10/35\n",
      " - 2s - loss: 0.2252 - acc: 0.9095 - val_loss: 0.5711 - val_acc: 0.8031\n",
      "Epoch 11/35\n",
      " - 2s - loss: 0.1984 - acc: 0.9212 - val_loss: 0.6227 - val_acc: 0.7973\n",
      "Epoch 12/35\n",
      " - 2s - loss: 0.1829 - acc: 0.9270 - val_loss: 0.6120 - val_acc: 0.8054\n",
      "Epoch 13/35\n",
      " - 2s - loss: 0.1642 - acc: 0.9353 - val_loss: 0.6541 - val_acc: 0.8026\n",
      "Epoch 14/35\n",
      " - 2s - loss: 0.1492 - acc: 0.9421 - val_loss: 0.6924 - val_acc: 0.8035\n",
      "Epoch 15/35\n",
      " - 2s - loss: 0.1356 - acc: 0.9464 - val_loss: 0.7014 - val_acc: 0.7996\n",
      "Epoch 16/35\n",
      " - 2s - loss: 0.1271 - acc: 0.9503 - val_loss: 0.7424 - val_acc: 0.7994\n",
      "Epoch 17/35\n",
      " - 2s - loss: 0.1121 - acc: 0.9576 - val_loss: 0.7562 - val_acc: 0.8017\n",
      "Epoch 18/35\n",
      " - 2s - loss: 0.1056 - acc: 0.9594 - val_loss: 0.8020 - val_acc: 0.8023\n",
      "Epoch 19/35\n",
      " - 2s - loss: 0.0978 - acc: 0.9623 - val_loss: 0.8224 - val_acc: 0.8052\n",
      "Epoch 20/35\n",
      " - 2s - loss: 0.0911 - acc: 0.9654 - val_loss: 0.8676 - val_acc: 0.7974\n",
      "Epoch 21/35\n",
      " - 2s - loss: 0.0850 - acc: 0.9672 - val_loss: 0.8636 - val_acc: 0.7964\n",
      "Epoch 22/35\n",
      " - 2s - loss: 0.0820 - acc: 0.9686 - val_loss: 0.8893 - val_acc: 0.8042\n",
      "Epoch 23/35\n",
      " - 2s - loss: 0.0741 - acc: 0.9722 - val_loss: 0.9533 - val_acc: 0.7962\n",
      "Epoch 24/35\n",
      " - 2s - loss: 0.0709 - acc: 0.9730 - val_loss: 0.9752 - val_acc: 0.7966\n",
      "Epoch 25/35\n",
      " - 2s - loss: 0.0699 - acc: 0.9737 - val_loss: 0.9345 - val_acc: 0.7944\n",
      "Epoch 26/35\n",
      " - 2s - loss: 0.0628 - acc: 0.9766 - val_loss: 0.9503 - val_acc: 0.7976\n",
      "Epoch 27/35\n",
      " - 2s - loss: 0.0622 - acc: 0.9766 - val_loss: 0.9901 - val_acc: 0.7986\n",
      "Epoch 28/35\n",
      " - 2s - loss: 0.0605 - acc: 0.9768 - val_loss: 0.9909 - val_acc: 0.7996\n",
      "Epoch 29/35\n",
      " - 2s - loss: 0.0549 - acc: 0.9799 - val_loss: 1.0367 - val_acc: 0.7970\n",
      "Epoch 30/35\n",
      " - 2s - loss: 0.0556 - acc: 0.9793 - val_loss: 1.0565 - val_acc: 0.8003\n",
      "Epoch 31/35\n",
      " - 2s - loss: 0.0521 - acc: 0.9807 - val_loss: 1.0697 - val_acc: 0.7995\n",
      "Epoch 32/35\n",
      " - 2s - loss: 0.0489 - acc: 0.9814 - val_loss: 1.0705 - val_acc: 0.8014\n",
      "Epoch 33/35\n",
      " - 2s - loss: 0.0493 - acc: 0.9812 - val_loss: 1.0761 - val_acc: 0.7994\n",
      "Epoch 34/35\n",
      " - 2s - loss: 0.0466 - acc: 0.9824 - val_loss: 1.1100 - val_acc: 0.8011\n",
      "Epoch 35/35\n",
      " - 2s - loss: 0.0447 - acc: 0.9836 - val_loss: 1.0967 - val_acc: 0.7984\n",
      "va acc: 0.7869375\n",
      "te acc: 0.79835\n",
      "2018-09-18 23:14:56.865901 stack:4/5\n",
      "Train on 64000 samples, validate on 20000 samples\n",
      "Epoch 1/35\n",
      " - 2s - loss: 0.4743 - acc: 0.7995 - val_loss: 0.4450 - val_acc: 0.8158\n",
      "Epoch 2/35\n",
      " - 2s - loss: 0.4305 - acc: 0.8243 - val_loss: 0.4402 - val_acc: 0.8219\n",
      "Epoch 3/35\n",
      " - 2s - loss: 0.4141 - acc: 0.8298 - val_loss: 0.4382 - val_acc: 0.8252\n",
      "Epoch 4/35\n",
      " - 2s - loss: 0.3945 - acc: 0.8384 - val_loss: 0.4611 - val_acc: 0.8197\n",
      "Epoch 5/35\n",
      " - 2s - loss: 0.3692 - acc: 0.8464 - val_loss: 0.4513 - val_acc: 0.8211\n",
      "Epoch 6/35\n",
      " - 2s - loss: 0.3387 - acc: 0.8597 - val_loss: 0.4797 - val_acc: 0.8157\n",
      "Epoch 7/35\n",
      " - 2s - loss: 0.3071 - acc: 0.8740 - val_loss: 0.5083 - val_acc: 0.8081\n",
      "Epoch 8/35\n",
      " - 2s - loss: 0.2746 - acc: 0.8885 - val_loss: 0.5199 - val_acc: 0.8144\n",
      "Epoch 9/35\n",
      " - 2s - loss: 0.2477 - acc: 0.8994 - val_loss: 0.5406 - val_acc: 0.8058\n",
      "Epoch 10/35\n",
      " - 2s - loss: 0.2238 - acc: 0.9101 - val_loss: 0.5687 - val_acc: 0.8093\n",
      "Epoch 11/35\n",
      " - 2s - loss: 0.1984 - acc: 0.9216 - val_loss: 0.6205 - val_acc: 0.8012\n",
      "Epoch 12/35\n",
      " - 2s - loss: 0.1786 - acc: 0.9281 - val_loss: 0.6084 - val_acc: 0.8007\n",
      "Epoch 13/35\n",
      " - 2s - loss: 0.1641 - acc: 0.9347 - val_loss: 0.6970 - val_acc: 0.7873\n",
      "Epoch 14/35\n",
      " - 2s - loss: 0.1478 - acc: 0.9420 - val_loss: 0.6724 - val_acc: 0.8028\n",
      "Epoch 15/35\n",
      " - 2s - loss: 0.1341 - acc: 0.9479 - val_loss: 0.7261 - val_acc: 0.8044\n",
      "Epoch 16/35\n",
      " - 2s - loss: 0.1243 - acc: 0.9521 - val_loss: 0.7387 - val_acc: 0.8018\n",
      "Epoch 17/35\n",
      " - 2s - loss: 0.1153 - acc: 0.9550 - val_loss: 0.7339 - val_acc: 0.8021\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/35\n",
      " - 2s - loss: 0.1073 - acc: 0.9578 - val_loss: 0.8206 - val_acc: 0.7948\n",
      "Epoch 19/35\n",
      " - 2s - loss: 0.0980 - acc: 0.9621 - val_loss: 0.8197 - val_acc: 0.8013\n",
      "Epoch 20/35\n",
      " - 2s - loss: 0.0916 - acc: 0.9644 - val_loss: 0.8433 - val_acc: 0.8017\n",
      "Epoch 21/35\n",
      " - 2s - loss: 0.0878 - acc: 0.9667 - val_loss: 0.8980 - val_acc: 0.8045\n",
      "Epoch 22/35\n",
      " - 2s - loss: 0.0813 - acc: 0.9688 - val_loss: 0.8801 - val_acc: 0.7993\n",
      "Epoch 23/35\n",
      " - 2s - loss: 0.0739 - acc: 0.9719 - val_loss: 0.9110 - val_acc: 0.7983\n",
      "Epoch 24/35\n",
      " - 2s - loss: 0.0694 - acc: 0.9741 - val_loss: 1.0896 - val_acc: 0.7786\n",
      "Epoch 25/35\n",
      " - 2s - loss: 0.0674 - acc: 0.9750 - val_loss: 0.9433 - val_acc: 0.8005\n",
      "Epoch 26/35\n",
      " - 2s - loss: 0.0636 - acc: 0.9758 - val_loss: 0.9618 - val_acc: 0.8010\n",
      "Epoch 27/35\n",
      " - 2s - loss: 0.0628 - acc: 0.9763 - val_loss: 0.9794 - val_acc: 0.7990\n",
      "Epoch 28/35\n",
      " - 2s - loss: 0.0581 - acc: 0.9785 - val_loss: 1.0079 - val_acc: 0.8001\n",
      "Epoch 29/35\n",
      " - 2s - loss: 0.0563 - acc: 0.9785 - val_loss: 0.9983 - val_acc: 0.7961\n",
      "Epoch 30/35\n",
      " - 2s - loss: 0.0564 - acc: 0.9790 - val_loss: 1.0426 - val_acc: 0.7964\n",
      "Epoch 31/35\n",
      " - 2s - loss: 0.0540 - acc: 0.9792 - val_loss: 1.0623 - val_acc: 0.7951\n",
      "Epoch 32/35\n",
      " - 2s - loss: 0.0513 - acc: 0.9804 - val_loss: 1.0816 - val_acc: 0.8004\n",
      "Epoch 33/35\n",
      " - 2s - loss: 0.0487 - acc: 0.9813 - val_loss: 1.1000 - val_acc: 0.8011\n",
      "Epoch 34/35\n",
      " - 2s - loss: 0.0478 - acc: 0.9822 - val_loss: 1.1369 - val_acc: 0.7929\n",
      "Epoch 35/35\n",
      " - 2s - loss: 0.0443 - acc: 0.9834 - val_loss: 1.1270 - val_acc: 0.7948\n",
      "va acc: 0.7885\n",
      "te acc: 0.7948\n",
      "2018-09-18 23:15:56.558580 stack:5/5\n",
      "Train on 64000 samples, validate on 20000 samples\n",
      "Epoch 1/35\n",
      " - 2s - loss: 0.4756 - acc: 0.7983 - val_loss: 0.4438 - val_acc: 0.8185\n",
      "Epoch 2/35\n",
      " - 2s - loss: 0.4320 - acc: 0.8231 - val_loss: 0.4409 - val_acc: 0.8205\n",
      "Epoch 3/35\n",
      " - 2s - loss: 0.4159 - acc: 0.8296 - val_loss: 0.4409 - val_acc: 0.8232\n",
      "Epoch 4/35\n",
      " - 2s - loss: 0.3953 - acc: 0.8386 - val_loss: 0.4448 - val_acc: 0.8206\n",
      "Epoch 5/35\n",
      " - 2s - loss: 0.3703 - acc: 0.8484 - val_loss: 0.4599 - val_acc: 0.8195\n",
      "Epoch 6/35\n",
      " - 2s - loss: 0.3384 - acc: 0.8615 - val_loss: 0.4759 - val_acc: 0.8197\n",
      "Epoch 7/35\n",
      " - 2s - loss: 0.3064 - acc: 0.8733 - val_loss: 0.4889 - val_acc: 0.8130\n",
      "Epoch 8/35\n",
      " - 1s - loss: 0.2756 - acc: 0.8878 - val_loss: 0.5375 - val_acc: 0.8030\n",
      "Epoch 9/35\n",
      " - 1s - loss: 0.2446 - acc: 0.9021 - val_loss: 0.5679 - val_acc: 0.8002\n",
      "Epoch 10/35\n",
      " - 2s - loss: 0.2200 - acc: 0.9123 - val_loss: 0.5800 - val_acc: 0.8024\n",
      "Epoch 11/35\n",
      " - 2s - loss: 0.1962 - acc: 0.9220 - val_loss: 0.6011 - val_acc: 0.8074\n",
      "Epoch 12/35\n",
      " - 2s - loss: 0.1736 - acc: 0.9317 - val_loss: 0.6561 - val_acc: 0.7944\n",
      "Epoch 13/35\n",
      " - 2s - loss: 0.1582 - acc: 0.9383 - val_loss: 0.6809 - val_acc: 0.8024\n",
      "Epoch 14/35\n",
      " - 2s - loss: 0.1445 - acc: 0.9428 - val_loss: 0.6868 - val_acc: 0.7986\n",
      "Epoch 15/35\n",
      " - 2s - loss: 0.1297 - acc: 0.9497 - val_loss: 0.7220 - val_acc: 0.8041\n",
      "Epoch 16/35\n",
      " - 2s - loss: 0.1202 - acc: 0.9530 - val_loss: 0.7679 - val_acc: 0.8016\n",
      "Epoch 17/35\n",
      " - 2s - loss: 0.1102 - acc: 0.9570 - val_loss: 0.7857 - val_acc: 0.8016\n",
      "Epoch 18/35\n",
      " - 2s - loss: 0.1010 - acc: 0.9613 - val_loss: 0.8688 - val_acc: 0.7890\n",
      "Epoch 19/35\n",
      " - 2s - loss: 0.0962 - acc: 0.9624 - val_loss: 0.8134 - val_acc: 0.7955\n",
      "Epoch 20/35\n",
      " - 2s - loss: 0.0881 - acc: 0.9673 - val_loss: 0.8974 - val_acc: 0.7924\n",
      "Epoch 21/35\n",
      " - 2s - loss: 0.0821 - acc: 0.9688 - val_loss: 0.9001 - val_acc: 0.7994\n",
      "Epoch 22/35\n",
      " - 2s - loss: 0.0755 - acc: 0.9715 - val_loss: 0.9542 - val_acc: 0.7945\n",
      "Epoch 23/35\n",
      " - 2s - loss: 0.0762 - acc: 0.9707 - val_loss: 0.9204 - val_acc: 0.7988\n",
      "Epoch 24/35\n",
      " - 2s - loss: 0.0684 - acc: 0.9742 - val_loss: 0.9683 - val_acc: 0.7960\n",
      "Epoch 25/35\n",
      " - 2s - loss: 0.0666 - acc: 0.9749 - val_loss: 0.9874 - val_acc: 0.7933\n",
      "Epoch 26/35\n",
      " - 2s - loss: 0.0649 - acc: 0.9757 - val_loss: 0.9928 - val_acc: 0.8015\n",
      "Epoch 27/35\n",
      " - 2s - loss: 0.0579 - acc: 0.9784 - val_loss: 1.0414 - val_acc: 0.8045\n",
      "Epoch 28/35\n",
      " - 2s - loss: 0.0569 - acc: 0.9786 - val_loss: 1.0518 - val_acc: 0.8001\n",
      "Epoch 29/35\n",
      " - 2s - loss: 0.0546 - acc: 0.9791 - val_loss: 1.0422 - val_acc: 0.7995\n",
      "Epoch 30/35\n",
      " - 2s - loss: 0.0534 - acc: 0.9799 - val_loss: 1.0664 - val_acc: 0.8004\n",
      "Epoch 31/35\n",
      " - 2s - loss: 0.0502 - acc: 0.9816 - val_loss: 1.1248 - val_acc: 0.7939\n",
      "Epoch 32/35\n",
      " - 2s - loss: 0.0492 - acc: 0.9817 - val_loss: 1.0952 - val_acc: 0.8011\n",
      "Epoch 33/35\n",
      " - 2s - loss: 0.0474 - acc: 0.9817 - val_loss: 1.1184 - val_acc: 0.7987\n",
      "Epoch 34/35\n",
      " - 2s - loss: 0.0459 - acc: 0.9830 - val_loss: 1.1540 - val_acc: 0.7970\n",
      "Epoch 35/35\n",
      " - 2s - loss: 0.0447 - acc: 0.9833 - val_loss: 1.1535 - val_acc: 0.7994\n",
      "va acc: 0.799125\n",
      "te acc: 0.7994\n",
      "2018-09-18 23:16:53.738239 save dmd2v stack done!\n"
     ]
    }
   ],
   "source": [
    "#----------------------dmd2v stack for Education/age/gender---------------------------\n",
    "\n",
    "df_stack = pd.DataFrame(index=range(len(df_all)))\n",
    "TR = 80000\n",
    "n = 5\n",
    "\n",
    "X = X_sp[:TR]\n",
    "X_te = X_sp[TR:]\n",
    "\n",
    "feat = 'dmd2v'\n",
    "for i,lb in enumerate(['Education','age','gender']):\n",
    "    num_class = len(pd.value_counts(ys[lb]))\n",
    "    y = ys[lb][:TR]\n",
    "    y_te = ys[lb][TR:]\n",
    "    \n",
    "    stack = np.zeros((X.shape[0],num_class))\n",
    "    stack_te = np.zeros((X_te.shape[0],num_class))\n",
    "    \n",
    "    for k,(tr,va) in enumerate(KFold(len(y),n_folds=n)):\n",
    "        print('{} stack:{}/{}'.format(datetime.now(),k+1,n))\n",
    "        nb_classes = num_class\n",
    "        X_train = X[tr]\n",
    "        y_train = y[tr]\n",
    "        X_test = X_te\n",
    "        y_test = y_te\n",
    "\n",
    "        X_train = X_train.astype('float32')\n",
    "        X_test = X_test.astype('float32')\n",
    "        Y_train = np_utils.to_categorical(y_train, nb_classes)\n",
    "        Y_test = np_utils.to_categorical(y_test, nb_classes)\n",
    "\n",
    "\n",
    "        model = Sequential()\n",
    "        model.add(Dense(300,input_shape=(X_train.shape[1],)))\n",
    "        model.add(Dropout(0.1))\n",
    "        model.add(Activation('tanh'))\n",
    "        model.add(Dense(nb_classes))\n",
    "        model.add(Activation('softmax'))\n",
    "\n",
    "        model.compile(loss='categorical_crossentropy',\n",
    "                      optimizer='adadelta',\n",
    "                      metrics=['accuracy'])\n",
    "\n",
    "        history = model.fit(X_train, Y_train,shuffle=True,\n",
    "                            batch_size=128, nb_epoch=35,\n",
    "                            verbose=2, validation_data=(X_test, Y_test))\n",
    "        y_pred_va = model.predict_proba(X[va])\n",
    "        y_pred_te = model.predict_proba(X_te)\n",
    "        print('va acc:',myAcc(y[va],y_pred_va))\n",
    "        print('te acc:',myAcc(y_te,y_pred_te))\n",
    "        stack[va] += y_pred_va\n",
    "        stack_te += y_pred_te\n",
    "    stack_te /= n\n",
    "    stack_all = np.vstack([stack,stack_te])\n",
    "    for l in range(stack_all.shape[1]):\n",
    "        df_stack['{}_{}_{}'.format(feat,lb,l)] = stack_all[:,l]\n",
    "df_stack.to_csv(cfg.data_path + 'dmd2v_stack_10W.csv',encoding='utf8',index=None)\n",
    "print(datetime.now(),'save dmd2v stack done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Education\n",
      "Index(['tfidf_Education_0', 'tfidf_Education_1', 'tfidf_Education_2',\n",
      "       'tfidf_Education_3', 'tfidf_Education_4', 'tfidf_Education_5',\n",
      "       'tfidf_age_0', 'tfidf_age_1', 'tfidf_age_2', 'tfidf_age_3',\n",
      "       'tfidf_age_4', 'tfidf_age_5', 'tfidf_gender_0', 'tfidf_gender_1',\n",
      "       'dbowd2v_Education_0', 'dbowd2v_Education_1', 'dbowd2v_Education_2',\n",
      "       'dbowd2v_Education_3', 'dbowd2v_Education_4', 'dbowd2v_Education_5',\n",
      "       'dbowd2v_age_0', 'dbowd2v_age_1', 'dbowd2v_age_2', 'dbowd2v_age_3',\n",
      "       'dbowd2v_age_4', 'dbowd2v_age_5', 'dbowd2v_gender_0',\n",
      "       'dbowd2v_gender_1', 'dmd2v_Education_0', 'dmd2v_Education_1',\n",
      "       'dmd2v_Education_2', 'dmd2v_Education_3', 'dmd2v_Education_4',\n",
      "       'dmd2v_Education_5', 'dmd2v_age_0', 'dmd2v_age_1', 'dmd2v_age_2',\n",
      "       'dmd2v_age_3', 'dmd2v_age_4', 'dmd2v_age_5', 'dmd2v_gender_0',\n",
      "       'dmd2v_gender_1'],\n",
      "      dtype='object')\n",
      "[0]\ttrain-merror:0.312775\teval-merror:0.3326\ttrain-acc:0.687225\teval-acc:0.6674\n",
      "Multiple eval metrics have been passed: 'eval-acc' will be used for early stopping.\n",
      "\n",
      "Will train until eval-acc hasn't improved in 25 rounds.\n",
      "[1]\ttrain-merror:0.3089\teval-merror:0.33135\ttrain-acc:0.6911\teval-acc:0.66865\n",
      "[2]\ttrain-merror:0.3099\teval-merror:0.3301\ttrain-acc:0.6901\teval-acc:0.6699\n",
      "[3]\ttrain-merror:0.308338\teval-merror:0.32825\ttrain-acc:0.691662\teval-acc:0.67175\n",
      "[4]\ttrain-merror:0.307938\teval-merror:0.32835\ttrain-acc:0.692063\teval-acc:0.67165\n",
      "[5]\ttrain-merror:0.307025\teval-merror:0.32835\ttrain-acc:0.692975\teval-acc:0.67165\n",
      "[6]\ttrain-merror:0.30675\teval-merror:0.3278\ttrain-acc:0.69325\teval-acc:0.6722\n",
      "[7]\ttrain-merror:0.306925\teval-merror:0.327\ttrain-acc:0.693075\teval-acc:0.673\n",
      "[8]\ttrain-merror:0.306925\teval-merror:0.32725\ttrain-acc:0.693075\teval-acc:0.67275\n",
      "[9]\ttrain-merror:0.306913\teval-merror:0.32795\ttrain-acc:0.693087\teval-acc:0.67205\n",
      "[10]\ttrain-merror:0.306475\teval-merror:0.32805\ttrain-acc:0.693525\teval-acc:0.67195\n",
      "[11]\ttrain-merror:0.306437\teval-merror:0.32735\ttrain-acc:0.693562\teval-acc:0.67265\n",
      "[12]\ttrain-merror:0.30645\teval-merror:0.32735\ttrain-acc:0.69355\teval-acc:0.67265\n",
      "[13]\ttrain-merror:0.306175\teval-merror:0.32725\ttrain-acc:0.693825\teval-acc:0.67275\n",
      "[14]\ttrain-merror:0.3061\teval-merror:0.32715\ttrain-acc:0.6939\teval-acc:0.67285\n",
      "[15]\ttrain-merror:0.306175\teval-merror:0.32695\ttrain-acc:0.693825\teval-acc:0.67305\n",
      "[16]\ttrain-merror:0.305975\teval-merror:0.3266\ttrain-acc:0.694025\teval-acc:0.6734\n",
      "[17]\ttrain-merror:0.3056\teval-merror:0.3266\ttrain-acc:0.6944\teval-acc:0.6734\n",
      "[18]\ttrain-merror:0.305075\teval-merror:0.327\ttrain-acc:0.694925\teval-acc:0.673\n",
      "[19]\ttrain-merror:0.30495\teval-merror:0.32685\ttrain-acc:0.69505\teval-acc:0.67315\n",
      "[20]\ttrain-merror:0.304563\teval-merror:0.3271\ttrain-acc:0.695438\teval-acc:0.6729\n",
      "[21]\ttrain-merror:0.304425\teval-merror:0.32655\ttrain-acc:0.695575\teval-acc:0.67345\n",
      "[22]\ttrain-merror:0.304575\teval-merror:0.3269\ttrain-acc:0.695425\teval-acc:0.6731\n",
      "[23]\ttrain-merror:0.304675\teval-merror:0.32705\ttrain-acc:0.695325\teval-acc:0.67295\n",
      "[24]\ttrain-merror:0.304338\teval-merror:0.32645\ttrain-acc:0.695662\teval-acc:0.67355\n",
      "[25]\ttrain-merror:0.304588\teval-merror:0.32585\ttrain-acc:0.695412\teval-acc:0.67415\n",
      "[26]\ttrain-merror:0.3043\teval-merror:0.3259\ttrain-acc:0.6957\teval-acc:0.6741\n",
      "[27]\ttrain-merror:0.304062\teval-merror:0.32605\ttrain-acc:0.695937\teval-acc:0.67395\n",
      "[28]\ttrain-merror:0.304238\teval-merror:0.3262\ttrain-acc:0.695762\teval-acc:0.6738\n",
      "[29]\ttrain-merror:0.304188\teval-merror:0.32615\ttrain-acc:0.695812\teval-acc:0.67385\n",
      "[30]\ttrain-merror:0.30385\teval-merror:0.32605\ttrain-acc:0.69615\teval-acc:0.67395\n",
      "[31]\ttrain-merror:0.303525\teval-merror:0.32595\ttrain-acc:0.696475\teval-acc:0.67405\n",
      "[32]\ttrain-merror:0.3035\teval-merror:0.32605\ttrain-acc:0.6965\teval-acc:0.67395\n",
      "[33]\ttrain-merror:0.303438\teval-merror:0.3261\ttrain-acc:0.696562\teval-acc:0.6739\n",
      "[34]\ttrain-merror:0.303525\teval-merror:0.32585\ttrain-acc:0.696475\teval-acc:0.67415\n",
      "[35]\ttrain-merror:0.303375\teval-merror:0.32605\ttrain-acc:0.696625\teval-acc:0.67395\n",
      "[36]\ttrain-merror:0.303313\teval-merror:0.32575\ttrain-acc:0.696688\teval-acc:0.67425\n",
      "[37]\ttrain-merror:0.303412\teval-merror:0.326\ttrain-acc:0.696588\teval-acc:0.674\n",
      "[38]\ttrain-merror:0.303362\teval-merror:0.3257\ttrain-acc:0.696638\teval-acc:0.6743\n",
      "[39]\ttrain-merror:0.3031\teval-merror:0.32545\ttrain-acc:0.6969\teval-acc:0.67455\n",
      "[40]\ttrain-merror:0.302938\teval-merror:0.3256\ttrain-acc:0.697063\teval-acc:0.6744\n",
      "[41]\ttrain-merror:0.302713\teval-merror:0.3256\ttrain-acc:0.697287\teval-acc:0.6744\n",
      "[42]\ttrain-merror:0.3025\teval-merror:0.32545\ttrain-acc:0.6975\teval-acc:0.67455\n",
      "[43]\ttrain-merror:0.302388\teval-merror:0.32505\ttrain-acc:0.697612\teval-acc:0.67495\n",
      "[44]\ttrain-merror:0.302287\teval-merror:0.3249\ttrain-acc:0.697712\teval-acc:0.6751\n",
      "[45]\ttrain-merror:0.302112\teval-merror:0.3253\ttrain-acc:0.697887\teval-acc:0.6747\n",
      "[46]\ttrain-merror:0.3021\teval-merror:0.32525\ttrain-acc:0.6979\teval-acc:0.67475\n",
      "[47]\ttrain-merror:0.301812\teval-merror:0.32515\ttrain-acc:0.698187\teval-acc:0.67485\n",
      "[48]\ttrain-merror:0.301875\teval-merror:0.32495\ttrain-acc:0.698125\teval-acc:0.67505\n",
      "[49]\ttrain-merror:0.301762\teval-merror:0.32505\ttrain-acc:0.698237\teval-acc:0.67495\n",
      "[50]\ttrain-merror:0.301775\teval-merror:0.3253\ttrain-acc:0.698225\teval-acc:0.6747\n",
      "[51]\ttrain-merror:0.301587\teval-merror:0.32555\ttrain-acc:0.698412\teval-acc:0.67445\n",
      "[52]\ttrain-merror:0.3015\teval-merror:0.3257\ttrain-acc:0.6985\teval-acc:0.6743\n",
      "[53]\ttrain-merror:0.3016\teval-merror:0.32575\ttrain-acc:0.6984\teval-acc:0.67425\n",
      "[54]\ttrain-merror:0.301375\teval-merror:0.32535\ttrain-acc:0.698625\teval-acc:0.67465\n",
      "[55]\ttrain-merror:0.301375\teval-merror:0.3255\ttrain-acc:0.698625\teval-acc:0.6745\n",
      "[56]\ttrain-merror:0.301275\teval-merror:0.3255\ttrain-acc:0.698725\teval-acc:0.6745\n",
      "[57]\ttrain-merror:0.301175\teval-merror:0.32545\ttrain-acc:0.698825\teval-acc:0.67455\n",
      "[58]\ttrain-merror:0.30105\teval-merror:0.3255\ttrain-acc:0.69895\teval-acc:0.6745\n",
      "[59]\ttrain-merror:0.300925\teval-merror:0.3258\ttrain-acc:0.699075\teval-acc:0.6742\n",
      "[60]\ttrain-merror:0.301025\teval-merror:0.32595\ttrain-acc:0.698975\teval-acc:0.67405\n",
      "[61]\ttrain-merror:0.30095\teval-merror:0.32595\ttrain-acc:0.69905\teval-acc:0.67405\n",
      "[62]\ttrain-merror:0.3007\teval-merror:0.32595\ttrain-acc:0.6993\teval-acc:0.67405\n",
      "[63]\ttrain-merror:0.300725\teval-merror:0.32615\ttrain-acc:0.699275\teval-acc:0.67385\n",
      "[64]\ttrain-merror:0.3007\teval-merror:0.326\ttrain-acc:0.6993\teval-acc:0.674\n",
      "[65]\ttrain-merror:0.30065\teval-merror:0.3259\ttrain-acc:0.69935\teval-acc:0.6741\n",
      "[66]\ttrain-merror:0.300775\teval-merror:0.3262\ttrain-acc:0.699225\teval-acc:0.6738\n",
      "[67]\ttrain-merror:0.300625\teval-merror:0.3259\ttrain-acc:0.699375\teval-acc:0.6741\n",
      "[68]\ttrain-merror:0.300512\teval-merror:0.326\ttrain-acc:0.699488\teval-acc:0.674\n",
      "[69]\ttrain-merror:0.30055\teval-merror:0.326\ttrain-acc:0.69945\teval-acc:0.674\n",
      "Stopping. Best iteration:\n",
      "[44]\ttrain-merror:0.302287\teval-merror:0.3249\ttrain-acc:0.697712\teval-acc:0.6751\n",
      "\n",
      "age\n",
      "[0]\ttrain-merror:0.371062\teval-merror:0.376\ttrain-acc:0.628938\teval-acc:0.624\n",
      "Multiple eval metrics have been passed: 'eval-acc' will be used for early stopping.\n",
      "\n",
      "Will train until eval-acc hasn't improved in 25 rounds.\n",
      "[1]\ttrain-merror:0.363275\teval-merror:0.37105\ttrain-acc:0.636725\teval-acc:0.62895\n",
      "[2]\ttrain-merror:0.361187\teval-merror:0.3674\ttrain-acc:0.638813\teval-acc:0.6326\n",
      "[3]\ttrain-merror:0.35985\teval-merror:0.36585\ttrain-acc:0.64015\teval-acc:0.63415\n",
      "[4]\ttrain-merror:0.359338\teval-merror:0.36595\ttrain-acc:0.640663\teval-acc:0.63405\n",
      "[5]\ttrain-merror:0.358988\teval-merror:0.36565\ttrain-acc:0.641012\teval-acc:0.63435\n",
      "[6]\ttrain-merror:0.358375\teval-merror:0.36465\ttrain-acc:0.641625\teval-acc:0.63535\n",
      "[7]\ttrain-merror:0.359062\teval-merror:0.3641\ttrain-acc:0.640938\teval-acc:0.6359\n",
      "[8]\ttrain-merror:0.358813\teval-merror:0.36445\ttrain-acc:0.641188\teval-acc:0.63555\n",
      "[9]\ttrain-merror:0.358413\teval-merror:0.3632\ttrain-acc:0.641587\teval-acc:0.6368\n",
      "[10]\ttrain-merror:0.358438\teval-merror:0.36305\ttrain-acc:0.641563\teval-acc:0.63695\n",
      "[11]\ttrain-merror:0.358187\teval-merror:0.3627\ttrain-acc:0.641813\teval-acc:0.6373\n",
      "[12]\ttrain-merror:0.358238\teval-merror:0.3631\ttrain-acc:0.641763\teval-acc:0.6369\n",
      "[13]\ttrain-merror:0.358213\teval-merror:0.3633\ttrain-acc:0.641787\teval-acc:0.6367\n",
      "[14]\ttrain-merror:0.357738\teval-merror:0.36275\ttrain-acc:0.642262\teval-acc:0.63725\n",
      "[15]\ttrain-merror:0.358113\teval-merror:0.36265\ttrain-acc:0.641888\teval-acc:0.63735\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16]\ttrain-merror:0.357825\teval-merror:0.3626\ttrain-acc:0.642175\teval-acc:0.6374\n",
      "[17]\ttrain-merror:0.357675\teval-merror:0.3627\ttrain-acc:0.642325\teval-acc:0.6373\n",
      "[18]\ttrain-merror:0.357513\teval-merror:0.36325\ttrain-acc:0.642487\teval-acc:0.63675\n",
      "[19]\ttrain-merror:0.357475\teval-merror:0.36335\ttrain-acc:0.642525\teval-acc:0.63665\n",
      "[20]\ttrain-merror:0.35745\teval-merror:0.36355\ttrain-acc:0.64255\teval-acc:0.63645\n",
      "[21]\ttrain-merror:0.357388\teval-merror:0.36335\ttrain-acc:0.642613\teval-acc:0.63665\n",
      "[22]\ttrain-merror:0.356813\teval-merror:0.3639\ttrain-acc:0.643188\teval-acc:0.6361\n",
      "[23]\ttrain-merror:0.356875\teval-merror:0.3636\ttrain-acc:0.643125\teval-acc:0.6364\n",
      "[24]\ttrain-merror:0.356813\teval-merror:0.36355\ttrain-acc:0.643188\teval-acc:0.63645\n",
      "[25]\ttrain-merror:0.356775\teval-merror:0.36345\ttrain-acc:0.643225\teval-acc:0.63655\n",
      "[26]\ttrain-merror:0.356638\teval-merror:0.3636\ttrain-acc:0.643362\teval-acc:0.6364\n",
      "[27]\ttrain-merror:0.356463\teval-merror:0.36365\ttrain-acc:0.643537\teval-acc:0.63635\n",
      "[28]\ttrain-merror:0.356037\teval-merror:0.36325\ttrain-acc:0.643962\teval-acc:0.63675\n",
      "[29]\ttrain-merror:0.355812\teval-merror:0.36315\ttrain-acc:0.644188\teval-acc:0.63685\n",
      "[30]\ttrain-merror:0.355987\teval-merror:0.3631\ttrain-acc:0.644012\teval-acc:0.6369\n",
      "[31]\ttrain-merror:0.3561\teval-merror:0.3629\ttrain-acc:0.6439\teval-acc:0.6371\n",
      "[32]\ttrain-merror:0.355725\teval-merror:0.36275\ttrain-acc:0.644275\teval-acc:0.63725\n",
      "[33]\ttrain-merror:0.355262\teval-merror:0.36265\ttrain-acc:0.644737\teval-acc:0.63735\n",
      "[34]\ttrain-merror:0.355087\teval-merror:0.36285\ttrain-acc:0.644912\teval-acc:0.63715\n",
      "[35]\ttrain-merror:0.354925\teval-merror:0.36265\ttrain-acc:0.645075\teval-acc:0.63735\n",
      "[36]\ttrain-merror:0.355013\teval-merror:0.3632\ttrain-acc:0.644988\teval-acc:0.6368\n",
      "[37]\ttrain-merror:0.355063\teval-merror:0.36325\ttrain-acc:0.644938\teval-acc:0.63675\n",
      "[38]\ttrain-merror:0.35495\teval-merror:0.3631\ttrain-acc:0.64505\teval-acc:0.6369\n",
      "[39]\ttrain-merror:0.355075\teval-merror:0.36315\ttrain-acc:0.644925\teval-acc:0.63685\n",
      "[40]\ttrain-merror:0.355188\teval-merror:0.36285\ttrain-acc:0.644813\teval-acc:0.63715\n",
      "[41]\ttrain-merror:0.354988\teval-merror:0.36265\ttrain-acc:0.645012\teval-acc:0.63735\n",
      "Stopping. Best iteration:\n",
      "[16]\ttrain-merror:0.357825\teval-merror:0.3626\ttrain-acc:0.642175\teval-acc:0.6374\n",
      "\n",
      "gender\n",
      "[0]\ttrain-merror:0.150412\teval-merror:0.1535\ttrain-acc:0.849588\teval-acc:0.8465\n",
      "Multiple eval metrics have been passed: 'eval-acc' will be used for early stopping.\n",
      "\n",
      "Will train until eval-acc hasn't improved in 25 rounds.\n",
      "[1]\ttrain-merror:0.150338\teval-merror:0.153\ttrain-acc:0.849662\teval-acc:0.847\n",
      "[2]\ttrain-merror:0.1488\teval-merror:0.1529\ttrain-acc:0.8512\teval-acc:0.8471\n",
      "[3]\ttrain-merror:0.148775\teval-merror:0.1528\ttrain-acc:0.851225\teval-acc:0.8472\n",
      "[4]\ttrain-merror:0.148487\teval-merror:0.1522\ttrain-acc:0.851513\teval-acc:0.8478\n",
      "[5]\ttrain-merror:0.148375\teval-merror:0.1526\ttrain-acc:0.851625\teval-acc:0.8474\n",
      "[6]\ttrain-merror:0.1481\teval-merror:0.15225\ttrain-acc:0.8519\teval-acc:0.84775\n",
      "[7]\ttrain-merror:0.14795\teval-merror:0.1523\ttrain-acc:0.85205\teval-acc:0.8477\n",
      "[8]\ttrain-merror:0.1479\teval-merror:0.1522\ttrain-acc:0.8521\teval-acc:0.8478\n",
      "[9]\ttrain-merror:0.1476\teval-merror:0.15225\ttrain-acc:0.8524\teval-acc:0.84775\n",
      "[10]\ttrain-merror:0.147725\teval-merror:0.1519\ttrain-acc:0.852275\teval-acc:0.8481\n",
      "[11]\ttrain-merror:0.147738\teval-merror:0.15195\ttrain-acc:0.852263\teval-acc:0.84805\n",
      "[12]\ttrain-merror:0.147838\teval-merror:0.1523\ttrain-acc:0.852163\teval-acc:0.8477\n",
      "[13]\ttrain-merror:0.1476\teval-merror:0.15215\ttrain-acc:0.8524\teval-acc:0.84785\n",
      "[14]\ttrain-merror:0.14775\teval-merror:0.15225\ttrain-acc:0.85225\teval-acc:0.84775\n",
      "[15]\ttrain-merror:0.1477\teval-merror:0.15215\ttrain-acc:0.8523\teval-acc:0.84785\n",
      "[16]\ttrain-merror:0.147813\teval-merror:0.152\ttrain-acc:0.852187\teval-acc:0.848\n",
      "[17]\ttrain-merror:0.147813\teval-merror:0.152\ttrain-acc:0.852187\teval-acc:0.848\n",
      "[18]\ttrain-merror:0.14755\teval-merror:0.1522\ttrain-acc:0.85245\teval-acc:0.8478\n",
      "[19]\ttrain-merror:0.147437\teval-merror:0.152\ttrain-acc:0.852563\teval-acc:0.848\n",
      "[20]\ttrain-merror:0.147512\teval-merror:0.1518\ttrain-acc:0.852487\teval-acc:0.8482\n",
      "[21]\ttrain-merror:0.147488\teval-merror:0.15205\ttrain-acc:0.852513\teval-acc:0.84795\n",
      "[22]\ttrain-merror:0.147425\teval-merror:0.1521\ttrain-acc:0.852575\teval-acc:0.8479\n",
      "[23]\ttrain-merror:0.147512\teval-merror:0.15225\ttrain-acc:0.852487\teval-acc:0.84775\n",
      "[24]\ttrain-merror:0.14735\teval-merror:0.15195\ttrain-acc:0.85265\teval-acc:0.84805\n",
      "[25]\ttrain-merror:0.147337\teval-merror:0.1518\ttrain-acc:0.852662\teval-acc:0.8482\n",
      "[26]\ttrain-merror:0.147463\teval-merror:0.15185\ttrain-acc:0.852537\teval-acc:0.84815\n",
      "[27]\ttrain-merror:0.14765\teval-merror:0.15175\ttrain-acc:0.85235\teval-acc:0.84825\n",
      "[28]\ttrain-merror:0.14755\teval-merror:0.15175\ttrain-acc:0.85245\teval-acc:0.84825\n",
      "[29]\ttrain-merror:0.147463\teval-merror:0.1518\ttrain-acc:0.852537\teval-acc:0.8482\n",
      "[30]\ttrain-merror:0.147437\teval-merror:0.15175\ttrain-acc:0.852563\teval-acc:0.84825\n",
      "[31]\ttrain-merror:0.147612\teval-merror:0.15195\ttrain-acc:0.852387\teval-acc:0.84805\n",
      "[32]\ttrain-merror:0.147488\teval-merror:0.1519\ttrain-acc:0.852513\teval-acc:0.8481\n",
      "[33]\ttrain-merror:0.14775\teval-merror:0.1519\ttrain-acc:0.85225\teval-acc:0.8481\n",
      "[34]\ttrain-merror:0.147625\teval-merror:0.15195\ttrain-acc:0.852375\teval-acc:0.84805\n",
      "[35]\ttrain-merror:0.147575\teval-merror:0.15195\ttrain-acc:0.852425\teval-acc:0.84805\n",
      "[36]\ttrain-merror:0.147525\teval-merror:0.1519\ttrain-acc:0.852475\teval-acc:0.8481\n",
      "[37]\ttrain-merror:0.14755\teval-merror:0.15185\ttrain-acc:0.85245\teval-acc:0.84815\n",
      "[38]\ttrain-merror:0.147437\teval-merror:0.1518\ttrain-acc:0.852563\teval-acc:0.8482\n",
      "[39]\ttrain-merror:0.147488\teval-merror:0.1513\ttrain-acc:0.852513\teval-acc:0.8487\n",
      "[40]\ttrain-merror:0.147575\teval-merror:0.1514\ttrain-acc:0.852425\teval-acc:0.8486\n",
      "[41]\ttrain-merror:0.147612\teval-merror:0.15145\ttrain-acc:0.852387\teval-acc:0.84855\n",
      "[42]\ttrain-merror:0.147575\teval-merror:0.15145\ttrain-acc:0.852425\teval-acc:0.84855\n",
      "[43]\ttrain-merror:0.147475\teval-merror:0.1514\ttrain-acc:0.852525\teval-acc:0.8486\n",
      "[44]\ttrain-merror:0.147425\teval-merror:0.1514\ttrain-acc:0.852575\teval-acc:0.8486\n",
      "[45]\ttrain-merror:0.147488\teval-merror:0.1515\ttrain-acc:0.852513\teval-acc:0.8485\n",
      "[46]\ttrain-merror:0.1473\teval-merror:0.1513\ttrain-acc:0.8527\teval-acc:0.8487\n",
      "[47]\ttrain-merror:0.147225\teval-merror:0.15145\ttrain-acc:0.852775\teval-acc:0.84855\n",
      "[48]\ttrain-merror:0.147225\teval-merror:0.15145\ttrain-acc:0.852775\teval-acc:0.84855\n",
      "[49]\ttrain-merror:0.147162\teval-merror:0.1516\ttrain-acc:0.852838\teval-acc:0.8484\n",
      "[50]\ttrain-merror:0.147025\teval-merror:0.15145\ttrain-acc:0.852975\teval-acc:0.84855\n",
      "[51]\ttrain-merror:0.147013\teval-merror:0.1515\ttrain-acc:0.852988\teval-acc:0.8485\n",
      "[52]\ttrain-merror:0.147062\teval-merror:0.15135\ttrain-acc:0.852938\teval-acc:0.84865\n",
      "[53]\ttrain-merror:0.14695\teval-merror:0.1513\ttrain-acc:0.85305\teval-acc:0.8487\n",
      "[54]\ttrain-merror:0.146938\teval-merror:0.1514\ttrain-acc:0.853062\teval-acc:0.8486\n",
      "[55]\ttrain-merror:0.146938\teval-merror:0.15145\ttrain-acc:0.853062\teval-acc:0.84855\n",
      "[56]\ttrain-merror:0.146975\teval-merror:0.15135\ttrain-acc:0.853025\teval-acc:0.84865\n",
      "[57]\ttrain-merror:0.146913\teval-merror:0.1515\ttrain-acc:0.853087\teval-acc:0.8485\n",
      "[58]\ttrain-merror:0.147\teval-merror:0.1514\ttrain-acc:0.853\teval-acc:0.8486\n",
      "[59]\ttrain-merror:0.147\teval-merror:0.15145\ttrain-acc:0.853\teval-acc:0.84855\n",
      "[60]\ttrain-merror:0.147175\teval-merror:0.15125\ttrain-acc:0.852825\teval-acc:0.84875\n",
      "[61]\ttrain-merror:0.147113\teval-merror:0.15135\ttrain-acc:0.852888\teval-acc:0.84865\n",
      "[62]\ttrain-merror:0.14705\teval-merror:0.15125\ttrain-acc:0.85295\teval-acc:0.84875\n",
      "[63]\ttrain-merror:0.147075\teval-merror:0.1516\ttrain-acc:0.852925\teval-acc:0.8484\n",
      "[64]\ttrain-merror:0.14705\teval-merror:0.1514\ttrain-acc:0.85295\teval-acc:0.8486\n",
      "[65]\ttrain-merror:0.147025\teval-merror:0.1513\ttrain-acc:0.852975\teval-acc:0.8487\n",
      "[66]\ttrain-merror:0.14695\teval-merror:0.1515\ttrain-acc:0.85305\teval-acc:0.8485\n",
      "[67]\ttrain-merror:0.146863\teval-merror:0.15155\ttrain-acc:0.853137\teval-acc:0.84845\n",
      "[68]\ttrain-merror:0.146875\teval-merror:0.15155\ttrain-acc:0.853125\teval-acc:0.84845\n",
      "[69]\ttrain-merror:0.146913\teval-merror:0.15145\ttrain-acc:0.853087\teval-acc:0.84855\n",
      "[70]\ttrain-merror:0.146825\teval-merror:0.1513\ttrain-acc:0.853175\teval-acc:0.8487\n",
      "[71]\ttrain-merror:0.146775\teval-merror:0.15135\ttrain-acc:0.853225\teval-acc:0.84865\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[72]\ttrain-merror:0.14675\teval-merror:0.15145\ttrain-acc:0.85325\teval-acc:0.84855\n",
      "[73]\ttrain-merror:0.14665\teval-merror:0.15155\ttrain-acc:0.85335\teval-acc:0.84845\n",
      "[74]\ttrain-merror:0.14665\teval-merror:0.1515\ttrain-acc:0.85335\teval-acc:0.8485\n",
      "[75]\ttrain-merror:0.146675\teval-merror:0.1514\ttrain-acc:0.853325\teval-acc:0.8486\n",
      "[76]\ttrain-merror:0.14665\teval-merror:0.1514\ttrain-acc:0.85335\teval-acc:0.8486\n",
      "[77]\ttrain-merror:0.146725\teval-merror:0.15155\ttrain-acc:0.853275\teval-acc:0.84845\n",
      "[78]\ttrain-merror:0.146575\teval-merror:0.15165\ttrain-acc:0.853425\teval-acc:0.84835\n",
      "[79]\ttrain-merror:0.146625\teval-merror:0.1515\ttrain-acc:0.853375\teval-acc:0.8485\n",
      "[80]\ttrain-merror:0.146637\teval-merror:0.1514\ttrain-acc:0.853363\teval-acc:0.8486\n",
      "[81]\ttrain-merror:0.146637\teval-merror:0.15145\ttrain-acc:0.853363\teval-acc:0.84855\n",
      "[82]\ttrain-merror:0.146575\teval-merror:0.15165\ttrain-acc:0.853425\teval-acc:0.84835\n",
      "[83]\ttrain-merror:0.146563\teval-merror:0.15165\ttrain-acc:0.853437\teval-acc:0.84835\n",
      "[84]\ttrain-merror:0.146488\teval-merror:0.1515\ttrain-acc:0.853513\teval-acc:0.8485\n",
      "[85]\ttrain-merror:0.1465\teval-merror:0.1515\ttrain-acc:0.8535\teval-acc:0.8485\n",
      "Stopping. Best iteration:\n",
      "[60]\ttrain-merror:0.147175\teval-merror:0.15125\ttrain-acc:0.852825\teval-acc:0.84875\n",
      "\n"
     ]
    }
   ],
   "source": [
    "'''xgb-ens for education/age/gender'''\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import cfg\n",
    "import datetime\n",
    "\n",
    "def xgb_acc_score(preds,dtrain):\n",
    "    y_true = dtrain.get_label()\n",
    "    y_pred = np.argmax(preds,axis=1)\n",
    "    return [('acc',np.mean(y_true == y_pred))]\n",
    "\n",
    "df_lr = pd.read_csv(cfg.data_path + 'tfidf_stack_10W.csv')\n",
    "df_dm = pd.read_csv(cfg.data_path + 'dmd2v_stack_10W.csv')\n",
    "df_dbow = pd.read_csv(cfg.data_path + 'dbowd2v_stack_10W.csv')\n",
    "\n",
    "df_lb = pd.read_csv(cfg.data_path + 'all_v2.csv',usecols=['Id','Education','age','gender'],nrows=100000)\n",
    "ys = {}\n",
    "for lb in ['Education','age','gender']:\n",
    "    ys[lb] = np.array(df_lb[lb])\n",
    "\n",
    "'''最好的参数组合'''\n",
    "#-------------------------education----------------------------------\n",
    "TR = 80000\n",
    "df_sub = pd.DataFrame()\n",
    "df_sub['Id'] = df_lb.iloc[TR:]['Id']\n",
    "seed = 10\n",
    "lb = 'Education'\n",
    "print(lb)\n",
    "\n",
    "esr = 25\n",
    "evals = 1\n",
    "n_trees = 1000\n",
    "\n",
    "df = pd.concat([df_lr,df_dbow,df_dm],axis=1)\n",
    "print(df.columns)\n",
    "num_class = len(pd.value_counts(ys[lb]))\n",
    "X = df.iloc[:TR]\n",
    "y = ys[lb][:TR]\n",
    "X_te = df.iloc[TR:]\n",
    "y_te = ys[lb][TR:]\n",
    "\n",
    "ss = 0.9\n",
    "mc = 2\n",
    "md = 8\n",
    "gm = 2\n",
    "# n_trees = 30\n",
    "\n",
    "params = {\n",
    "    \"objective\": \"multi:softprob\",\n",
    "    \"booster\": \"gbtree\",\n",
    "#     \"eval_metric\": \"merror\",\n",
    "    \"num_class\":num_class,\n",
    "    'max_depth':md,\n",
    "    'min_child_weight':mc,\n",
    "    'subsample':ss,\n",
    "    'colsample_bytree':0.8,\n",
    "    'gamma':gm,\n",
    "    \"eta\": 0.01,\n",
    "    \"lambda\":0,\n",
    "    'alpha':0,\n",
    "    \"silent\": 1,\n",
    "#     'seed':seed,\n",
    "}\n",
    "\n",
    "dtrain = xgb.DMatrix(X, y)\n",
    "dvalid = xgb.DMatrix(X_te, y_te)\n",
    "watchlist = [(dtrain, 'train'), (dvalid, 'eval')]\n",
    "bst = xgb.train(params, dtrain, n_trees, evals=watchlist,feval=xgb_acc_score,maximize=True,\n",
    "                early_stopping_rounds=esr, verbose_eval=evals)\n",
    "df_sub['Education'] = np.argmax(bst.predict(dvalid),axis=1) + 1\n",
    "#------------------------ age-----------------------------------\n",
    "lb = 'age'\n",
    "print(lb)\n",
    "num_class = len(pd.value_counts(ys[lb]))\n",
    "\n",
    "# df = pd.concat([df_stack_tfidf,df_stack_d2v],axis=1)\n",
    "num_class = len(pd.value_counts(ys[lb]))\n",
    "X = df.iloc[:TR]\n",
    "y = ys[lb][:TR]\n",
    "X_te = df.iloc[TR:]\n",
    "y_te = ys[lb][TR:]\n",
    "\n",
    "ss = 0.5\n",
    "mc = 3\n",
    "md = 7\n",
    "gm = 2\n",
    "# n_trees = 37\n",
    "\n",
    "params = {\n",
    "    \"objective\": \"multi:softprob\",\n",
    "    \"booster\": \"gbtree\",\n",
    "#     \"eval_metric\": \"merror\",\n",
    "    \"num_class\":num_class,\n",
    "    'max_depth':md,\n",
    "    'min_child_weight':mc,\n",
    "    'subsample':ss,\n",
    "    'colsample_bytree':1,\n",
    "    'gamma':gm,\n",
    "    \"eta\": 0.01,\n",
    "    \"lambda\":0,\n",
    "    'alpha':0,\n",
    "    \"silent\": 1,\n",
    "#     'seed':seed,\n",
    "}\n",
    "\n",
    "dtrain = xgb.DMatrix(X, y)\n",
    "dvalid = xgb.DMatrix(X_te, y_te)\n",
    "watchlist = [(dtrain, 'train'), (dvalid, 'eval')]\n",
    "bst = xgb.train(params, dtrain, n_trees, evals=watchlist,feval=xgb_acc_score,maximize=True,\n",
    "                early_stopping_rounds=esr, verbose_eval=evals)\n",
    "df_sub['age'] = np.argmax(bst.predict(dvalid),axis=1)+1\n",
    "#--------------------------gender-------------------------------------\n",
    "lb = 'gender'\n",
    "print(lb)\n",
    "num_class = len(pd.value_counts(ys[lb]))\n",
    "\n",
    "# df = pd.concat([df_lr,df_multid2v],axis=1)\n",
    "num_class = len(pd.value_counts(ys[lb]))\n",
    "X = df.iloc[:TR]\n",
    "y = ys[lb][:TR]\n",
    "X_te = df.iloc[TR:]\n",
    "y_te = ys[lb][TR:]\n",
    "\n",
    "\n",
    "ss = 0.5\n",
    "mc = 0.8\n",
    "md = 7\n",
    "gm = 1\n",
    "# n_trees = 25\n",
    "\n",
    "params = {\n",
    "    \"objective\": \"multi:softprob\",\n",
    "    \"booster\": \"gbtree\",\n",
    "#     \"eval_metric\": \"merror\",\n",
    "    \"num_class\":num_class,\n",
    "    'max_depth':md,\n",
    "    'min_child_weight':mc,\n",
    "    'subsample':ss,\n",
    "    'colsample_bytree':1,\n",
    "    'gamma':gm,\n",
    "    \"eta\": 0.01,\n",
    "    \"lambda\":0,\n",
    "    'alpha':0,\n",
    "    \"silent\": 1,\n",
    "#     'seed':seed,\n",
    "}\n",
    "\n",
    "dtrain = xgb.DMatrix(X, y)\n",
    "dvalid = xgb.DMatrix(X_te, y_te)\n",
    "watchlist = [(dtrain, 'train'), (dvalid, 'eval')]\n",
    "bst = xgb.train(params, dtrain, n_trees, evals=watchlist,feval=xgb_acc_score,maximize=True,\n",
    "                early_stopping_rounds=esr, verbose_eval=evals)\n",
    "df_sub['gender'] = np.argmax(bst.predict(dvalid),axis=1)+1\n",
    "\n",
    "df_sub = df_sub[['Id','age','gender','Education']]\n",
    "df_sub.to_csv(cfg.data_path + 'tfidf_dm_dbow_2W.csv',index=None,header=None,sep=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
